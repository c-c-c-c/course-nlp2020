{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/01_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LIVXAmw_tMRv"
   },
   "source": [
    "# 01 ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ‰±ã„æ–¹ï¼šåŸºæœ¬ä¸­ã®åŸºæœ¬ç·¨\n",
    "\n",
    "* ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯ã€é•·ã„é•·ã„æ–‡å­—åˆ—ã€‚\n",
    "* é•·ã„é•·ã„æ–‡å­—åˆ—ã®ã¾ã¾ã§ã¯ã€æ™®é€šã¯åˆ†æã§ããªã„ã€‚\n",
    "* ä»Šå›ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ã«ãŠã‘ã‚‹åŸºæœ¬çš„ãªå‰å‡¦ç†ã«ã¤ã„ã¦å­¦ã¶ã€‚\n",
    "* ã¾ãŸã€ä»Šå›ã¯ã€è‹±èªãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æ‰±ã†ã€‚\n",
    " * æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã¯ã€æ¬¡å›ã€æ‰±ã†ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hXE1NNPpXbjI"
   },
   "source": [
    "ä»Šå›ã®notebookä½œæˆã«ã‚ãŸã£ã¦ã€ä¸‹è¨˜ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å‚è€ƒã«ã—ã¾ã—ãŸã€‚\n",
    "\n",
    " * https://github.com/dipanjanS/nlp_essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AgeSwPsGJFWj"
   },
   "source": [
    "## 01-01 å¤§æ–‡å­—å°æ–‡å­—é–“ã®å¤‰æ›\n",
    "\n",
    "* Pythonã®æ–‡å­—åˆ—å‹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ãˆã°ã€å¯èƒ½ã€‚\n",
    "\n",
    "* å•ï¼šå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ã£ãŸå¤§æ–‡å­—ã¨å°æ–‡å­—ã®åŒºåˆ¥ã‚’ç„¡ãã—ã¦ã—ã¾ã†ã“ã¨ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OQp382lJJFWp",
    "outputId": "bc84c694-433d-4130-b8e6-00adee0165e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox jumped over The Big Dog'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The quick brown fox jumped over The Big Dog'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FaAwb7HZJFWz",
    "outputId": "4878430b-f4f2-4a42-f7f2-982a6f8d38b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox jumped over the big dog'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ihX9LwVuJFW4",
    "outputId": "484a7ddc-8857-4f16-f3fc-cf7cd8657af8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE QUICK BROWN FOX JUMPED OVER THE BIG DOG'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "U24TBZ82JFW8",
    "outputId": "fe197368-e516-4c1a-e6c1-5f62739ba62d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Quick Brown Fox Jumped Over The Big Dog'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å„ãƒˆãƒ¼ã‚¯ãƒ³ã®ä¸€æ–‡å­—ç›®ã‚’å¤§æ–‡å­—ã«ã™ã‚‹ã€‚\n",
    "text.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NtCf5TIaJpEr"
   },
   "source": [
    "## 01-02 NLTKã‚’ä½¿ã£ã¦ã¿ã‚‹\n",
    "\n",
    "* NLTKã¯ã€Pythonã®æœ‰åãªè‡ªç„¶è¨€èªå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚2001å¹´ã‚¹ã‚¿ãƒ¼ãƒˆã‚‰ã—ã„ã€‚\n",
    "\n",
    "* https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "ceSG71XiJoka",
    "outputId": "b73be6cf-019b-4565-9b98-1fb809fd247f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3GzHq46JFW_"
   },
   "source": [
    "### Tokenization\n",
    "\n",
    "* æ–‡ã«åˆ†ã‘ã‚‹ã€å˜èªã«åˆ†ã‘ã‚‹ã€ãªã©ã€é•·ã„æ–‡å­—åˆ—ã¨ã—ã¦ã®è¨€èªãƒ‡ãƒ¼ã‚¿ã‚’ã‚ˆã‚Šå°ã•ãªå˜ä½ã¸ã¨åˆ†å‰²ã™ã‚‹ã“ã¨ã‚’ã€ä¸€èˆ¬ã«tokenizationã¨è¨€ã†ã€‚\n",
    "* segmentationã¨è¨€ã†ã“ã¨ã‚‚ã‚ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "zIiPr5JBJFXA",
    "outputId": "d72863ba-3c91-4423-e761-973ecfba18e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pythonã®æ–‡å­—åˆ—ã¯ã€è¤‡æ•°è¡Œã«ã‚ãŸã£ã¦ã„ã¦ã‚‚ã€ä¸¸æ‹¬å¼§ã§ããã‚Œã°ä¸€ã¤ã®é•·ã„æ–‡å­—åˆ—ã«ãªã‚‹ã€‚\n",
    "# ï¼ˆãŸã ã—ã€æœ€å¾Œã®è¡Œã‚’é™¤ã„ã¦ã€æœ«å°¾ã«ç©ºç™½ã‚’å…¥ã‚Œã¦ãŠãã®ã‚’å¿˜ã‚Œãªã„ã‚ˆã†ã«ã€‚ï¼‰\n",
    "\n",
    "sample_text = (\"US unveils world's most powerful supercomputer, beats China. \" \n",
    "               \"The US has unveiled the world's most powerful supercomputer called 'Summit', \" \n",
    "               \"beating the previous record-holder China's Sunway TaihuLight. With a peak performance \"\n",
    "               \"of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, \"\n",
    "               \"which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, \"\n",
    "               \"which reportedly take up the size of two tennis courts.\")\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "i2m8nEPmJFXD",
    "outputId": "9f5edeee-957d-47ea-e69c-330bf5e0ea82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"US unveils world's most powerful supercomputer, beats China.\",\n",
       " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\",\n",
       " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.',\n",
       " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ–‡ã”ã¨ã«åˆ†å‰²\n",
    "nltk.sent_tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gqCjdGno8FZ7"
   },
   "source": [
    "* å•ï¼šä¸‹ã«ç¤ºã™word tokenizationã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "KjVNIwLoJFXG",
    "outputId": "6ebf9093-afd8-450a-ef42-e95640e18f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US', 'unveils', 'world', \"'s\", 'most', 'powerful', 'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has', 'unveiled', 'the', 'world', \"'s\", 'most', 'powerful', 'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the', 'previous', 'record-holder', 'China', \"'s\", 'Sunway', 'TaihuLight', '.', 'With', 'a', 'peak', 'performance', 'of', '200,000', 'trillion', 'calculations', 'per', 'second', ',', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',', 'which', 'is', 'capable', 'of', '93,000', 'trillion', 'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608', 'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size', 'of', 'two', 'tennis', 'courts', '.']\n"
     ]
    }
   ],
   "source": [
    "# å˜èªã”ã¨ã«åˆ†å‰²\n",
    "print(nltk.word_tokenize(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D25190-Ft9Ls"
   },
   "source": [
    "## 01-03 spaCyã‚’ä½¿ã£ã¦ã¿ã‚‹\n",
    "\n",
    "* spaCyã‚‚ã€Pythonã®æœ‰åãªè‡ªç„¶è¨€èªå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚2015å¹´ã‚¹ã‚¿ãƒ¼ãƒˆã‚‰ã—ã„ã€‚\n",
    "\n",
    "* https://spacy.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nS5twUUnuIPf"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZjhORAuPJFXL"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DR6LA_YHJFXN"
   },
   "outputs": [],
   "source": [
    "text_spacy = nlp(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "QI_nN_l3zQwa",
    "outputId": "89f24723-b2c8-45d2-e23b-ff74516db807"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"US unveils world's most powerful supercomputer, beats China.\",\n",
       " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\",\n",
       " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.',\n",
       " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[obj.text for obj in text_spacy.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RR2DcOE18LfI"
   },
   "source": [
    "* å•ï¼š ä¸‹ã®word tokenizationã¯ã€å…ˆã»ã©ã®word tokenizationã¨ã©ã†é•ã†ã‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "DBuAHdR8JFXQ",
    "outputId": "ddc7480d-7186-4abc-fb98-ae4857abca67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US', 'unveils', 'world', \"'s\", 'most', 'powerful', 'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has', 'unveiled', 'the', 'world', \"'s\", 'most', 'powerful', 'supercomputer', 'called', \"'\", 'Summit', \"'\", ',', 'beating', 'the', 'previous', 'record', '-', 'holder', 'China', \"'s\", 'Sunway', 'TaihuLight', '.', 'With', 'a', 'peak', 'performance', 'of', '200,000', 'trillion', 'calculations', 'per', 'second', ',', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',', 'which', 'is', 'capable', 'of', '93,000', 'trillion', 'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608', 'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size', 'of', 'two', 'tennis', 'courts', '.']\n"
     ]
    }
   ],
   "source": [
    "print([obj.text for obj in text_spacy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fhxnJkIsJFXS"
   },
   "source": [
    "## 01-04 HTMLæ–‡æ›¸ã®å‰å‡¦ç†\n",
    "\n",
    "* __`<p>`__ã‚„__`<a>`__ã‚„__`<div>`__ãªã©ã€é »ç¹ã«ä½¿ã†HTMLã‚¿ã‚°ã¯é ­ã«å…¥ã‚Œã¦ãŠã„ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "* ãªãœãªã‚‰ã€ã‚ã‚‹ç¨‹åº¦HTMLã‚¿ã‚°ãŒèª­ã‚ã¦ã¯ã˜ã‚ã¦ã€ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ããŸã‚ã®ã€HTMLã‚½ãƒ¼ã‚¹ã®ä¸‹èª¿ã¹ãŒã§ãã‚‹ã‹ã‚‰ã§ã™ã€‚\n",
    " * è‡ªå‰ã§Webä¸Šã‹ã‚‰åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã¨ãã¯ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã‚ˆã†ã¨ã™ã‚‹Webãƒšãƒ¼ã‚¸ã®HTMLã®æ§‹é€ ã‚’è‡ªåˆ†ã®ç›®ã§ç¢ºèªã™ã‚‹ã€‚\n",
    "\n",
    "* å•ï¼šèª°ã‹ã«ã‚ˆã£ã¦æ•´å‚™ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ãªãã€è‡ªå‰ã§HTMLæ–‡æ›¸ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ã“ã¨ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ewyVIu3auUl"
   },
   "source": [
    "### HTMLæ–‡æ›¸ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "* ã„ãã¤ã‹æ–¹æ³•ã¯ã‚ã‚‹ãŒã€ã“ã“ã§ã¯requestsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "E3qV1WOpJFXT",
    "outputId": "f8d0faa0-efbe-423f-b8c7-8523fb878259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"id00011\" style=\"margin-top: 2em\">*** START OF THE PROJECT GUTENBERG EBOOK, THE BIBLE, KING JAMES, BOOK 1***</p>\r\n",
      "\r\n",
      "<p id=\"id00012\" style=\"margin-top: 4em\">This eBook was produced by David Widger\r\n",
      "with the help of Derek Andrew's text from January 1992\r\n",
      "and the work of Bryan Taylor in November 2002.</p>\r\n",
      "\r\n",
      "<h1 id=\"id00013\" style=\"margin-top: 5em\">Book 01        Genesis</h1>\r\n",
      "\r\n",
      "<p id=\"id00014\">01:001:001 In the beginning God created the heaven and the earth.</p>\r\n",
      "\r\n",
      "<p id=\"id00015\" style=\"margin-left: 0%; margin-right: 0%\">01:001:002 And the earth was without form, and void; and darkness was\r\n",
      "           upon the face of the deep. And the Spirit of God moved upon\r\n",
      "           the face of the waters.</p>\r\n",
      "\r\n",
      "<p id=\"id00016\">01:001:003 And God said, Let there be light: and there was light.</p>\r\n",
      "\r\n",
      "<p id=\"id00017\">01:001:004 And God saw the light, that it was good: and God divided the<br/>\r\n",
      "\r\n",
      "Â Â Â Â Â Â Â Â Â Â Â light from the darkness.<br/>\r\n",
      "</p>\r\n",
      "\r\n",
      "<p id=\"id00018\">01:001:005 And God called the light Day, and the darkness he called<br/>\r\n",
      "\r\n",
      "Â Â Â Â Â Â Â Â Â Â Â Night. And the evening and the morning were the first day.<br/>\r\n",
      "</p>\r\n",
      "\r\n",
      "<p id=\"id00019\">01:001:006 And God said, Let there be a firmament in the mi\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = requests.get('http://www.gutenberg.org/cache/epub/8001/pg8001.html')\n",
    "content = data.text\n",
    "print(content[2745:3948])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Vte11lpuXV_"
   },
   "source": [
    "### Beautiful Soupã®åˆ©ç”¨\n",
    "\n",
    "* HTMLæ–‡æ›¸ã®æ§‹é€ ã‚’è§£æã™ã‚‹ãŸã‚ã«ã‚ˆãä½¿ã‚ã‚Œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚\n",
    "\n",
    "* å‚è€ƒè³‡æ–™ï¼šã€ŒBeautiful Soup 4ã«ã‚ˆã‚‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®åŸºç¤ã€\n",
    "\n",
    " * https://www.atmarkit.co.jp/ait/articles/1910/18/news015.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "E6UAz3mjJFXY",
    "outputId": "6bc556a8-ad18-49b2-a4b2-4a553e729fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** START OF THE PROJECT GUTENBERG EBOOK, THE BIBLE, KING JAMES, BOOK 1***\n",
      "This eBook was produced by David Widger\n",
      "with the help of Derek Andrew's text from January 1992\n",
      "and the work of Bryan Taylor in November 2002.\n",
      "Book 01        Genesis\n",
      "01:001:001 In the beginning God created the heaven and the earth.\n",
      "01:001:002 And the earth was without form, and void; and darkness was\n",
      "           upon the face of the deep. And the Spirit of God moved upon\n",
      "           the face of the waters.\n",
      "01:001:003 And God said, Let there be light: and there was light.\n",
      "01:001:004 And God saw the light, that it was good: and God divided the\n",
      "Â Â Â Â Â Â Â Â Â Â Â light from the darkness.\n",
      "01:001:005 And God called the light Day, and the darkness he called\n",
      "Â Â Â Â Â Â Â Â Â Â Â Night. And the evening and the morning were the first day.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    # ä¸‹ã®æ­£è¦è¡¨ç¾ã®æ„å‘³ã‚’èª¬æ˜ã—ã¦ã¿ã‚ˆã†ã€‚\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    return stripped_text\n",
    "\n",
    "clean_content = strip_html_tags(content)\n",
    "print(clean_content[1163:1957])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "au1nuTllwX07"
   },
   "source": [
    "## æ¼”ç¿’1-1\n",
    "* clean_contentã‚’å˜èªã«åˆ†å‰²ã—ã€å„å˜èªã®å‡ºç¾é »åº¦ã‚’æ±‚ã‚ã€å‡ºç¾é »åº¦ã®é«˜ã„é †ã«ä¸Šä½100ã®å˜èªã‚’ã€å‡ºç¾é »åº¦ã¨ã¨ã‚‚ã«è¡¨ç¤ºã—ã‚ˆã†ã€‚\n",
    "* clean_contentã®å†…å®¹ã‚’ã™ã¹ã¦å°æ–‡å­—ã«å¤‰æ›ã—ãŸå¾Œã§åŒã˜ã“ã¨ã‚’ã—ã¦ã¿ã‚ˆã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdGJ9gYO_j1o"
   },
   "outputs": [],
   "source": [
    "# æ¼”ç¿’1-1ã®ç­”æ¡ˆ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fJi5YyKJFXc"
   },
   "source": [
    "## 01-05 ã‚¢ã‚¯ã‚»ãƒ³ãƒˆè¨˜å·ã®é™¤å»\n",
    "\n",
    "* unicodedataã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã†ã€‚\n",
    "\n",
    " * https://docs.python.org/3/library/unicodedata.html\n",
    "\n",
    "* 'NFKD'ã¯ä½•ã‚’æ„å‘³ã™ã‚‹ã‹ï¼Ÿ ï¼ˆWikipediaã€ŒUnicodeæ­£è¦åŒ–ã€ï¼‰\n",
    "\n",
    " * https://ja.wikipedia.org/wiki/Unicode%E6%AD%A3%E8%A6%8F%E5%8C%96\n",
    "\n",
    "* Pythonã«ãŠã‘ã‚‹Unicode HOWTO\n",
    "\n",
    " * https://docs.python.org/ja/3/howto/unicode.html\n",
    "\n",
    "* ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã«ãŠã„ã¦ã‚¢ã‚¯ã‚»ãƒ³ãƒˆè¨˜å·ã‚’é™¤å»ã™ã‚‹ã“ã¨ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ps9wmhv9JFXd"
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Mc7JR8CQJFXh",
    "outputId": "52237b22-9b83-4552-f51f-cac4cb3d815a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Le bon sens est la chose du monde la mieux partagÃ©e; car chacun pense en Ãªtre si bien pourvu, que ceux mÃªme qui sont les plus difficiles Ã  contenter en toute autre chose n'ont point coutume d'en dÃ©sirer plus qu'ils en ont.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = (\"Le bon sens est la chose du monde la mieux partagÃ©e; car chacun pense \"\n",
    "  \"en Ãªtre si bien pourvu, que ceux mÃªme qui sont les plus difficiles Ã  \"\n",
    "  \"contenter en toute autre chose n'ont point coutume d'en dÃ©sirer plus \"\n",
    "  \"qu'ils en ont.\")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "I6a-e-mVJFXm",
    "outputId": "75dc5262-d2ec-4aa3-a829-9e4750614aae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Le bon sens est la chose du monde la mieux partagee; car chacun pense en etre si bien pourvu, que ceux meme qui sont les plus difficiles a contenter en toute autre chose n'ont point coutume d'en desirer plus qu'ils en ont.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_accented_chars(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gj8CyGmPJFXr"
   },
   "source": [
    "## 01-06 ç‰¹æ®Šæ–‡å­—ã€æ•°å­—ã€è¨˜å·ã®é™¤å»\n",
    "\n",
    "* reãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ã†ã€‚reã¯regular expression(æ­£è¦è¡¨ç¾)ã®ã“ã¨ã€‚\n",
    "\n",
    "* å•ï¼šãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã«ãŠã„ã¦ç‰¹æ®Šæ–‡å­—ã€æ•°å­—ã€è¨˜å·ãªã©ã‚’é™¤å»ã™ã‚‹ã“ã¨ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dkc4ESDJFXs"
   },
   "outputs": [],
   "source": [
    "# å•ï¼šä¸‹ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ï¼’ã¤ã®æ­£è¦è¡¨ç¾ã¯ãã‚Œãã‚Œã©ã†ã„ã†æ„å‘³ã‹ï¼Ÿ\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XUwKvQ-1JFXx",
    "outputId": "ede15681-b2c4-46b7-da2b-6140736c6c5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun! See you at 7:30, What do you think!!? #$@@9318@ ğŸ™‚ğŸ™‚ğŸ™‚'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Well this was fun! See you at 7:30, What do you think!!? #$@@9318@ ğŸ™‚ğŸ™‚ğŸ™‚\"\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Sy9x4XFyJFYL",
    "outputId": "c148567e-a426-42f1-efa7-ffd4de444a35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun See you at  What do you think  '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_special_characters(s, remove_digits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "s2vT0GK5JFYQ",
    "outputId": "ebe8bddc-5220-4c1b-80fd-53c1900425ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun See you at 730 What do you think 9318 '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_special_characters(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ho6h68QbJFYX"
   },
   "source": [
    "## 01-07 contraction\n",
    "\n",
    "* è‹±èªã«ã¯æ§˜ã€…ãªçœç•¥è¡¨ç¾ãŒã‚ã‚‹ã€‚ã“ã‚Œã‚’å…ƒã«æˆ»ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "mgGTT1URJFYY",
    "outputId": "6f55ab39-eede-4958-d19d-8a97b4ca7290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.0.25-py2.py3-none-any.whl (3.2 kB)\n",
      "Collecting textsearch\n",
      "  Downloading textsearch-0.0.17-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: pyahocorasick in /opt/conda/lib/python3.7/site-packages (from textsearch->contractions) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in /opt/conda/lib/python3.7/site-packages (from textsearch->contractions) (1.1.1)\n",
      "Installing collected packages: textsearch, contractions\n",
      "Successfully installed contractions-0.0.25 textsearch-0.0.17\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: textsearch in /opt/conda/lib/python3.7/site-packages (0.0.17)\n",
      "Requirement already satisfied: pyahocorasick in /opt/conda/lib/python3.7/site-packages (from textsearch) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in /opt/conda/lib/python3.7/site-packages (from textsearch) (1.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "!pip install textsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5xWsgO-jJFYc",
    "outputId": "79dfd64f-07ab-4fdd-abdc-5125a75c7391"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Y'all can't expand contractions I'd think! You wouldn't be able to. How'd you do it?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Y'all can't expand contractions I'd think! You wouldn't be able to. How'd you do it?\"\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S2QTF2HFJFYi",
    "outputId": "04fb9ca9-ba0e-40b0-d223-0f73ad21ccb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "\n",
    "contractions_list = list(contractions.contractions_dict.items())\n",
    "print(len(contractions_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Lm2e0y-Vymmg",
    "outputId": "a72b5f28-714a-465f-8ca6-e7ab3f88ad0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"ain't\", 'are not'), (\"aren't\", 'are not'), (\"can't\", 'can not'), (\"can't've\", 'can not have'), (\"'cause\", 'because'), (\"could've\", 'could have'), (\"couldn't\", 'could not'), (\"couldn't've\", 'could not have'), (\"didn't\", 'did not'), (\"doesn't\", 'does not'), (\"don't\", 'do not'), (\"hadn't\", 'had not'), (\"hadn't've\", 'had not have'), (\"hasn't\", 'has not'), (\"haven't\", 'have not'), (\"he'd\", 'he would'), (\"he'd've\", 'he would have'), (\"he'll\", 'he will'), (\"he'll've\", 'he will have'), (\"he's\", 'he is'), (\"how'd\", 'how did'), (\"how're\", 'how are'), (\"how'd'y\", 'how do you'), (\"how'll\", 'how will'), (\"how's\", 'how is'), (\"I'd\", 'I would'), (\"I'd've\", 'I would have'), (\"I'll\", 'I will'), (\"I'll've\", 'I will have'), (\"I'm\", 'I am'), (\"I've\", 'I have'), (\"isn't\", 'is not'), (\"it'd\", 'it would'), (\"it'd've\", 'it would have'), (\"it'll\", 'it will'), (\"it'll've\", 'it will have'), (\"it's\", 'it is'), (\"let's\", 'let us'), (\"ma'am\", 'madam'), (\"mayn't\", 'may not'), (\"might've\", 'might have'), (\"mightn't\", 'might not'), (\"mightn't've\", 'might not have'), (\"must've\", 'must have'), (\"mustn't\", 'must not'), (\"mustn't've\", 'must not have'), (\"needn't\", 'need not'), (\"needn't've\", 'need not have'), (\"o'clock\", 'of the clock'), (\"oughtn't\", 'ought not'), (\"oughtn't've\", 'ought not have'), (\"shan't\", 'shall not'), (\"sha'n't\", 'shall not'), (\"shan't've\", 'shall not have'), (\"she'd\", 'she would'), (\"she'd've\", 'she would have'), (\"she'll\", 'she will'), (\"she'll've\", 'she will have'), (\"she's\", 'she is'), (\"should've\", 'should have'), (\"shouldn't\", 'should not'), (\"shouldn't've\", 'should not have'), (\"so've\", 'so have'), (\"so's\", 'so is'), (\"that'd\", 'that would'), (\"that'd've\", 'that would have'), (\"that's\", 'that is'), (\"there'd\", 'there would'), (\"there'd've\", 'there would have'), (\"there's\", 'there is'), (\"they'd\", 'they would'), (\"they'd've\", 'they would have'), (\"they'll\", 'they will'), (\"they'll've\", 'they will have'), (\"they're\", 'they are'), (\"they've\", 'they have'), (\"to've\", 'to have'), (\"wasn't\", 'was not'), (\"we'd\", 'we would'), (\"we'd've\", 'we would have'), (\"we'll\", 'we will'), (\"we'll've\", 'we will have'), (\"we're\", 'we are'), (\"we've\", 'we have'), (\"weren't\", 'were not'), (\"what'll\", 'what will'), (\"what'll've\", 'what will have'), (\"what're\", 'what are'), (\"what's\", 'what is'), (\"what've\", 'what have'), (\"when's\", 'when is'), (\"when've\", 'when have'), (\"where'd\", 'where did'), (\"where's\", 'where is'), (\"where've\", 'where have'), (\"who'll\", 'who will'), (\"who'll've\", 'who will have'), (\"who's\", 'who is'), (\"who've\", 'who have'), (\"why's\", 'why is'), (\"why've\", 'why have'), (\"will've\", 'will have'), (\"won't\", 'will not'), (\"won't've\", 'will not have'), (\"would've\", 'would have'), (\"wouldn't\", 'would not'), (\"wouldn't've\", 'would not have'), (\"y'all\", 'you all'), (\"y'all'd\", 'you all would'), (\"y'all'd've\", 'you all would have'), (\"y'all're\", 'you all are'), (\"y'all've\", 'you all have'), (\"you'd\", 'you would'), (\"you'd've\", 'you would have'), (\"you'll\", 'you will'), (\"you'll've\", 'you shall have'), (\"you're\", 'you are'), (\"you've\", 'you have'), ('jan.', 'january'), ('feb.', 'february'), ('mar.', 'march'), ('apr.', 'april'), ('jun.', 'june'), ('jul.', 'july'), ('aug.', 'august'), ('sep.', 'september'), ('oct.', 'october'), ('nov.', 'november'), ('dec.', 'december'), ('ainâ€™t', 'are not'), ('arenâ€™t', 'are not'), ('canâ€™t', 'can not'), ('canâ€™tâ€™ve', 'can not have'), ('â€™cause', 'because'), ('couldâ€™ve', 'could have'), ('couldnâ€™t', 'could not'), ('couldnâ€™tâ€™ve', 'could not have'), ('didnâ€™t', 'did not'), ('doesnâ€™t', 'does not'), ('donâ€™t', 'do not'), ('hadnâ€™t', 'had not'), ('hadnâ€™tâ€™ve', 'had not have'), ('hasnâ€™t', 'has not'), ('havenâ€™t', 'have not'), ('heâ€™d', 'he would'), ('heâ€™dâ€™ve', 'he would have'), ('heâ€™ll', 'he will'), ('heâ€™llâ€™ve', 'he will have'), ('heâ€™s', 'he is'), ('howâ€™d', 'how did'), ('howâ€™re', 'how are'), ('howâ€™dâ€™y', 'how do you'), ('howâ€™ll', 'how will'), ('howâ€™s', 'how is'), ('Iâ€™d', 'I would'), ('Iâ€™dâ€™ve', 'I would have'), ('Iâ€™ll', 'I will'), ('Iâ€™llâ€™ve', 'I will have'), ('Iâ€™m', 'I am'), ('Iâ€™ve', 'I have'), ('isnâ€™t', 'is not'), ('itâ€™d', 'it would'), ('itâ€™dâ€™ve', 'it would have'), ('itâ€™ll', 'it will'), ('itâ€™llâ€™ve', 'it will have'), ('itâ€™s', 'it is'), ('letâ€™s', 'let us'), ('maâ€™am', 'madam'), ('maynâ€™t', 'may not'), ('mightâ€™ve', 'might have'), ('mightnâ€™t', 'might not'), ('mightnâ€™tâ€™ve', 'might not have'), ('mustâ€™ve', 'must have'), ('mustnâ€™t', 'must not'), ('mustnâ€™tâ€™ve', 'must not have'), ('neednâ€™t', 'need not'), ('neednâ€™tâ€™ve', 'need not have'), ('oâ€™clock', 'of the clock'), ('oughtnâ€™t', 'ought not'), ('oughtnâ€™tâ€™ve', 'ought not have'), ('shanâ€™t', 'shall not'), ('shaâ€™nâ€™t', 'shall not'), ('shanâ€™tâ€™ve', 'shall not have'), ('sheâ€™d', 'she would'), ('sheâ€™dâ€™ve', 'she would have'), ('sheâ€™ll', 'she will'), ('sheâ€™llâ€™ve', 'she will have'), ('sheâ€™s', 'she is'), ('shouldâ€™ve', 'should have'), ('shouldnâ€™t', 'should not'), ('shouldnâ€™tâ€™ve', 'should not have'), ('soâ€™ve', 'so have'), ('soâ€™s', 'so is'), ('thatâ€™d', 'that would'), ('thatâ€™dâ€™ve', 'that would have'), ('thatâ€™s', 'that is'), ('thereâ€™d', 'there would'), ('thereâ€™dâ€™ve', 'there would have'), ('thereâ€™s', 'there is'), ('theyâ€™d', 'they would'), ('theyâ€™dâ€™ve', 'they would have'), ('theyâ€™ll', 'they will'), ('theyâ€™llâ€™ve', 'they will have'), ('theyâ€™re', 'they are'), ('theyâ€™ve', 'they have'), ('toâ€™ve', 'to have'), ('wasnâ€™t', 'was not'), ('weâ€™d', 'we would'), ('weâ€™dâ€™ve', 'we would have'), ('weâ€™ll', 'we will'), ('weâ€™llâ€™ve', 'we will have'), ('weâ€™re', 'we are'), ('weâ€™ve', 'we have'), ('werenâ€™t', 'were not'), ('whatâ€™ll', 'what will'), ('whatâ€™llâ€™ve', 'what will have'), ('whatâ€™re', 'what are'), ('whatâ€™s', 'what is'), ('whatâ€™ve', 'what have'), ('whenâ€™s', 'when is'), ('whenâ€™ve', 'when have'), ('whereâ€™d', 'where did'), ('whereâ€™s', 'where is'), ('whereâ€™ve', 'where have'), ('whoâ€™ll', 'who will'), ('whoâ€™llâ€™ve', 'who will have'), ('whoâ€™s', 'who is'), ('whoâ€™ve', 'who have'), ('whyâ€™s', 'why is'), ('whyâ€™ve', 'why have'), ('willâ€™ve', 'will have'), ('wonâ€™t', 'will not'), ('wonâ€™tâ€™ve', 'will not have'), ('wouldâ€™ve', 'would have'), ('wouldnâ€™t', 'would not'), ('wouldnâ€™tâ€™ve', 'would not have'), ('yâ€™all', 'you all'), ('yâ€™allâ€™d', 'you all would'), ('yâ€™allâ€™dâ€™ve', 'you all would have'), ('yâ€™allâ€™re', 'you all are'), ('yâ€™allâ€™ve', 'you all have'), ('youâ€™d', 'you would'), ('youâ€™dâ€™ve', 'you would have'), ('youâ€™ll', 'you will'), ('youâ€™llâ€™ve', 'you shall have'), ('youâ€™re', 'you are'), ('youâ€™ve', 'you have')]\n"
     ]
    }
   ],
   "source": [
    "print(contractions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KoIGJXqCJFYo",
    "outputId": "99cede2d-5e28-46bd-ed87-8826bdef1e28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you all can not expand contractions I would think! You would not be able to. how did you do it?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions.fix(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bC54E8pjzGMu",
    "outputId": "b10fd826-0be5-4636-d75e-e30ff6f44a74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it is pool-season from this week, is not it? Oh yes. I have got to go and buy a swimming suit, then.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"It's pool-season from this week, isn't it? Oh yes. I've gotta go and buy a swimming suit, then.\"\n",
    "contractions.fix(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EeUHPmhDJFZC"
   },
   "source": [
    "## 01-08 NLTKã§stemming\n",
    "\n",
    "* èªå°¾ãŒå¤‰åŒ–ã™ã‚‹å˜èªã®ã€ãã®å¤‰åŒ–ã‚’ç„¡ãã—ã¦ã€èªå¹¹ã‚’å¾—ã‚‹ã€‚\n",
    "* å¾—ã‚‰ã‚Œã‚‹èªå¹¹ã¯ã€è‹±å˜èªã¨ã—ã¦é€šç”¨ã—ãªã„æ–‡å­—åˆ—ã«ãªã‚‹ã“ã¨ãŒå¤šã„ã€‚\n",
    "* Stemming and Lemmatization in Python\n",
    " * https://www.datacamp.com/community/tutorials/stemming-lemmatization-python\n",
    "\n",
    "\n",
    "* å•ï¼šãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ã—ã¦stemmingã‚’ã™ã‚‹ã“ã¨ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã‹ï¼Ÿ\n",
    "* å•ï¼šæ§˜ã€…ãªç¨®é¡ã®stemmerãŒã‚ã‚‹ã®ã¯ãªãœã‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8ndJ4XOKJFZD",
    "outputId": "c1aea33a-192f-41fd-ceba-37af3335f701"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porter Stemmerã‚’ä½¿ã£ã¦ã¿ã‚‹ ï¼ˆstemmerã¨è¨€ãˆã°ã“ã‚Œã€ã¨ã„ã†ãã‚‰ã„è‰¯ãçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ï¼‰\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "ps.stem('jumping'), ps.stem('jumps'), ps.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CmWLISH-JFZG",
    "outputId": "fe8a33a4-627a-4713-b921-2268ac9e1bcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lie'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Q7KRj1jtJFZJ",
    "outputId": "f1dada9b-0656-4828-c97b-a44bdf13d68c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strang'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('strange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cQNUmpfLJFZu"
   },
   "source": [
    "## 01-09 NLTKã§lemmatizationï¼ˆä¸å®Œå…¨ç‰ˆï¼‰\n",
    "\n",
    "* èªå½¢ãŒå¤‰ã‚ã‚‹å˜èªã‚’åŸå‹ã«æˆ»ã™ã€‚\n",
    "* åŸå‹ã¯ã€è‹±èªã®å˜èªã¨ã—ã¦é€šç”¨ã™ã‚‹ã€‚\n",
    "\n",
    "* å•ï¼šãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ã—ã¦lemmatizationã‚’ã™ã‚‹ã“ã¨ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16ygP7t1JFZv"
   },
   "outputs": [],
   "source": [
    "# WordNetã‚’è¾æ›¸ã¨ã—ã¦ä½¿ã†lemmatizer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "AieUIjYaJFZ3",
    "outputId": "b9f36af6-5af2-4ebd-b36d-421798f8327c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method lemmatize in module nltk.stem.wordnet:\n",
      "\n",
      "lemmatize(word, pos='n') method of nltk.stem.wordnet.WordNetLemmatizer instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(wnl.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "_ZPcwz44JFZ7",
    "outputId": "a5c72f36-491a-44c7-8251-f33b22d551fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "box\n"
     ]
    }
   ],
   "source": [
    "# åè©\n",
    "print(wnl.lemmatize('cars', 'n'))\n",
    "print(wnl.lemmatize('boxes', 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "KJN-uQ28JFZ_",
    "outputId": "ad38f894-5d98-47f4-a3d9-398f6dc9fb34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "# å‹•è©\n",
    "print(wnl.lemmatize('running', 'v'))\n",
    "print(wnl.lemmatize('ate', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "L0u5uZeoJFaF",
    "outputId": "ec8b25ae-ef5f-4541-c299-fc654e0dd7ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n",
      "fancy\n"
     ]
    }
   ],
   "source": [
    "# å½¢å®¹è©\n",
    "print(wnl.lemmatize('saddest', 'a'))\n",
    "print(wnl.lemmatize('fancier', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "NhKXkdckJFaN",
    "outputId": "22a75d95-37e3-4ef5-b5d0-ac177140f22e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ate\n",
      "fancier\n",
      "fancier\n"
     ]
    }
   ],
   "source": [
    "# æŒ‡å®šã—ãŸå“è©ãŒé–“é•ã£ã¦ã„ã‚‹ã¨ã€ã†ã¾ãã„ã‹ãªã„ã€‚\n",
    "# ï¼ˆå“è©ã‚’å–å¾—ã™ã‚‹æ–¹æ³•ã¯ã€ã™ãå¾Œã§è§£èª¬ã™ã‚‹ã€‚ï¼‰\n",
    "print(wnl.lemmatize('ate', 'n'))\n",
    "print(wnl.lemmatize('fancier', 'v'))\n",
    "print(wnl.lemmatize('fancier'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQ1S2ngz7B84"
   },
   "source": [
    "## 01-10 NLTKã«ã‚ˆã‚‹tokenizationã¨lemmatizationã®çµ„ã¿åˆã‚ã›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0l372SiEJFaU",
    "outputId": "2eb567ed-4466-429e-f138-02154293a66e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'foxes', 'are', 'quick', 'and', 'they', 'are', 'jumping', 'over', 'the', 'sleeping', 'lazy', 'dogs', '!']\n"
     ]
    }
   ],
   "source": [
    "s = 'The brown foxes are quick and they are jumping over the sleeping lazy dogs!'\n",
    "\n",
    "tokens = nltk.word_tokenize(s)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "s1FHAghFJFaX",
    "outputId": "d860770c-1aa2-4901-ed0c-f0bd2127e9af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The brown fox are quick and they are jumping over the sleeping lazy dog !'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ã“ã“ã§ã®lemmatizationã¯ã€å“è©æƒ…å ±ã‚’ä½¿ã£ã¦ã„ãªã„ã®ã§ã€ä¸å®Œå…¨ã€‚ä¸‹ã§ã“ã‚Œã‚’æ”¹è‰¯ã™ã‚‹ã€‚\n",
    "\n",
    "lemmatized_text = ' '.join(wnl.lemmatize(token) for token in tokens)\n",
    "lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d0-fgmbi7E5_"
   },
   "source": [
    "## 01-11 POS Tagging\n",
    "\n",
    "* å•ï¼šå“è©ã®æƒ…å ±ãŒå¿…è¦ã«ãªã‚‹ã®ã¯ã©ã†ã„ã†ã¨ãã‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "UDffFU3gJFaZ",
    "outputId": "a7243111-6789-4ce7-b62a-5a48c9d05205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('brown', 'JJ'), ('foxes', 'NNS'), ('are', 'VBP'), ('quick', 'JJ'), ('and', 'CC'), ('they', 'PRP'), ('are', 'VBP'), ('jumping', 'VBG'), ('over', 'IN'), ('the', 'DT'), ('sleeping', 'VBG'), ('lazy', 'JJ'), ('dogs', 'NNS'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "print(tagged_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9STnRHVt7HRG"
   },
   "source": [
    "### NLTKãŒä¸ãˆã‚‹POSã‚¿ã‚°ã‚’WordNetã®POSã‚¿ã‚°ã«å¤‰æ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2S9kS_xPJFaf"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def pos_tag_wordnet(tagged_tokens):\n",
    "    tag_map = {'j': wordnet.ADJ, 'v': wordnet.VERB, 'n': wordnet.NOUN, 'r': wordnet.ADV}\n",
    "    new_tagged_tokens = [(word, tag_map.get(tag[0].lower(), wordnet.NOUN))\n",
    "                            for word, tag in tagged_tokens]\n",
    "    return new_tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "TbijTK6YJFaj",
    "outputId": "04969ecf-9630-4601-dbde-3ebac768c320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'n'), ('brown', 'a'), ('foxes', 'n'), ('are', 'v'), ('quick', 'a'), ('and', 'n'), ('they', 'n'), ('are', 'v'), ('jumping', 'v'), ('over', 'n'), ('the', 'n'), ('sleeping', 'v'), ('lazy', 'a'), ('dogs', 'n'), ('!', 'n')]\n"
     ]
    }
   ],
   "source": [
    "wordnet_tokens = pos_tag_wordnet(tagged_tokens)\n",
    "print(wordnet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKia_-ov7KLH"
   },
   "source": [
    "## 01-12 NLTKã§lemmatizationï¼ˆå®Œå…¨ç‰ˆï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tNOpTLDTJFal",
    "outputId": "170c7da3-61f3-44e3-f83b-ef7695f10ff9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The brown fox be quick and they be jump over the sleep lazy dog !'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_text = ' '.join(wnl.lemmatize(word, tag) for word, tag in wordnet_tokens)\n",
    "lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9zisZIs1JFan"
   },
   "source": [
    "## æ¼”ç¿’1-2\n",
    "\n",
    "* ä¸Šã®3ã¤ã®ã‚»ãƒ«ã§ãŠã“ãªã£ãŸå‡¦ç†ã‚’ã¾ã¨ã‚ã¦ä¸€ã¤ã®é–¢æ•°ã¨ã—ã¦å®šç¾©ã—ã‚ˆã†ã€‚\n",
    " - é–¢æ•° __`wordnet_lemmatize_text()`__ ã‚’å®šç¾©ã™ã‚‹ã€‚\n",
    " - å…¥åŠ›ã¯å¤‰æ•° __`text`__ ã¨ã—ã€ã“ã‚Œã¯æ–‡å­—åˆ—ã¨ã™ã‚‹ã€‚\n",
    " - ã“ã®é–¢æ•°ã®ãªã‹ã§ã€ã•ãã»ã©å®šç¾©ã—ãŸé–¢æ•°__`pos_tag_wordnet()`__ã‚’ä½¿ã†ã€‚\n",
    " - ãã—ã¦ã€lemmatizeã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡å­—åˆ—å‹ã®å‡ºåŠ›ã¨ã—ã¦è¿”ã™ã‚ˆã†ã«ã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPovRPZb5PVG"
   },
   "outputs": [],
   "source": [
    "# æ¼”ç¿’1-2ã®ç­”æ¡ˆ\n",
    "# def wordnet_lemmatize_text(text):\n",
    "#   ..........\n",
    "\n",
    "\n",
    "\n",
    "#s = 'The brown foxes are quick and they are jumping over the sleeping lazy dogs!'\n",
    "#wordnet_lemmatize_text(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KgQJp2SH7OC_"
   },
   "source": [
    "## 01-13 spaCyã§lemmatization\n",
    "\n",
    "* ä¸Šã®ã‚ˆã†ã«ã€åˆ¥é€”å“è©ã‚’èª¿ã¹ã‚‹å¿…è¦ã¯ãªã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3N2ExlFqJFaw"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en', parse=False, tag=False, entity=False)\n",
    "\n",
    "def spacy_lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ga-E47JKJFaz",
    "outputId": "5f9c3d97-d391-48b1-97c8-05c6d41db872"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The brown foxes are quick and they are jumping over the sleeping lazy dogs!'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'The brown foxes are quick and they are jumping over the sleeping lazy dogs!'\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Bb-PrIeqJFa5",
    "outputId": "dcbcad3f-8c78-4955-82a0-81577584d0e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the brown fox be quick and they be jump over the sleep lazy dog !'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_lemmatize_text(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQsKAXlvJFa7"
   },
   "source": [
    "## 01-14 ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã®é™¤å»\n",
    "\n",
    "* ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã¨ã¯ã€è¨€èªãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹ã«ã‚ãŸã£ã¦ã€éå¸¸ã«é »ç¹ã«ä½¿ã‚ã‚Œã‚‹ãŸã‚å†…å®¹ã®åˆ†æã«ã‚ã¾ã‚Šå½¹ã«ç«‹ãŸãªã„å˜èªã®ã“ã¨ã‚’è¨€ã†ã€‚\n",
    "\n",
    "* ã“ã‚Œã“ããŒè‹±èªã®ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã ï¼ã¨è¨€ãˆã‚‹ã‚ˆã†ãªæ±ºå®šçš„ãªã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆãŒã‚ã‚‹ã‚ã‘ã§ã¯ãªã„ã€‚\n",
    "\n",
    " * ä¸»è¦ãªNLPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã¯ã€ã‚ã‚‰ã‹ã˜ã‚ç”¨æ„ã•ã‚ŒãŸã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆã‚’ä½¿ã†ã“ã¨ãŒã§ãã‚‹ã€‚\n",
    "\n",
    " * ã—ã‹ã—ã€åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦ã€ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹ã“ã¨ã‚‚ã€ã‚ˆãã‚ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "9TaYuRW2AxvE",
    "outputId": "635d38b3-7945-47a5-a359-ab88e8f2742c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'either', 'four', 'yours', 'around', 'hereafter', 'along', 'who', 'has', 'least', 'beside', 'â€˜ll', 'go', 'besides', 'whither', 'whereas', 'â€˜m', 'ours', 'seeming', 'which', 'other', 'were', 'to', 'often', 'rather', 'of', 'quite', 'sixty', 'so', 'nâ€˜t', 'show', 'would', 'anything', 'his', 'nothing', 'since', 'whose', 'as', 'and', 'perhaps', 'somehow', 'otherwise', 'everything', 'keep', 'regarding', 'get', 'was', 'yet', 'call', 'next', 'hundred', 'per', 'whenever', 'he', 'only', 'whoever', 'did', 'sometime', 'it', 'less', 'why', 'seem', 'ca', 'most', 'somewhere', 'â€™re', 'without', 'former', 'still', 'hereupon', 'anyway', 'used', 'again', 'â€™ll', 'across', 'done', 'others', 'much', 'ourselves', 'become', \"'ll\", 'itself', 'that', 'because', 'enough', 'do', 'even', 'more', \"'d\", 'â€™ve', 'have', 'several', 'nowhere', 'none', 'sometimes', 'had', 'being', 'thereby', 'never', 'just', 'whereupon', 'him', 'two', \"'ve\", 'each', 'back', 'hers', 'if', 'also', 'part', 'should', 'anyone', 'thence', 'below', 'into', 'doing', 'noone', 'on', 'onto', 'its', 'another', 'for', 'could', 'will', 'toward', 'neither', 'some', 'well', 'move', 'among', 'with', 'off', 'how', 'â€˜s', 'here', 'third', 'her', 'you', 'formerly', 'few', 'too', 'mine', 'both', 'â€˜re', 'not', 'up', 'hereby', 'something', 'whereby', 'i', 'she', 'really', 'thereafter', 'twenty', 'does', 'are', 'becoming', 'there', 'one', 'those', 'whom', 'must', 'them', 'himself', 'thru', 'where', 'already', 'such', 'until', 'they', 'first', 'moreover', 'elsewhere', 'fifteen', 'although', 'thereupon', 'might', 'take', 'now', 'the', 'â€˜ve', 'whereafter', 'seemed', 'during', 'eleven', 'give', 'six', 'against', 'seems', 'their', 'serious', 'your', 'over', 'about', 'amount', 'throughout', 'behind', 'beforehand', 'in', 'hence', 'herself', 'twelve', 'when', 'therein', 'once', 'themselves', 'due', \"n't\", 'no', 'became', 'be', 'by', 'whatever', 'three', \"'m\", 'â€™m', 'beyond', 'using', 'thus', 'indeed', 'ever', 'us', 'whole', 'this', 'any', 'someone', 'becomes', 'my', 'various', 'own', 'eight', 'while', 're', 'can', 'â€™d', 'wherever', 'top', 'â€˜d', 'â€™s', 'nobody', 'all', 'may', 'above', 'am', 'whether', 'almost', 'latterly', 'therefore', 'made', 'yourself', 'many', 'is', \"'s\", 'empty', 'everywhere', 'however', 'afterwards', 'down', 'towards', 'put', 'or', 'nine', 'further', 'our', 'anyhow', 'alone', 'through', 'before', 'everyone', 'bottom', 'meanwhile', 'at', 'nevertheless', 'name', 'though', 'else', 'upon', 'always', 'five', 'namely', 'than', 'please', 'after', 'side', 'see', 'between', 'whence', 'nâ€™t', 'been', 'via', 'cannot', 'anywhere', 'out', 'fifty', 'myself', 'front', 'nor', 'from', 'forty', 'same', 'amongst', 'unless', 'a', 'say', \"'re\", 'an', 'make', 'under', 'me', 'within', 'latter', 'except', 'what', 'these', 'but', 'ten', 'very', 'together', 'then', 'every', 'full', 'last', 'herein', 'we', 'wherein', 'yourselves', 'mostly'}\n",
      "326\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "print(STOP_WORDS)\n",
    "print(len(STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkJLKKxrJFa7"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def remove_stopwords(text, stopwords=None):\n",
    "    if not stopwords:\n",
    "        stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    tokens = [obj.text for obj in nlp(text)]\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ycusSsPBJFbA",
    "outputId": "f74ffdbd-10b7-4022-b57a-62dd688c93ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The brown foxes are quick and they are jumping over the sleeping lazy dogs!'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'The brown foxes are quick and they are jumping over the sleeping lazy dogs!'\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oWKjTPnzJFbD",
    "outputId": "799934f3-6832-4339-c0f8-0ad9c0c69a6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The brown foxes quick jumping sleeping lazy dogs !'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVfSpyrrCJ63"
   },
   "source": [
    "## 01-99 segmentationã«ã¤ã„ã¦\n",
    "* å›³è¡¨ã¯ä¸‹è¨˜ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚ˆã‚Šã€‚\n",
    " * https://ai.googleblog.com/2020/09/advancing-nlp-with-efficient-projection.html\n",
    "\n",
    "![Segmentation.png](https://raw.githubusercontent.com/tomonari-masada/course-nlp2020/master/Segmentation.png)\n",
    "![inherent_task_complexity.png](https://raw.githubusercontent.com/tomonari-masada/course-nlp2020/master/inherent_task_complexity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wj8RJ6EoCwgp"
   },
   "source": [
    "# èª²é¡Œ1\n",
    "\n",
    "* Wikipediaã®é©å½“ãªè‹±èªã®ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚\n",
    "\n",
    " * é¸ã¶ã®ãŒé¢å€’ã¨ã„ã†æ–¹ã¯AIã®ã‚¨ãƒ³ãƒˆãƒªã§ã‚‚ã©ã†ãã€‚\n",
    "   * https://en.wikipedia.org/wiki/Artificial_intelligence\n",
    "\n",
    "* BeautifulSoupã§æœ¬æ–‡ã®ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã‚’å–å¾—ã™ã‚‹ã€‚\n",
    "\n",
    " * HTMLã®ã‚½ãƒ¼ã‚¹ã‚’è¦‹ã¦ã€ã©ã“ãŒæœ¬æ–‡ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚\n",
    " * ã‚ã‚‹ã„ã¯ã€ãƒãƒƒãƒˆæ¤œç´¢ã‚’ã—ã¦ã€Wikipediaã®ã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰æœ¬æ–‡ã ã‘ã‚’å–å¾—ã™ã‚‹æ–¹æ³•ã‚’èª¿ã¹ã‚‹ã€‚\n",
    "\n",
    "* ä»¥ä¸‹ã®å‰å‡¦ç†ã‚’ã™ã‚‹ã€‚\n",
    "\n",
    " * å¤§æ–‡å­—ã¯å°æ–‡å­—ã«ã™ã‚‹ã€‚ãŸã ã—å›ºæœ‰åè©ã‚’é™¤ãã€‚\n",
    "\n",
    " * ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚’é™¤å»ã™ã‚‹ã€‚\n",
    "\n",
    " * lemmatizationã™ã‚‹ã€‚\n",
    "\n",
    "* å„å˜èªã®å‡ºç¾å›æ•°ã‚’æ±‚ã‚ã€è¡¨ç¤ºã™ã‚‹ã€‚\n",
    "\n",
    "* lemmatizationã—ãŸå¾Œã®å˜èªã‚’ã€å…ƒã®å‡ºç¾é †åºã©ãŠã‚Šã«ã€åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦ã¤ãªãã€é•·ã„ä¸€ã¤ã®æ–‡å­—åˆ—ã«ã™ã‚‹ã€‚\n",
    " * joinãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ãˆã°ã‚ˆã„ã€‚ã¤ã¾ã‚Šã€__`' '.join(`__ lemmatizeã•ã‚ŒãŸå˜èªã®ãƒªã‚¹ãƒˆ __`)`__ ã¨ã„ã†æ„Ÿã˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zDMb9o6cgMg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
