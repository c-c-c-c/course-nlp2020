{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/06_PyTorch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9P3MzvmdrobX"
   },
   "outputs": [],
   "source": [
    "PATH = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgVr8oKj-DJ5"
   },
   "source": [
    "### 実験の再現性確保のための設定\n",
    "* torch.backends.cudnn.deterministicをTrueにするのは、こうしないと、GPU上での計算が毎回同じ値を与えないため。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mf-jw4S8rhTB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "SEED = 123\n",
    "torch.manual_seed(123)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAv8yYt8-Yn0"
   },
   "source": [
    "あらかじめランタイムをGPUに設定しておこう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hl9euZ-P-fiG"
   },
   "source": [
    "### 単語埋め込みデータファイルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WjF1vzSosL5l"
   },
   "outputs": [],
   "source": [
    "texts = dict()\n",
    "labels = dict()\n",
    "for tag in ['train', 'valid', 'test']:\n",
    "  with open(f'{PATH}{tag}.npy', 'rb') as f:\n",
    "    texts[tag] = np.load(f)\n",
    "  with open(f'{PATH}{tag}_labels.npy', 'rb') as f:\n",
    "    labels[tag] = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "uE7RXSjEsWPU",
    "outputId": "715eea78-f378-4a5b-d2e4-fa2620d4bf48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 300)\n",
      "(5000, 300)\n",
      "(25000, 300)\n"
     ]
    }
   ],
   "source": [
    "for tag in ['train', 'valid', 'test']:\n",
    "  print(texts[tag].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7AybiDZ-jvr"
   },
   "source": [
    "### ndarrayをPyTorchのテンソルに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuEe746MtFtr"
   },
   "outputs": [],
   "source": [
    "for tag in ['train', 'valid', 'test']:\n",
    "  texts[tag], labels[tag] = torch.tensor(texts[tag]), torch.tensor(labels[tag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0QVlHKJ-vZn"
   },
   "source": [
    "## 06-02 学習のための準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNOz5rSW-olE"
   },
   "source": [
    "### 定数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Klcm5_AucfM"
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE, EMBED_DIM = texts['train'].shape\n",
    "NUM_CLASS = len(torch.unique(labels['train']))\n",
    "\n",
    "DEV_SIZE = labels['valid'].shape[0]\n",
    "TEST_SIZE = labels['test'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RrkpdhR3vL1_",
    "outputId": "40cf0609-9150-404e-fbce-16d992c52a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 2 20000 5000 25000\n"
     ]
    }
   ],
   "source": [
    "print(EMBED_DIM, NUM_CLASS, TRAIN_SIZE, DEV_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TBR8VZLsq_H"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = texts['train'], labels['train']\n",
    "X_dev, y_dev = texts['valid'], labels['valid']\n",
    "X_test, y_test = texts['test'], labels['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipq2udez-0ez"
   },
   "source": [
    "### データローダの作成\n",
    "* shuffleをTrueにして、毎エポック異なる順で訓練データを見ていくようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfloEv0Osj2n"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iE-wx62k9d3J"
   },
   "source": [
    "## 06-03 モデルの定義と学習の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkRnetIrs9DX"
   },
   "outputs": [],
   "source": [
    "class TextSentiment(nn.Module):\n",
    "  def __init__(self, embed_dim, num_class):\n",
    "    super(TextSentiment, self).__init__()\n",
    "    self.fc1 = nn.Linear(embed_dim, 500)\n",
    "    self.fc2 = nn.Linear(500, 100)\n",
    "    self.fc3 = nn.Linear(100, num_class)\n",
    "    self.init_weights()\n",
    "\n",
    "  def init_weights(self):\n",
    "    initrange = 0.5\n",
    "    self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "    self.fc1.bias.data.zero_()\n",
    "    self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "    self.fc2.bias.data.zero_()\n",
    "    self.fc3.weight.data.uniform_(-initrange, initrange)\n",
    "    self.fc3.bias.data.zero_()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLkGnlqfvQpp"
   },
   "outputs": [],
   "source": [
    "model = TextSentiment(EMBED_DIM, NUM_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRWTIEYy_FKj"
   },
   "source": [
    "### 損失関数とoptimizerとschedulerを作る\n",
    "* 損失関数をGPUに移動させている点に注意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yB0NIxhlxka5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0ko1VZz_Kng"
   },
   "source": [
    "### 訓練用の関数\n",
    "* 前回とほぼ同じ。\n",
    "* データのフォーマットが変わっただけ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHvS00cVvaVU"
   },
   "outputs": [],
   "source": [
    "def train_func():\n",
    "\n",
    "  # Train the model\n",
    "  train_loss = 0\n",
    "  train_acc = 0\n",
    "  for i, (text, cls) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    text, cls = text.to(device), cls.to(device)\n",
    "    output = model(text)\n",
    "    loss = criterion(output, cls)\n",
    "    train_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "  # Adjust the learning rate\n",
    "  scheduler.step()\n",
    "\n",
    "  return train_loss / TRAIN_SIZE, train_acc / TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0ARJYib_M84"
   },
   "source": [
    "### 評価用の関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DDFVMgRqyl4Q"
   },
   "outputs": [],
   "source": [
    "def test(X, y):\n",
    "  loss = 0\n",
    "  acc = 0\n",
    "  data = DataLoader(TensorDataset(X, y), batch_size=BATCH_SIZE)\n",
    "  for text, cls in data:\n",
    "    text, cls = text.to(device), cls.to(device)\n",
    "    with torch.no_grad():\n",
    "      output = model(text)\n",
    "      loss = criterion(output, cls)\n",
    "      loss += loss.item()\n",
    "      acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "  return loss / X.shape[0], acc / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3W9fIHDa9j0P"
   },
   "source": [
    "## 06-04 分類器の訓練と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B_rGEelGzuRO",
    "outputId": "841fdaef-ace2-4732-ed6e-4d445c219ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0065(train)\t|\tAcc: 62.2%(train)\n",
      "\tLoss: 0.0003(dev)\t|\tAcc: 62.3%(dev)\n",
      "Epoch: 2  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0060(train)\t|\tAcc: 68.3%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 76.5%(dev)\n",
      "Epoch: 3  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0058(train)\t|\tAcc: 68.7%(train)\n",
      "\tLoss: 0.0003(dev)\t|\tAcc: 61.0%(dev)\n",
      "Epoch: 4  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0056(train)\t|\tAcc: 71.1%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 71.2%(dev)\n",
      "Epoch: 5  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0054(train)\t|\tAcc: 72.1%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 72.2%(dev)\n",
      "Epoch: 6  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0052(train)\t|\tAcc: 74.0%(train)\n",
      "\tLoss: 0.0003(dev)\t|\tAcc: 63.5%(dev)\n",
      "Epoch: 7  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0051(train)\t|\tAcc: 75.1%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 75.2%(dev)\n",
      "Epoch: 8  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0049(train)\t|\tAcc: 76.3%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 81.8%(dev)\n",
      "Epoch: 9  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0047(train)\t|\tAcc: 77.8%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 74.0%(dev)\n",
      "Epoch: 10  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0046(train)\t|\tAcc: 78.3%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 82.7%(dev)\n",
      "Epoch: 11  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0045(train)\t|\tAcc: 79.5%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 77.5%(dev)\n",
      "Epoch: 12  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0044(train)\t|\tAcc: 79.4%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 69.0%(dev)\n",
      "Epoch: 13  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0042(train)\t|\tAcc: 81.1%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 83.4%(dev)\n",
      "Epoch: 14  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0041(train)\t|\tAcc: 81.3%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 83.0%(dev)\n",
      "Epoch: 15  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0040(train)\t|\tAcc: 82.3%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 83.7%(dev)\n",
      "Epoch: 16  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0040(train)\t|\tAcc: 82.2%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 83.7%(dev)\n",
      "Epoch: 17  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0039(train)\t|\tAcc: 82.6%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 81.6%(dev)\n",
      "Epoch: 18  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0039(train)\t|\tAcc: 82.9%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 83.8%(dev)\n",
      "Epoch: 19  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0039(train)\t|\tAcc: 83.0%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 83.9%(dev)\n",
      "Epoch: 20  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0038(train)\t|\tAcc: 83.2%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 83.9%(dev)\n",
      "Epoch: 21  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0038(train)\t|\tAcc: 83.4%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 83.4%(dev)\n",
      "Epoch: 22  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0038(train)\t|\tAcc: 83.3%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 83.9%(dev)\n",
      "Epoch: 23  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0038(train)\t|\tAcc: 83.5%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 84.3%(dev)\n",
      "Epoch: 24  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0038(train)\t|\tAcc: 83.7%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 84.4%(dev)\n",
      "Epoch: 25  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0038(train)\t|\tAcc: 83.7%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 84.4%(dev)\n",
      "Epoch: 26  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0038(train)\t|\tAcc: 83.8%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.4%(dev)\n",
      "Epoch: 27  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0038(train)\t|\tAcc: 83.7%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.3%(dev)\n",
      "Epoch: 28  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 83.8%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.2%(dev)\n",
      "Epoch: 29  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
      "Epoch: 30  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 84.4%(dev)\n",
      "Epoch: 31  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 83.9%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.4%(dev)\n",
      "Epoch: 32  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 83.9%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
      "Epoch: 33  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 83.9%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 84.6%(dev)\n",
      "Epoch: 34  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
      "Epoch: 35  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.0%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
      "Epoch: 36  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.1%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
      "Epoch: 37  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.1%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.7%(dev)\n",
      "Epoch: 38  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.1%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
      "Epoch: 39  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.4%(dev)\n",
      "Epoch: 40  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.1%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.3%(dev)\n",
      "Epoch: 41  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.7%(dev)\n",
      "Epoch: 42  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
      "Epoch: 43  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.1%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.7%(dev)\n",
      "Epoch: 44  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.3%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
      "Epoch: 45  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
      "Epoch: 46  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.3%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.5%(dev)\n",
      "Epoch: 47  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
      "Epoch: 48  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
      "Epoch: 49  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.3%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.6%(dev)\n",
      "Epoch: 50  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 84.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 84.7%(dev)\n"
     ]
    }
   ],
   "source": [
    "max_valacc_sgd = 0\n",
    "import time\n",
    "\n",
    "N_EPOCHS = 50\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "  start_time = time.time()\n",
    "  train_loss, train_acc = train_func()\n",
    "  dev_loss, dev_acc = test(X_dev, y_dev)\n",
    "\n",
    "  secs = int(time.time() - start_time)\n",
    "  mins = secs / 60\n",
    "  secs = secs % 60\n",
    "\n",
    "  print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "  print(f'\\tLoss: {dev_loss:.4f}(dev)\\t|\\tAcc: {dev_acc * 100:.1f}%(dev)')\n",
    "\n",
    "  if max_valacc_sgd < dev_acc:\n",
    "    max_valacc_sgd = dev_acc\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "UbG7hxf70Ggf",
    "outputId": "945c88f7-2ab8-471e-be17-366b8fe1a70d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset...\n",
      "\tLoss: 0.0000(test)\t|\tAcc: 83.6%(test)\n",
      "max_valacc 0.8472\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset...')\n",
    "test_loss, test_acc = test(X_test, y_test)\n",
    "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')\n",
    "\n",
    "\n",
    "print(\"max_valacc\", max_valacc_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUzVkJ2v-tt_"
   },
   "source": [
    "# 課題6\n",
    "* モデルやoptimizerやschedulerを変更して、dev setの分類性能をできるだけ向上させてみよう。\n",
    "* その後、自分で選択した設定を使って、最終的にtest setで評価しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLkGnlqfvQpp"
   },
   "outputs": [],
   "source": [
    "model = TextSentiment(EMBED_DIM, NUM_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0079(train)\t|\tAcc: 77.0%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 84.9%(dev)\n",
      "Epoch: 2  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 83.8%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 83.3%(dev)\n",
      "Epoch: 3  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0037(train)\t|\tAcc: 83.9%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.7%(dev)\n",
      "Epoch: 4  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0036(train)\t|\tAcc: 84.4%(train)\n",
      "\tLoss: 0.0002(dev)\t|\tAcc: 84.7%(dev)\n",
      "Epoch: 5  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0035(train)\t|\tAcc: 85.0%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.0%(dev)\n",
      "Epoch: 6  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0035(train)\t|\tAcc: 84.8%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.7%(dev)\n",
      "Epoch: 7  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0034(train)\t|\tAcc: 85.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 8  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0033(train)\t|\tAcc: 85.7%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.6%(dev)\n",
      "Epoch: 9  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0033(train)\t|\tAcc: 85.7%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 10  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0033(train)\t|\tAcc: 85.9%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.2%(dev)\n",
      "Epoch: 11  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0033(train)\t|\tAcc: 86.1%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 12  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0032(train)\t|\tAcc: 86.6%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.2%(dev)\n",
      "Epoch: 13  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0031(train)\t|\tAcc: 86.7%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.1%(dev)\n",
      "Epoch: 14  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0031(train)\t|\tAcc: 86.8%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 15  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0031(train)\t|\tAcc: 86.7%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 16  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0031(train)\t|\tAcc: 86.9%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 17  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0030(train)\t|\tAcc: 87.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.1%(dev)\n",
      "Epoch: 18  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0030(train)\t|\tAcc: 87.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.1%(dev)\n",
      "Epoch: 19  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0030(train)\t|\tAcc: 87.3%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.7%(dev)\n",
      "Epoch: 20  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0030(train)\t|\tAcc: 87.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.6%(dev)\n",
      "Epoch: 21  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0029(train)\t|\tAcc: 87.7%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.4%(dev)\n",
      "Epoch: 22  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0029(train)\t|\tAcc: 87.9%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.3%(dev)\n",
      "Epoch: 23  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0029(train)\t|\tAcc: 87.8%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 24  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0028(train)\t|\tAcc: 88.0%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 25  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0028(train)\t|\tAcc: 88.1%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 26  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0028(train)\t|\tAcc: 88.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.3%(dev)\n",
      "Epoch: 27  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0028(train)\t|\tAcc: 88.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.3%(dev)\n",
      "Epoch: 28  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0027(train)\t|\tAcc: 88.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.2%(dev)\n",
      "Epoch: 29  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0027(train)\t|\tAcc: 88.6%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 30  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0027(train)\t|\tAcc: 88.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.1%(dev)\n",
      "Epoch: 31  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0027(train)\t|\tAcc: 88.6%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.3%(dev)\n",
      "Epoch: 32  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0027(train)\t|\tAcc: 88.6%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.3%(dev)\n",
      "Epoch: 33  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0027(train)\t|\tAcc: 88.8%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.5%(dev)\n",
      "Epoch: 34  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0027(train)\t|\tAcc: 88.9%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.4%(dev)\n",
      "Epoch: 35  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.0%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.2%(dev)\n",
      "Epoch: 36  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.0%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 37  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.0%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.1%(dev)\n",
      "Epoch: 38  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.0%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.1%(dev)\n",
      "Epoch: 39  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.2%(dev)\n",
      "Epoch: 40  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.1%(dev)\n",
      "Epoch: 41  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 42  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 43  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.2%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 44  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.3%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 45  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.3%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 46  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 47  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0026(train)\t|\tAcc: 89.3%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 48  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 49  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 50  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.3%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 51  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 52  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 53  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 54  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 55  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 56  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 86.0%(dev)\n",
      "Epoch: 57  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.4%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 58  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 59  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 60  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 61  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 62  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 63  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 64  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 65  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 66  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 67  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 68  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 69  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.6%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 71  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 72  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 73  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 74  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.9%(dev)\n",
      "Epoch: 75  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 76  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 77  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 78  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 79  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.6%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 80  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 81  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 82  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 83  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.6%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 84  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 85  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 86  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.6%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 87  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 88  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.6%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 89  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 90  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 91  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 92  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.6%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 93  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 94  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 95  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 96  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 97  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 98  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 99  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n",
      "Epoch: 100  | time in 0 minutes, 0 seconds\n",
      "\tLoss: 0.0025(train)\t|\tAcc: 89.5%(train)\n",
      "\tLoss: 0.0001(dev)\t|\tAcc: 85.8%(dev)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "max_valacc_adam = 0\n",
    "\n",
    "N_EPOCHS = 100\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "  start_time = time.time()\n",
    "  train_loss, train_acc = train_func()\n",
    "  dev_loss, dev_acc = test(X_dev, y_dev)\n",
    "\n",
    "  secs = int(time.time() - start_time)\n",
    "  mins = secs / 60\n",
    "  secs = secs % 60\n",
    "  if max_valacc_adam < dev_acc:\n",
    "    max_valacc_adam = dev_acc\n",
    "    \n",
    "\n",
    "  print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "  print(f'\\tLoss: {dev_loss:.4f}(dev)\\t|\\tAcc: {dev_acc * 100:.1f}%(dev)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset...\n",
      "\tLoss: 0.0000(test)\t|\tAcc: 85.3%(test)\n",
      "max_valacc 0.8582\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset...')\n",
    "test_loss, test_acc = test(X_test, y_test)\n",
    "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')\n",
    "print(\"max_valacc\", max_valacc_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam の方が最終的な精度が良い。\n",
    "\n",
    "イテレーションの中の最大のvalの値で、\n",
    "sgd：0.8472　　Adam:0.8582\n",
    "\n",
    "また、adamの場合、1epochから84.9という結果が出た。(sgdは62.3%)\n",
    "収束が早いという性質も伺える。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM7urZRTQx38TelXDB15lg+",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1Ju5Lc6g45t9qjI0R2cFUAA1wHBFm2IeB",
   "name": "06_PyTorch_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
