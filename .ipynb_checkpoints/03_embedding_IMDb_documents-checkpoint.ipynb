{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 fastTextのword embeddingsを使ってみる\n",
    "* このnotebookは、Google Colabではなく、手元の環境で動かすことを想定しています。\n",
    " * Google Colabで動かすとかなり時間がかかると思います。\n",
    "* 必要ならば、このnotebookを実行する前に、condaの環境を作っておきましょう。\n",
    "\n",
    "`$ conda create -n D_wordvec`\n",
    "\n",
    "`$ source activate D_wordvec`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03-01 fastTextをインストールする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /opt/conda/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from fasttext) (45.2.0.post20200209)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fasttext) (1.18.1)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.7/site-packages (from fasttext) (2.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Word vectors for 157 languages\"から英語データをダウンロード\n",
    "* fastTextのドキュメント https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "* 論文 https://arxiv.org/abs/1802.06893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fasttext.util' has no attribute 'download_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9e3af40e0339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fasttext.util' has no attribute 'download_model'"
     ]
    }
   ],
   "source": [
    "import fasttext.util\n",
    "\n",
    "fasttext.util.download_model('en', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03-02 IMDbデータセットをダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本家のサイトからダウンロード\n",
    "* 方法は他にもあるが、ここでは本家サイトから直にダウンロードする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar zxf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ml-datasetsをインストール\n",
    "* https://pypi.org/project/ml-datasets/\n",
    "* 機械学習のデータセットのローダ。IMDbも簡単に扱える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ml-datasets in /Users/masada/opt/anaconda3/envs/D_wordvec/lib/python3.8/site-packages (0.1.6)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=1.0.1 in /Users/masada/opt/anaconda3/envs/D_wordvec/lib/python3.8/site-packages (from ml-datasets) (1.0.2)\r\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Users/masada/opt/anaconda3/envs/D_wordvec/lib/python3.8/site-packages (from ml-datasets) (1.19.1)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/masada/opt/anaconda3/envs/D_wordvec/lib/python3.8/site-packages (from ml-datasets) (4.48.2)\r\n",
      "Requirement already satisfied: catalogue<3.0.0,>=0.2.0 in /Users/masada/opt/anaconda3/envs/D_wordvec/lib/python3.8/site-packages (from ml-datasets) (1.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ml-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastTextの単語ベクトルを読み込む\n",
    "* さきほどダウンロードし、解凍しておいたものを読み込む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# loading cc.en.300.bin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "model_path = 'cc.en.300.bin'\n",
    "print(f'# loading {model_path} ...', flush=True) \n",
    "ft = fasttext.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDbデータセットを読み込む\n",
    "* 本家サイトからダウンロードし、解凍しておいたものを、ml_datasetsを使って読み込む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_datasets import imdb\n",
    "\n",
    "train_valid_data, test_data = imdb(loc='./aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Some people say Steve Irwin\\'s larrikin antics and gregarious personality are only an act. Watch this film: it\\'s obvious he can\\'t act.\\n\\n\\n\\nSteve Irwin, dangerman star of the small screen in his *Crocodile Hunter Diaries*, *Croc Files* and eponymous *Crocodile Hunter* series (you see a naming trend here, or is it just me?), rockets his larger-than-strife persona to the big screen with *Crocodile Hunter: Collision Course* (yup \\x96 there\\'s a definite trend of words beginning with \\'C\\') - basically an episode of *Crocodile Hunter* mashed together with a B-Movie.\\n\\n\\n\\nOn a mission to relocate a big croc to save it from being shot by an eccentric farmer (Magda Szubanski), Steve and wife Terri are unaware that the croc is being tracked by American spies (Lachy Hulme and Kenneth Ransom), out to recover a spy satellite beacon it has swallowed. Will it hurt my credibility to say \"They\\'re on a Collision Course with Wackiness\"? (what credibility? - Ed note.)\\n\\n\\n\\nThe plot is irrelevant, as it is Steve\\'s animal magnetism that propels the film. If you find his persona trying, the film is a failure, but if you\\'re a fan of either him (as a businessman, conservationist or just plain ass-klown) or his television shows, expect more of the same on a wide-screen budget.\\n\\n\\n\\nJohn Stainton, faithful liege, best mate and helmer of the Crocodile Hunter *oeuvre* (can it be called that with a straight face?), writes and directs with the same provincial swagger that made Steve a household wildlife jester.\\n\\n\\n\\nThe most jarring aspect of this movie is that Steve (one of the few people for whom you can actually hear the exclamation points going by as he speaks) and Terri (Steve\\'s spouse of 10 years, fiercest ally and closest friend) treat it like it IS one of their documentaries, breaking the \"fourth wall\" and speaking directly to the camera, whilst all the other characters behave as if they\\'re in a bad movie (well\\x85). It wouldn\\'t be so incongruous if Steve and Terri were kept separated from the rest of the characters \\x96 but when the Bad Americans constantly threaten Steve\\'s life, we Confused Viewers must ask ourselves why the indifferent camera crew doesn\\'t at least call the cops if not try to poke the bad guys in the eye with the boom mics, or run screaming into the bush \\x96 anything but continue filming casually with great lighting, crisp audio and seven action angles. \\n\\n\\n\\nWhile Terri is unfairly painted as Steve\\'s mildly incompetent sidekick (her acting consists of boldly inept line reads and gadding about in pear-shaped-buttock-hugging jeans - for the last, I\\'m not complaining), Steve goes about his business-as-usual of show-and-tell with creatures intent on killing him, doing all his stunts himself because, well, to him they\\'re not really stunts, just a Day At The Office. \\n\\n\\n\\nOf course, watching this madman\\'s koo-koo adventures after his tragic death in September 2006 casts a strange detachment over the proceedings. But to those of us who never met him, this kind of malarkey (as well as various incarnations of the *Crocodile Hunter* series in constant re-runs) keeps him as alive as ever in our crocodile burrows. The wrenching reality of his absence will only be apparent to those nearest him. And I truly wish them the best in following in his outsize footprints\\x85 \\n\\n\\n\\nSo enjoy this diversion for what it is \\x96 a half-baked movie featuring a full-on legend. He died doing what he loved \\x96 interacting with wildlife - and he could never have asked for more of his first feature film in portraying him doing just that.\\n\\n\\n\\n(Movie Maniacs, visit: poffysmoviemania.com)',\n",
       "  0),\n",
       " ('Acting is horrible. This film makes Fast and Furious look like an academy award winning film. They throw a few boobs and butts in there to try and keep you interested despite the EXTREMELY weak and far fetched story. There is a reason why people on the internet aren\\'t even downloading this movie. This movie sunk like an iron turd. DO NOT waste your time renting or even downloading it. This film is and always will be a PERMA-TURD. I am now dumber for having watched it. In fact this title should be referred to as a \"PERMA-TURD\" from now on. Calling it a film is a travesty and insult. abhorrent, abominable, appalling, awful, beastly, cruel, detestable, disagreeable, disgusting, dreadful, eerie, execrable, fairy, fearful, frightful, ghastly, grim, grisly, gruesome, heinous, hideous, horrendous, horrid, loathsome, lousy, lurid, mean, nasty, obnoxious, offensive, repellent, repulsive, revolting, scandalous, scary, shameful, shocking, sickie, terrible, terrifying, ungodly, unholy, unkind',\n",
       "  0),\n",
       " (\"The Fallen Ones starts with archaeologist Matt Fletcher (Casper Van Dien) in the desert discovering the mummified remains of a 42 foot tall giant, now there's something you don't see everyday. Matt is working for property developer Morton (Robert Wagner) who wants to build a holiday resort on the land & he calls in fellow archaeologist Angela (Kristen Miller) for reasons I'm unsure of. Anyway they both try to figure out what they've got on they're hands when some of the team go missing, Morton calls in security guy Ammon (Navid Negahban) to handle the situation. Meanwhile ancient text translator the Rabbi Eli Schmidtt (Tom Bosley) translates some ancient text (as he would) & is shocked to learn of a evil prophecy in which these giants will rise up & take over the world for the Fallen One, or something like that. It's up to Matt to save the day & the whole planet...\\n\\n\\n\\nWritten & directed by Kevin VanHook, who also has a small role in the film as the ancient warrior leader at the start, I personally thought The Fallen Ones was a terrible film & it's as simple & straight forward as that. There are so many things that are just plain bad about The Fallen Ones both on a technical & conceptual level, the script doesn't make a whole lot of sense & it doesn't really get going until the final 20 odd minutes by which time I had almost lost the will to live. The character's are awful & as clichéd as you like, the dialogue is bad as in very, very bad & the entire film is predictable, I mean it's not going to come as a surprise that Casper Van Dien is going to save the day is it? It's not a huge surprise that the mummified giant is going to come back to life either so why wait until over an hour into the film when most of the audience will be in some sort of comatose state. This is bad, very bad. You have been warned.\\n\\n\\n\\nDirector VanHook doesn't impress, the fight scenes are absolutely awful & why dress your bad guys up in a horrible shade of purple? They look naff. To give it a bit of credit the special effects on the giant Mummy itself are actually good although there's not that many of them since he doesn't make an appearance for over an hour, there are also some normal sized Mummy's that look to have come straight from the set of The Mummy (1999), unfortunately these aren't used to any great effect & in fact are wasted as some comic relief. The mechanical Mummy was a pretty good idea but looked silly & there is no way on Earth that all those people inside could work in sync with each other to operate it, actually the more I think about the more ridiculous the idea is. Forget about any scares, tension or atmosphere & don't even think about any gore or violence because there isn't any.\\n\\n\\n\\nTechnically The Fallen Ones isn't anything special & apart from the impressive giant Mummy effects there's little her to get excited about. The ghost CGI & water effects are terrible, it was made-for-TV & it's shows. The acting was poor, Wagner looks embarrassed & this is probably the only thing the likes of Dien & Bosley can get these days.\\n\\n\\n\\nThe Fallen Ones is a bad film, there's no two ways about it as far as I'm concerned. Not recommended on any level or in any way, one to avoid.\",\n",
       "  0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テキスト部分と0/1ラベル部分に分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_texts, train_valid_labels = zip(*train_valid_data)\n",
    "test_texts, test_labels = zip(*test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストセット以外をランダムにシャッフル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "random.shuffle(train_valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手動で訓練データと検証データへ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(train_valid_data) * 0.8)\n",
    "train_texts, train_labels = train_valid_texts[:split], train_valid_labels[:split]\n",
    "valid_texts, valid_labels = train_valid_texts[split:], train_valid_labels[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 20000 training, 5000 validation, and 25000 test docs\n"
     ]
    }
   ],
   "source": [
    "print(f'# {len(train_texts)} training, {len(valid_texts)} validation, and {len(test_texts)} test docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    'train': (train_texts, train_labels),\n",
    "    'valid': (valid_texts, valid_labels),\n",
    "    'test': (test_texts, test_labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全文書のembeddingを得てファイルに保存\n",
    "* fastTextのget_sentence_vectorを使って文書のベクトル表現を得る。\n",
    "* 全文書のベクトル表現をndarrayに変換、`.npy`形式で保存\n",
    "* 全文書のラベルもndarrayに変換、`.npy`形式で保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train set: ---------*---------*\n",
      "# valid set: -----\n",
      "# test set: ---------*---------*-----\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for tag in splits:\n",
    "    print(f'# {tag} set: ', end='', flush=True)\n",
    "    cnt = 0\n",
    "    X = list()\n",
    "    for text in splits[tag][0]:\n",
    "        vec = ft.get_sentence_vector(' '.join(text.split('\\n')))\n",
    "        X.append(vec)\n",
    "        cnt += 1\n",
    "        if cnt % 10000 == 0: print('*', end='', flush=True)\n",
    "        elif cnt % 1000 == 0: print('-', end='', flush=True)\n",
    "    X = np.array(X)\n",
    "    with open(f'{tag}.npy', 'wb') as f:\n",
    "        np.save(f, X, allow_pickle=False)\n",
    "    with open(f'{tag}_labels.npy', 'wb') as f:\n",
    "        np.save(f, np.array(splits[tag][1]), allow_pickle=False)\n",
    "    print(flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 masada  staff  30000128  8 20 17:26 test.npy\r\n",
      "-rw-r--r--  1 masada  staff    200128  8 20 17:26 test_labels.npy\r\n",
      "-rw-r--r--  1 masada  staff  24000128  8 20 17:26 train.npy\r\n",
      "-rw-r--r--  1 masada  staff    160128  8 20 17:26 train_labels.npy\r\n",
      "-rw-r--r--  1 masada  staff   6000128  8 20 17:26 valid.npy\r\n",
      "-rw-r--r--  1 masada  staff     40128  8 20 17:26 valid_labels.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al *.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
