{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/07_document_classification_20201219.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_0ZZ8bo1mgH"
   },
   "source": [
    "# 07 単語埋め込みを使った文書分類\n",
    "* 今回も、IMDbデータセットの感情分析を文書分類問題として解く。\n",
    "* ただし今回は、fastTextのような学習済みの単語埋め込みは使わない。\n",
    "* 単語埋め込み自体の学習も、ネットワークの学習と同時におこなう。\n",
    "* IMDbデータの準備も、`torch.torchtext`を使っておこなう。\n",
    " * つまりすべてをPyTorchのなかでおこなう。\n",
    "* 参考資料\n",
    " * https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
    " * https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n",
    " * https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyjU004LNbMt"
   },
   "source": [
    "## データをどう扱うか\n",
    "* ネットワークへの入力は、単語埋め込みを、単語の出現順どおりに並べた列にする。\n",
    " * ミニバッチは[ミニバッチのなかでの最大文書長, ミニバッチのサイズ, 単語埋め込み次元数]という形の3階のテンソルになる。\n",
    "* そして、前向き計算のなかではじめて、単語埋め込みの平均をとることにする。\n",
    " * `.mean(0)`と、軸0で平均をとることになる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_puYg6Zi8x3"
   },
   "source": [
    "## 07-00 Google Colabのランタイムのタイプを変更する\n",
    "* Google ColabのランタイムのタイプをGPUに変更しておこう。\n",
    " * 上のメニューの「ランタイム」→「ランタイムのタイプを変更」→「ハードウェア　アクセラレータ」から「GPU」を選択"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLEeO0fw23Xp"
   },
   "source": [
    "## 07-01 torchtextを使ってIMDbデータを読み込む\n",
    "* ここでIMDbデータセットの読み込みにつかう`torchtext.datasets`については、下記を参照。\n",
    " * https://torchtext.readthedocs.io/en/latest/datasets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go7epLZe3JmF"
   },
   "source": [
    "### 実験の再現性確保のための設定など\n",
    "* https://pytorch.org/docs/stable/notes/randomness.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG']=\":4096:8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6nSqNzof1lTJ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.data import Field, LabelField, BucketIterator\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.set_deterministic(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y1_GyXg22f6"
   },
   "source": [
    "### torchtextのフィールド\n",
    "* TEXTフィールドと、LABELフィールドという２種類のFieldオブジェクトのインスタンスを作る。\n",
    " * Fieldクラスの詳細については[ここ](https://github.com/pytorch/text/blob/master/torchtext/data/field.py)を参照。\n",
    "* TEXTフィールドは、テキストの前処理の仕方を決めておくのに使う。\n",
    " * tokenizerは、デフォルトでは単にstring型のsplitメソッドを適用するだけになる。これは高速だが、tokenizationとしては雑。\n",
    "* LABELフィールドは、ラベルの前処理に使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qjq8oooE2uQY"
   },
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize=\"spacy\")\n",
    "LABEL = LabelField()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtEq23GS3Vxl"
   },
   "source": [
    "### IMDbデータセットをダウンロードした後、前処理しつつ読み込む\n",
    "* ダウンロードはすぐ終わるが、解凍に少し時間がかかる。\n",
    "* また、TEXTフィールドでspaCyのtokenizationを使うように設定したので、少し時間がかかる。\n",
    " * string型のsplitメソッドでtokenizeすると、時間はあまりかからない。（そのかわり、やや雑なtokenizationになる。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzgVXf3G3YPI",
    "outputId": "47f6bae8-d0d0-4929-8874-151832e32ae3"
   },
   "outputs": [],
   "source": [
    "train_valid_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0sltPjT3j36"
   },
   "source": [
    "### 最初の文書を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrXwYMVH3orf",
    "outputId": "a2954d89-3907-4d00-99d6-f289e84e5fa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'disagree', 'strongly', 'with', 'anyone', 'who', 'might', 'dismiss', 'this', 'film', 'as', '\"', 'just', '\"', 'entertainment', '.', 'Set', 'right', 'after', 'the', 'carefree', ',', 'roaring', '20s', ',', 'during', 'the', 'early', 'days', 'of', 'the', 'Great', 'Depression', ',', 'Dance', ',', 'Fools', ',', 'Dance', 'is', 'at', 'its', 'heart', 'an', 'earnest', 'cautionary', 'tale', ',', 'with', 'a', 'clear', 'message', 'about', 'how', 'best', 'to', 'endure', 'these', 'hard', 'times', '.', 'Yet', 'this', 'fast', '-', 'paced', 'and', 'tightly', '-', 'plotted', 'film', 'is', 'far', 'from', 'being', 'a', 'dreary', 'morality', 'tale.<br', '/><br', '/>In', 'the', '30s', ',', 'Hollywood', 'had', 'a', 'knack', 'for', 'churning', 'out', 'one', 'entertaining', '*', 'and', '*', 'enlightening', 'audience', '-', 'pleaser', 'after', 'another', ',', 'all', 'without', 'wasting', 'a', 'frame', 'of', 'film', '.', 'Dance', ',', 'Fools', ',', 'Dance', '--', 'one', 'of', '*', 'four', '*', 'films', 'that', 'Harry', 'Beaumont', 'directed', 'in', '1931', '--', 'is', 'barely', '80', 'minutes', 'long', ',', 'yet', 'its', 'characters', 'are', 'well', 'developed', ',', 'its', 'story', 'never', 'seems', 'rushed', ',', 'and', 'despite', 'its', 'many', 'twists', 'in', 'plot', ',', 'the', 'audience', 'is', 'never', 'left', 'behind.<br', '/><br', '/>With', 'the', 'lone', 'exception', 'of', 'Lester', 'Vail', 'as', 'flaccid', 'love', 'interest', 'Bob', 'Townsend', ',', 'the', 'supporting', 'cast', 'is', 'uniformly', 'strong', '.', 'Worthy', 'of', 'note', 'are', 'William', 'Bakewell', 'as', 'Crawford', \"'s\", 'brother', ',', 'Cliff', 'Edwards', '(', 'best', 'known', 'as', 'the', 'voice', 'of', 'Jiminy', 'Cricket', ')', 'as', 'reporter', 'Bert', 'Scranton', ',', 'and', 'Clark', 'Gable', 'in', 'an', 'early', 'supporting', 'role', 'as', 'gangster', 'Jake', 'Luva.<br', '/><br', '/>But', 'this', 'is', 'Joan', 'Crawford', \"'s\", 'film', ',', 'and', 'she', 'absolutely', 'shines', 'in', 'it', '.', 'Made', 'when', 'she', 'was', 'just', '27', ',', 'this', 'lesser', '-', 'known', 'version', 'of', 'Crawford', 'will', 'probably', 'be', 'unrecognizable', 'to', 'those', 'more', 'familiar', 'with', 'her', 'later', 'work', '.', 'However', ',', 'here', 'is', 'proof', 'that', 'long', 'before', 'she', 'took', 'home', 'an', 'Oscar', 'for', 'Mildred', 'Pierce', ',', 'Crawford', 'was', 'a', 'star', 'in', 'the', 'true', 'sense', 'of', 'the', 'word', ',', 'a', 'terrific', 'actress', 'with', 'the', 'charisma', 'to', 'carry', 'a', 'picture', 'all', 'by', 'herself.<br', '/><br', '/>Score', ':', 'EIGHT', 'out', 'of', 'TEN']\n"
     ]
    }
   ],
   "source": [
    "print(train_valid_data[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRMuAOum3rB5",
    "outputId": "8d8f54a2-fb21-403c-d2f3-af8d955f55e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "print(train_valid_data[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgZgQbyD3u9D"
   },
   "source": [
    "### テストセット以外の部分を訓練データと検証データに分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h2FtnEKZ32hM"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_valid_data.split(split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fzsi9ZC36eR",
    "outputId": "81f00aaa-a794-47a7-a60c-60fa51b1540a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 20000\n",
      "Number of validation examples: 5000\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsLNP7pGaNtp",
    "outputId": "37f2e0ec-3b55-4788-e125-73535256d878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'one', 'of', 'the', 'greatest', 'child', '-', 'pet', 'movies', 'ever', 'created', '.', 'I', 'cry', 'every', 'time', 'I', 'see', 'Shadow', 'yelling', '\"', 'Wait', ',', 'wait', 'for', 'me', 'Peter', '!', '\"', 'as', 'the', 'family', 'car', 'is', 'pulling', 'away', '.', 'This', 'is', 'a', 'must', 'see', 'if', 'you', 'love', 'animals', '!', 'Best', 'Movie', 'Ever', '!', 'The', 'lines', 'in', 'the', 'movie', 'are', 'sometimes', 'stupid', '.', 'Like', 'when', 'Sassy', 'says', 'to', 'Chance', ';', '\"', 'Cat', \"'s\", 'Rule', 'and', 'dogs', 'drool', '!', '\"', 'Lines', 'like', 'this', 'I', 'could', 'do', 'without', ',', 'but', 'when', 'I', 'was', 'six', 'I', 'bet', 'I', 'loved', 'that', 'line', '.', 'The', 'storyline', 'may', 'seem', 'hooky', 'to', 'some', ',', 'but', 'I', 'like', 'it', '.', 'Shadow', 'as', 'the', 'older', 'dog', 'who', \"'s\", 'preparing', 'Chance', 'to', 'take', 'over', 'for', 'him', 'when', 'he', \"'s\", 'gone', 'is', 'really', 'moving', 'when', 'you', 'think', 'about', 'it', '.', 'It', 'reminded', 'me', 'of', 'my', 'childhood', 'dog', '.', 'I', 'think', 'everyone', 'can', 'find', 'a', 'piece', 'of', 'themselves', 'in', '\"', 'Homeward', 'Bound', '.', '\"']\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oXz2lvB37Vm"
   },
   "source": [
    "### データセットの語彙とラベルを作る\n",
    "* TEXTラベルのほうでは、最大語彙サイズを指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DBQeD7yC37x4"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000 # この値は適当。\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iv6RSh3HmLf"
   },
   "source": [
    "なぜ語彙サイズが25,000ではなく25,002なのかについては、少し下の説明を参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWuYQthC4Ml8",
    "outputId": "df6b1579-ce16-474e-c847-a00d49777d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lW4eR-K44Rba"
   },
   "source": [
    "### 出現頻度順で上位２０単語を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jan98ffr4PXP",
    "outputId": "e89114cd-c26b-4d03-9d70-70d6ab4a67a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 231466), (',', 220572), ('.', 189097), ('a', 125017), ('and', 125012), ('of', 114875), ('to', 106992), ('is', 87340), ('in', 70294), ('I', 61900), ('it', 61164), ('that', 56231), ('\"', 50199), (\"'s\", 49490), ('this', 48385), ('-', 42420), ('/><br', 40924), ('was', 40198), ('as', 34764), ('with', 34223)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKQojOuv4Z38"
   },
   "source": [
    "### 単語ID順に最初の１０単語を見てみる\n",
    "* IDのうち、0と1は、未知語とパディング用の単語という特殊な単語に割り振られている。\n",
    " * 未知語は`<unk>`という特殊な単語に置き換えられる。これのIDが0。\n",
    " * パディングとは、長さが不揃いの複数の文書を同じミニバッチにまとめるとき、すべての文書の長さを無理やりそろえるため、文書末尾に特殊な単語（元々の語彙にない、人工的に用意した単語）を追加すること。\n",
    " * パディング用の単語が`<pad>`になっているのは、上のほうで使ったFieldクラスのインスタンスを作るときのデフォルトの値がこの`<pad>`になっているため。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlhXRT3g4Xad",
    "outputId": "213b6de8-b2f1-479f-f241-edf711760b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vJfHTdR4qd4"
   },
   "source": [
    "### ラベルのほうのIDを確認する\n",
    "* こちらはnegとposに対応する２つのIDしかない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vI7Pz_6R4bYM",
    "outputId": "6f013d10-164d-437b-924e-187bc4b5210b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14_znTjp4w5s"
   },
   "source": [
    "### ミニバッチを取り出すためのiteratorを作る\n",
    "* ミニバッチのサイズを指定する。\n",
    " * ミニバッチのサイズは、性能を出すためにチューニングすべきハイパーパラメータのひとつ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cUED86Jb4tUy"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator = BucketIterator(train_data, batch_size=BATCH_SIZE, device=device,\n",
    "                                     sort_within_batch=True, shuffle=True, sort_key=lambda x: len(x.text))\n",
    "valid_iterator = BucketIterator(valid_data, batch_size=BATCH_SIZE, device=device)\n",
    "test_iterator = BucketIterator(test_data, batch_size=BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a45QA7ncg_Qv"
   },
   "source": [
    "### ミニバッチの中身を確認する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAW9Ec5q6BQO"
   },
   "source": [
    "* 訓練データのiteratorを回してミニバッチをすべて取得してみる\n",
    " * ミニバッチのshapeを表示してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kpn4tfWl42kY",
    "outputId": "97e11c70-9483-418f-fbf4-42dd19c320a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([133, 100])\n",
      "1 torch.Size([454, 100])\n",
      "2 torch.Size([248, 100])\n",
      "3 torch.Size([213, 100])\n",
      "4 torch.Size([106, 100])\n",
      "5 torch.Size([374, 100])\n",
      "6 torch.Size([94, 100])\n",
      "7 torch.Size([187, 100])\n",
      "8 torch.Size([286, 100])\n",
      "9 torch.Size([112, 100])\n",
      "10 torch.Size([49, 100])\n",
      "11 torch.Size([531, 100])\n",
      "12 torch.Size([190, 100])\n",
      "13 torch.Size([161, 100])\n",
      "14 torch.Size([227, 100])\n",
      "15 torch.Size([135, 100])\n",
      "16 torch.Size([386, 100])\n",
      "17 torch.Size([829, 100])\n",
      "18 torch.Size([182, 100])\n",
      "19 torch.Size([170, 100])\n",
      "20 torch.Size([243, 100])\n",
      "21 torch.Size([921, 100])\n",
      "22 torch.Size([1055, 100])\n",
      "23 torch.Size([69, 100])\n",
      "24 torch.Size([300, 100])\n",
      "25 torch.Size([270, 100])\n",
      "26 torch.Size([329, 100])\n",
      "27 torch.Size([216, 100])\n",
      "28 torch.Size([612, 100])\n",
      "29 torch.Size([128, 100])\n",
      "30 torch.Size([275, 100])\n",
      "31 torch.Size([223, 100])\n",
      "32 torch.Size([154, 100])\n",
      "33 torch.Size([472, 100])\n",
      "34 torch.Size([63, 100])\n",
      "35 torch.Size([175, 100])\n",
      "36 torch.Size([398, 100])\n",
      "37 torch.Size([438, 100])\n",
      "38 torch.Size([121, 100])\n",
      "39 torch.Size([695, 100])\n",
      "40 torch.Size([410, 100])\n",
      "41 torch.Size([201, 100])\n",
      "42 torch.Size([166, 100])\n",
      "43 torch.Size([157, 100])\n",
      "44 torch.Size([346, 100])\n",
      "45 torch.Size([581, 100])\n",
      "46 torch.Size([422, 100])\n",
      "47 torch.Size([265, 100])\n",
      "48 torch.Size([145, 100])\n",
      "49 torch.Size([56, 100])\n",
      "50 torch.Size([100, 100])\n",
      "51 torch.Size([142, 100])\n",
      "52 torch.Size([294, 100])\n",
      "53 torch.Size([149, 100])\n",
      "54 torch.Size([259, 100])\n",
      "55 torch.Size([159, 100])\n",
      "56 torch.Size([254, 100])\n",
      "57 torch.Size([365, 100])\n",
      "58 torch.Size([179, 100])\n",
      "59 torch.Size([118, 100])\n",
      "60 torch.Size([490, 100])\n",
      "61 torch.Size([164, 100])\n",
      "62 torch.Size([184, 100])\n",
      "63 torch.Size([206, 100])\n",
      "64 torch.Size([749, 100])\n",
      "65 torch.Size([210, 100])\n",
      "66 torch.Size([177, 100])\n",
      "67 torch.Size([152, 100])\n",
      "68 torch.Size([236, 100])\n",
      "69 torch.Size([281, 100])\n",
      "70 torch.Size([653, 100])\n",
      "71 torch.Size([141, 100])\n",
      "72 torch.Size([230, 100])\n",
      "73 torch.Size([156, 100])\n",
      "74 torch.Size([239, 100])\n",
      "75 torch.Size([203, 100])\n",
      "76 torch.Size([356, 100])\n",
      "77 torch.Size([337, 100])\n",
      "78 torch.Size([150, 100])\n",
      "79 torch.Size([313, 100])\n",
      "80 torch.Size([168, 100])\n",
      "81 torch.Size([75, 100])\n",
      "82 torch.Size([198, 100])\n",
      "83 torch.Size([81, 100])\n",
      "84 torch.Size([220, 100])\n",
      "85 torch.Size([88, 100])\n",
      "86 torch.Size([147, 100])\n",
      "87 torch.Size([131, 100])\n",
      "88 torch.Size([1996, 100])\n",
      "89 torch.Size([555, 100])\n",
      "90 torch.Size([144, 100])\n",
      "91 torch.Size([137, 100])\n",
      "92 torch.Size([139, 100])\n",
      "93 torch.Size([172, 100])\n",
      "94 torch.Size([195, 100])\n",
      "95 torch.Size([125, 100])\n",
      "96 torch.Size([322, 100])\n",
      "97 torch.Size([305, 100])\n",
      "98 torch.Size([508, 100])\n",
      "99 torch.Size([192, 100])\n",
      "100 torch.Size([240, 100])\n",
      "101 torch.Size([200, 100])\n",
      "102 torch.Size([224, 100])\n",
      "103 torch.Size([231, 100])\n",
      "104 torch.Size([105, 100])\n",
      "105 torch.Size([133, 100])\n",
      "106 torch.Size([153, 100])\n",
      "107 torch.Size([220, 100])\n",
      "108 torch.Size([562, 100])\n",
      "109 torch.Size([111, 100])\n",
      "110 torch.Size([189, 100])\n",
      "111 torch.Size([228, 100])\n",
      "112 torch.Size([390, 100])\n",
      "113 torch.Size([186, 100])\n",
      "114 torch.Size([269, 100])\n",
      "115 torch.Size([156, 100])\n",
      "116 torch.Size([324, 100])\n",
      "117 torch.Size([141, 100])\n",
      "118 torch.Size([155, 100])\n",
      "119 torch.Size([254, 100])\n",
      "120 torch.Size([1044, 100])\n",
      "121 torch.Size([194, 100])\n",
      "122 torch.Size([539, 100])\n",
      "123 torch.Size([663, 100])\n",
      "124 torch.Size([249, 100])\n",
      "125 torch.Size([169, 100])\n",
      "126 torch.Size([309, 100])\n",
      "127 torch.Size([1698, 100])\n",
      "128 torch.Size([591, 100])\n",
      "129 torch.Size([144, 100])\n",
      "130 torch.Size([341, 100])\n",
      "131 torch.Size([149, 100])\n",
      "132 torch.Size([417, 100])\n",
      "133 torch.Size([213, 100])\n",
      "134 torch.Size([478, 100])\n",
      "135 torch.Size([94, 100])\n",
      "136 torch.Size([165, 100])\n",
      "137 torch.Size([63, 100])\n",
      "138 torch.Size([183, 100])\n",
      "139 torch.Size([206, 100])\n",
      "140 torch.Size([825, 100])\n",
      "141 torch.Size([197, 100])\n",
      "142 torch.Size([301, 100])\n",
      "143 torch.Size([217, 100])\n",
      "144 torch.Size([68, 100])\n",
      "145 torch.Size([498, 100])\n",
      "146 torch.Size([443, 100])\n",
      "147 torch.Size([380, 100])\n",
      "148 torch.Size([371, 100])\n",
      "149 torch.Size([124, 100])\n",
      "150 torch.Size([236, 100])\n",
      "151 torch.Size([127, 100])\n",
      "152 torch.Size([264, 100])\n",
      "153 torch.Size([287, 100])\n",
      "154 torch.Size([294, 100])\n",
      "155 torch.Size([120, 100])\n",
      "156 torch.Size([75, 100])\n",
      "157 torch.Size([88, 100])\n",
      "158 torch.Size([350, 100])\n",
      "159 torch.Size([142, 100])\n",
      "160 torch.Size([167, 100])\n",
      "161 torch.Size([191, 100])\n",
      "162 torch.Size([172, 100])\n",
      "163 torch.Size([623, 100])\n",
      "164 torch.Size([430, 100])\n",
      "165 torch.Size([754, 100])\n",
      "166 torch.Size([147, 100])\n",
      "167 torch.Size([137, 100])\n",
      "168 torch.Size([81, 100])\n",
      "169 torch.Size([146, 100])\n",
      "170 torch.Size([100, 100])\n",
      "171 torch.Size([49, 100])\n",
      "172 torch.Size([117, 100])\n",
      "173 torch.Size([174, 100])\n",
      "174 torch.Size([203, 100])\n",
      "175 torch.Size([276, 100])\n",
      "176 torch.Size([135, 100])\n",
      "177 torch.Size([332, 100])\n",
      "178 torch.Size([163, 100])\n",
      "179 torch.Size([181, 100])\n",
      "180 torch.Size([403, 100])\n",
      "181 torch.Size([160, 100])\n",
      "182 torch.Size([161, 100])\n",
      "183 torch.Size([361, 100])\n",
      "184 torch.Size([176, 100])\n",
      "185 torch.Size([158, 100])\n",
      "186 torch.Size([130, 100])\n",
      "187 torch.Size([915, 100])\n",
      "188 torch.Size([316, 100])\n",
      "189 torch.Size([210, 100])\n",
      "190 torch.Size([178, 100])\n",
      "191 torch.Size([282, 100])\n",
      "192 torch.Size([244, 100])\n",
      "193 torch.Size([56, 100])\n",
      "194 torch.Size([151, 100])\n",
      "195 torch.Size([517, 100])\n",
      "196 torch.Size([702, 100])\n",
      "197 torch.Size([259, 100])\n",
      "198 torch.Size([461, 100])\n",
      "199 torch.Size([139, 100])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "  print(i, batch.text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWW1np1P6OQg"
   },
   "source": [
    "* ミニバッチの形は、[ミニバッチ内での最大文書長, ミニバッチのサイズ]になっていることに注意！\n",
    " * ミニバッチのサイズが最初に来ているのではない！\n",
    " * [ミニバッチのサイズ, ミニバッチ内での最大文書長]という形にしたいなら、テキストのfieldを作るとき以下のようにする。\n",
    "\n",
    "__`TEXT = data.Field(tokenize=\"spacy\", batch_first=True)`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHytOsiSUdeS"
   },
   "source": [
    "* 上記のループを抜けたあとには、変数batchには最後のミニバッチが代入されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d78vJW616H7m",
    "outputId": "c283572b-ef0e-4f97-a036-1b9c504f6ab4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([139, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHMHkR73VuCD"
   },
   "source": [
    "* このミニバッチに含まれる文書のうち、最初の文書の単語ID列を表示させてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-tZLm0hQVjZE",
    "outputId": "1ba0160b-184f-4afc-cc24-4cd6077a47d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   11,   216,    14,    25,  4676,     7, 17659,    14,    19,     5,\n",
      "           62,    59, 17411,   710,    22,     3,    21,    60,  3409,   375,\n",
      "           45,  1460,  8578,     3,  2819, 24356,     6,  3640,     0,     4,\n",
      "          173,    16,    78,    43,   426,     7,     2,   225,    29,   239,\n",
      "            2,  1328,    30,    12,    63,   264,    36,    38,     7,    83,\n",
      "         1668,   786,    17,   664,   569,     7,     2,  5589,    18, 13953,\n",
      "            3,    11,   160,   236,  6596, 24356,     8,  1525,     3,   450,\n",
      "         5012,     0,    85,    27,   952,    49,    20,    95,    23,    90,\n",
      "            7,     2,   225,     6,    72,    85,    34,     8,  4498,     2,\n",
      "         7731,   164,     0,   130,     4,   173,    31,   217,    54,     2,\n",
      "            0,  1328,    52,     2, 12691,     6,     2,    14, 15005,    14,\n",
      "          175,    10,   172,   158,     3,   123,    16,    22,     9,  1184,\n",
      "          590,     4,  3401,    83,   924,  1668,     7,     2,   774,   117,\n",
      "            3,    26,    10,    82,   830,    99,    41,    42,     4],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch.text[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcXV1WLCdax1"
   },
   "source": [
    "* このミニバッチに含まれる文書のうち、最初の文書の単語ID列を単語列に戻したものを表示させてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjaS-Mjadf63",
    "outputId": "ff5255fe-c24f-4290-e16a-514693edefdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I thought \" The River of Souls \" was a very good Babylon 5 movie , with some exceptional performances from Martin Sheen , Tracy Scoggins and Ian <unk> . If this were an episode of the series ( without the humour ) it would probably be one of my favourite stand - alone stories of the series.<br /><br />Personally , I 've always preferred Scoggins to Christian , although granted <unk> did n't write her as well for much of the series and she did have to endure the Byron / <unk> plot . If you take out the <unk> humour about the brothel and the \" poorer \" actors in those scenes , then this movie is solid stuff . Probably my third favourite of the four movies , but in no means bad at all .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([TEXT.vocab.itos[i] for i in batch.text[:, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uoslpyTgz8w"
   },
   "source": [
    "* このミニバッチに含まれる文書のうち、最後の文書の単語ID列を表示させてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcdyIhK0TUac",
    "outputId": "0bb36bf7-5959-41fd-80fd-4dde04585966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   11,    34,    91,     5,   356,     7,    16,    22,    23,   176,\n",
      "            6,   176,     4,  1448,     7, 16091,     0,   875,    93,     2,\n",
      "        20137,     3,    11,    74,     8,   217,     2,    22,   142,     2,\n",
      "         4367,     6,   126,    12,     4,   567,   101,   169,    10,  5920,\n",
      "           85,    33,    81,   112,   425,    16,    22,    19,    10,   818,\n",
      "           84,    58,  3733,  6274,     6,  1916,  6953,    32,   818,  3004,\n",
      "            4,   764,    11,   133,    34,   178,  9864,  2183, 11328,     3,\n",
      "           16,    22,  1146,    84,   209,    68,    11,   126,    12,     4,\n",
      "           25,   131,     9,   377,     8,   805,    23,     5,   248,     6,\n",
      "            2,   527,     9,    48,  1475,     4,    11,   648,   398,    13,\n",
      "           31,   126,    16,    76,    31,    34,    27,   494,     4,   240,\n",
      "           96,    94,     8,    81,  3165, 12228,     3,  5487,  3889,     3,\n",
      "        16091, 18484,     3,     6,  4427,  3886,    88,     8,   445,     5,\n",
      "          186,    88,    42,   227,  3851,   375,     4,     1,     1],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch.text[:, BATCH_SIZE-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtDXRKPMT9KW"
   },
   "source": [
    "最後の文書の末尾は「1」で埋められていることが分かる。\n",
    "\n",
    "この1は、パディング用単語のIDだったことを想起されたい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDzk2ghCUD8N"
   },
   "source": [
    "ミニバッチに含まれる文書の長さを調べると、文書が文書長の降順に並べられていることが分かる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PutP_EU4Tca-",
    "outputId": "3ea6ce69-ceab-4125-9c19-6129aa9c2996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
       "        139, 139, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
       "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
       "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
       "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
       "        138, 138, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,\n",
       "        137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,\n",
       "        137, 137], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch.text != 1).sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PDZlF0O6doP"
   },
   "source": [
    "## 07-02 MLPによる文書分類の準備\n",
    "* 今回は、ごく簡単なMLPで文書分類をする。\n",
    "* 文書中の全単語トークンの埋め込みベクトルの平均を、MLPの入力とする。\n",
    " * 当然、語順の情報は使われない。\n",
    " * つまり、bag-of-wordsモデルになっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjpel2i46gbD"
   },
   "source": [
    "### 定数の設定\n",
    "* 単語埋め込みベクトルの次元数を設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元を128→512に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQPXVLC66NUM",
    "outputId": "38541916-59af-449e-d820-5651746fd780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "語彙サイズ 25002, クラス数 2, 単語埋め込み次元 512\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "NUM_CLASS = len(LABEL.vocab)\n",
    "EMBED_DIM = 512\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "print(f'語彙サイズ {INPUT_DIM}, クラス数 {NUM_CLASS}, 単語埋め込み次元 {EMBED_DIM}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsuHjuNp6tvt"
   },
   "source": [
    "### モデルを定義する前にPyTorchの単語埋め込みがどんなものかを見てみる\n",
    "* 埋め込みとは、単語IDから単語ベクトルへのマッピング。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3J7TzxFVMsR"
   },
   "source": [
    "* 以下のように、語彙サイズと埋め込みの次元数を指定しつつ、torch.nn.Embeddingのインスタンスを作ればよい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QP7jJVYT6tBg"
   },
   "outputs": [],
   "source": [
    "embed = nn.Embedding(INPUT_DIM, EMBED_DIM, padding_idx=PAD_IDX).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUl6lR8JVWTu"
   },
   "source": [
    "* パディング用の単語の埋め込みはゼロベクトルになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3ZCr9Ll61m8",
    "outputId": "d447c7ab-5057-4f4b-fafd-98d8a4d035f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3173, -0.5923,  0.6092,  ..., -0.9463,  0.4801,  0.3610],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(embed(torch.tensor([21,1]).to(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YN0kM3urr-Il"
   },
   "source": [
    "* 埋め込みの効果を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQ0FqJRcr6Vo",
    "outputId": "eac813a0-1235-482f-8edf-f48442194a43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([401, 100, 512])\n",
      "1 torch.Size([143, 100, 512])\n",
      "2 torch.Size([281, 100, 512])\n",
      "3 torch.Size([105, 100, 512])\n",
      "4 torch.Size([207, 100, 512])\n",
      "5 torch.Size([171, 100, 512])\n",
      "6 torch.Size([511, 100, 512])\n",
      "7 torch.Size([88, 100, 512])\n",
      "8 torch.Size([81, 100, 512])\n",
      "9 torch.Size([136, 100, 512])\n",
      "10 torch.Size([230, 100, 512])\n",
      "11 torch.Size([198, 100, 512])\n",
      "12 torch.Size([347, 100, 512])\n",
      "13 torch.Size([211, 100, 512])\n",
      "14 torch.Size([753, 100, 512])\n",
      "15 torch.Size([201, 100, 512])\n",
      "16 torch.Size([921, 100, 512])\n",
      "17 torch.Size([367, 100, 512])\n",
      "18 torch.Size([148, 100, 512])\n",
      "19 torch.Size([301, 100, 512])\n",
      "20 torch.Size([584, 100, 512])\n",
      "21 torch.Size([294, 100, 512])\n",
      "22 torch.Size([195, 100, 512])\n",
      "23 torch.Size([438, 100, 512])\n",
      "24 torch.Size([616, 100, 512])\n",
      "25 torch.Size([222, 100, 512])\n",
      "26 torch.Size([62, 100, 512])\n",
      "27 torch.Size([239, 100, 512])\n",
      "28 torch.Size([829, 100, 512])\n",
      "29 torch.Size([264, 100, 512])\n",
      "30 torch.Size([219, 100, 512])\n",
      "31 torch.Size([182, 100, 512])\n",
      "32 torch.Size([193, 100, 512])\n",
      "33 torch.Size([1041, 100, 512])\n",
      "34 torch.Size([188, 100, 512])\n",
      "35 torch.Size([76, 100, 512])\n",
      "36 torch.Size([123, 100, 512])\n",
      "37 torch.Size([276, 100, 512])\n",
      "38 torch.Size([163, 100, 512])\n",
      "39 torch.Size([157, 100, 512])\n",
      "40 torch.Size([173, 100, 512])\n",
      "41 torch.Size([329, 100, 512])\n",
      "42 torch.Size([146, 100, 512])\n",
      "43 torch.Size([474, 100, 512])\n",
      "44 torch.Size([112, 100, 512])\n",
      "45 torch.Size([322, 100, 512])\n",
      "46 torch.Size([169, 100, 512])\n",
      "47 torch.Size([117, 100, 512])\n",
      "48 torch.Size([176, 100, 512])\n",
      "49 torch.Size([314, 100, 512])\n",
      "50 torch.Size([132, 100, 512])\n",
      "51 torch.Size([388, 100, 512])\n",
      "52 torch.Size([134, 100, 512])\n",
      "53 torch.Size([287, 100, 512])\n",
      "54 torch.Size([159, 100, 512])\n",
      "55 torch.Size([141, 100, 512])\n",
      "56 torch.Size([214, 100, 512])\n",
      "57 torch.Size([657, 100, 512])\n",
      "58 torch.Size([270, 100, 512])\n",
      "59 torch.Size([375, 100, 512])\n",
      "60 torch.Size([145, 100, 512])\n",
      "61 torch.Size([180, 100, 512])\n",
      "62 torch.Size([226, 100, 512])\n",
      "63 torch.Size([156, 100, 512])\n",
      "64 torch.Size([165, 100, 512])\n",
      "65 torch.Size([154, 100, 512])\n",
      "66 torch.Size([150, 100, 512])\n",
      "67 torch.Size([338, 100, 512])\n",
      "68 torch.Size([234, 100, 512])\n",
      "69 torch.Size([185, 100, 512])\n",
      "70 torch.Size([533, 100, 512])\n",
      "71 torch.Size([161, 100, 512])\n",
      "72 torch.Size([248, 100, 512])\n",
      "73 torch.Size([702, 100, 512])\n",
      "74 torch.Size([204, 100, 512])\n",
      "75 torch.Size([308, 100, 512])\n",
      "76 torch.Size([138, 100, 512])\n",
      "77 torch.Size([457, 100, 512])\n",
      "78 torch.Size([254, 100, 512])\n",
      "79 torch.Size([167, 100, 512])\n",
      "80 torch.Size([130, 100, 512])\n",
      "81 torch.Size([49, 100, 512])\n",
      "82 torch.Size([99, 100, 512])\n",
      "83 torch.Size([94, 100, 512])\n",
      "84 torch.Size([69, 100, 512])\n",
      "85 torch.Size([56, 100, 512])\n",
      "86 torch.Size([259, 100, 512])\n",
      "87 torch.Size([560, 100, 512])\n",
      "88 torch.Size([243, 100, 512])\n",
      "89 torch.Size([120, 100, 512])\n",
      "90 torch.Size([1743, 100, 512])\n",
      "91 torch.Size([190, 100, 512])\n",
      "92 torch.Size([140, 100, 512])\n",
      "93 torch.Size([413, 100, 512])\n",
      "94 torch.Size([127, 100, 512])\n",
      "95 torch.Size([177, 100, 512])\n",
      "96 torch.Size([426, 100, 512])\n",
      "97 torch.Size([493, 100, 512])\n",
      "98 torch.Size([152, 100, 512])\n",
      "99 torch.Size([358, 100, 512])\n",
      "100 torch.Size([157, 100, 512])\n",
      "101 torch.Size([823, 100, 512])\n",
      "102 torch.Size([358, 100, 512])\n",
      "103 torch.Size([427, 100, 512])\n",
      "104 torch.Size([259, 100, 512])\n",
      "105 torch.Size([197, 100, 512])\n",
      "106 torch.Size([191, 100, 512])\n",
      "107 torch.Size([171, 100, 512])\n",
      "108 torch.Size([141, 100, 512])\n",
      "109 torch.Size([173, 100, 512])\n",
      "110 torch.Size([212, 100, 512])\n",
      "111 torch.Size([125, 100, 512])\n",
      "112 torch.Size([914, 100, 512])\n",
      "113 torch.Size([225, 100, 512])\n",
      "114 torch.Size([221, 100, 512])\n",
      "115 torch.Size([657, 100, 512])\n",
      "116 torch.Size([316, 100, 512])\n",
      "117 torch.Size([56, 100, 512])\n",
      "118 torch.Size([237, 100, 512])\n",
      "119 torch.Size([218, 100, 512])\n",
      "120 torch.Size([537, 100, 512])\n",
      "121 torch.Size([134, 100, 512])\n",
      "122 torch.Size([618, 100, 512])\n",
      "123 torch.Size([294, 100, 512])\n",
      "124 torch.Size([324, 100, 512])\n",
      "125 torch.Size([143, 100, 512])\n",
      "126 torch.Size([180, 100, 512])\n",
      "127 torch.Size([183, 100, 512])\n",
      "128 torch.Size([175, 100, 512])\n",
      "129 torch.Size([493, 100, 512])\n",
      "130 torch.Size([166, 100, 512])\n",
      "131 torch.Size([129, 100, 512])\n",
      "132 torch.Size([275, 100, 512])\n",
      "133 torch.Size([153, 100, 512])\n",
      "134 torch.Size([112, 100, 512])\n",
      "135 torch.Size([214, 100, 512])\n",
      "136 torch.Size([228, 100, 512])\n",
      "137 torch.Size([140, 100, 512])\n",
      "138 torch.Size([208, 100, 512])\n",
      "139 torch.Size([413, 100, 512])\n",
      "140 torch.Size([379, 100, 512])\n",
      "141 torch.Size([118, 100, 512])\n",
      "142 torch.Size([458, 100, 512])\n",
      "143 torch.Size([401, 100, 512])\n",
      "144 torch.Size([332, 100, 512])\n",
      "145 torch.Size([178, 100, 512])\n",
      "146 torch.Size([240, 100, 512])\n",
      "147 torch.Size([269, 100, 512])\n",
      "148 torch.Size([281, 100, 512])\n",
      "149 torch.Size([88, 100, 512])\n",
      "150 torch.Size([74, 100, 512])\n",
      "151 torch.Size([475, 100, 512])\n",
      "152 torch.Size([68, 100, 512])\n",
      "153 torch.Size([150, 100, 512])\n",
      "154 torch.Size([168, 100, 512])\n",
      "155 torch.Size([442, 100, 512])\n",
      "156 torch.Size([105, 100, 512])\n",
      "157 torch.Size([193, 100, 512])\n",
      "158 torch.Size([148, 100, 512])\n",
      "159 torch.Size([122, 100, 512])\n",
      "160 torch.Size([233, 100, 512])\n",
      "161 torch.Size([205, 100, 512])\n",
      "162 torch.Size([254, 100, 512])\n",
      "163 torch.Size([200, 100, 512])\n",
      "164 torch.Size([49, 100, 512])\n",
      "165 torch.Size([136, 100, 512])\n",
      "166 torch.Size([138, 100, 512])\n",
      "167 torch.Size([244, 100, 512])\n",
      "168 torch.Size([164, 100, 512])\n",
      "169 torch.Size([162, 100, 512])\n",
      "170 torch.Size([752, 100, 512])\n",
      "171 torch.Size([249, 100, 512])\n",
      "172 torch.Size([160, 100, 512])\n",
      "173 torch.Size([158, 100, 512])\n",
      "174 torch.Size([132, 100, 512])\n",
      "175 torch.Size([94, 100, 512])\n",
      "176 torch.Size([155, 100, 512])\n",
      "177 torch.Size([151, 100, 512])\n",
      "178 torch.Size([369, 100, 512])\n",
      "179 torch.Size([188, 100, 512])\n",
      "180 torch.Size([585, 100, 512])\n",
      "181 torch.Size([557, 100, 512])\n",
      "182 torch.Size([100, 100, 512])\n",
      "183 torch.Size([1067, 100, 512])\n",
      "184 torch.Size([287, 100, 512])\n",
      "185 torch.Size([146, 100, 512])\n",
      "186 torch.Size([63, 100, 512])\n",
      "187 torch.Size([389, 100, 512])\n",
      "188 torch.Size([300, 100, 512])\n",
      "189 torch.Size([695, 100, 512])\n",
      "190 torch.Size([307, 100, 512])\n",
      "191 torch.Size([203, 100, 512])\n",
      "192 torch.Size([349, 100, 512])\n",
      "193 torch.Size([341, 100, 512])\n",
      "194 torch.Size([1996, 100, 512])\n",
      "195 torch.Size([186, 100, 512])\n",
      "196 torch.Size([515, 100, 512])\n",
      "197 torch.Size([145, 100, 512])\n",
      "198 torch.Size([264, 100, 512])\n",
      "199 torch.Size([81, 100, 512])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "  print(i, embed(batch.text).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGyngitc78hv"
   },
   "source": [
    "### モデルの定義\n",
    "* MLP（多層パーセプトロン）だが、入り口に単語埋め込み層が挿入されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初めの層を1024に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9asdLYng7DOu"
   },
   "outputs": [],
   "source": [
    "class EmbedTextSentiment(nn.Module):\n",
    "  def __init__(self, embed_dim, num_class, vocab_size, padding_idx):\n",
    "    super(EmbedTextSentiment, self).__init__()\n",
    "    self.padding_idx = padding_idx # 2020/12/19追加\n",
    "    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "    self.fc1 = nn.Linear(embed_dim, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 100)\n",
    "    self.fc3 = nn.Linear(100, num_class)\n",
    "\n",
    "  def forward(self, text):\n",
    "    x = self.embed(text)\n",
    "    #x = x.mean(0) # 文書に含まれる全単語トークンの単語ベクトルの平均\n",
    "    #上の平均の計算を正確に書くと、以下の2行のようになります。（2020/12/19追加）\n",
    "    mask = (text != self.padding_idx)\n",
    "    x = (x * mask.unsqueeze(2)).sum(0) / mask.sum(0).unsqueeze(1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foU72cB48IO9"
   },
   "source": [
    "### モデルを作る\n",
    "* モデル（のインスタンス）をGPUに移動させている点に注意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "W0BHCGAZ8F18"
   },
   "outputs": [],
   "source": [
    "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wylQOq8N8cqI"
   },
   "source": [
    "### 損失関数とoptimizerとschedulerを作る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lr を0.001に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gw34INS78cIW"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilWLfu8Z8MzW"
   },
   "source": [
    "### 訓練用の関数\n",
    "* 最初の`model.train()`に注意。こうやって、モデルを訓練モードに設定する。\n",
    " * 例えば、dropoutを含むモデルなど、訓練時と評価時で、ふるまい方を変える必要があるときがあるため、こういうことをする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UR2R4Lqh8J7n"
   },
   "outputs": [],
   "source": [
    "def train(data_iterator, model, optimizer, scheduler, criterion):\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  train_loss = 0\n",
    "  train_acc = 0\n",
    "  for batch in data_iterator:\n",
    "    optimizer.zero_grad()\n",
    "    text, cls = batch.text, batch.label\n",
    "    output = model(text)\n",
    "    loss = criterion(output, cls)\n",
    "    train_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_acc += (output.argmax(1) == cls).float().mean().item()\n",
    "\n",
    "  scheduler.step()\n",
    "\n",
    "  num_batch = len(data_iterator)\n",
    "  return train_loss / num_batch, train_acc / num_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftuX8e1W8iRh"
   },
   "source": [
    "### 評価用の関数\n",
    "* 最初の`model.eval()`に注意。こうやって、モデルを評価モードに設定する。\n",
    " * 例えば、dropoutを含むモデルなど、訓練時と評価時で、ふるまい方を変える必要があるときがあるため、こういうことをする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "wGUnsJlq8Ue3"
   },
   "outputs": [],
   "source": [
    "def test(data_iterator, model, criterion):\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  loss = 0\n",
    "  acc = 0\n",
    "  for batch in data_iterator:\n",
    "    text, cls = batch.text, batch.label\n",
    "    with torch.no_grad():\n",
    "      output = model(text)\n",
    "      loss = criterion(output, cls)\n",
    "      loss += loss.item()\n",
    "      acc += (output.argmax(1) == cls).float().mean().item()\n",
    "\n",
    "  num_batch = len(data_iterator)\n",
    "  return loss / num_batch, acc / num_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8o_jDAg8osP"
   },
   "source": [
    "## 07-03 分類器の訓練と検証セットでの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エポック数を100に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJJFv4k-8mH1",
    "outputId": "2d741b71-b62c-40cc-ee8e-9a38bb9e748d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | time in 0 minutes, 5 seconds | lr=0.000950\n",
      "\tLoss: 0.48000(train)\t|\tAcc: 75.82%(train)\n",
      "\tLoss: 0.02058(valid)\t|\tAcc: 82.66%(valid)\n",
      "Epoch 2 | time in 0 minutes, 4 seconds | lr=0.000902\n",
      "\tLoss: 0.27400(train)\t|\tAcc: 89.07%(train)\n",
      "\tLoss: 0.01430(valid)\t|\tAcc: 86.40%(valid)\n",
      "Epoch 3 | time in 0 minutes, 4 seconds | lr=0.000857\n",
      "\tLoss: 0.18338(train)\t|\tAcc: 93.30%(train)\n",
      "\tLoss: 0.01140(valid)\t|\tAcc: 88.04%(valid)\n",
      "Epoch 4 | time in 0 minutes, 4 seconds | lr=0.000815\n",
      "\tLoss: 0.12105(train)\t|\tAcc: 95.86%(train)\n",
      "\tLoss: 0.01135(valid)\t|\tAcc: 88.18%(valid)\n",
      "Epoch 5 | time in 0 minutes, 4 seconds | lr=0.000774\n",
      "\tLoss: 0.07044(train)\t|\tAcc: 97.88%(train)\n",
      "\tLoss: 0.01413(valid)\t|\tAcc: 88.12%(valid)\n",
      "Epoch 6 | time in 0 minutes, 4 seconds | lr=0.000735\n",
      "\tLoss: 0.04270(train)\t|\tAcc: 98.85%(train)\n",
      "\tLoss: 0.03023(valid)\t|\tAcc: 87.42%(valid)\n",
      "Epoch 7 | time in 0 minutes, 4 seconds | lr=0.000698\n",
      "\tLoss: 0.02149(train)\t|\tAcc: 99.57%(train)\n",
      "\tLoss: 0.01842(valid)\t|\tAcc: 87.30%(valid)\n",
      "Epoch 8 | time in 0 minutes, 4 seconds | lr=0.000663\n",
      "\tLoss: 0.01182(train)\t|\tAcc: 99.76%(train)\n",
      "\tLoss: 0.03355(valid)\t|\tAcc: 87.30%(valid)\n",
      "Epoch 9 | time in 0 minutes, 4 seconds | lr=0.000630\n",
      "\tLoss: 0.00528(train)\t|\tAcc: 99.89%(train)\n",
      "\tLoss: 0.01998(valid)\t|\tAcc: 87.36%(valid)\n",
      "Epoch 10 | time in 0 minutes, 4 seconds | lr=0.000599\n",
      "\tLoss: 0.00215(train)\t|\tAcc: 99.96%(train)\n",
      "\tLoss: 0.02036(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 11 | time in 0 minutes, 4 seconds | lr=0.000569\n",
      "\tLoss: 0.00099(train)\t|\tAcc: 99.98%(train)\n",
      "\tLoss: 0.02497(valid)\t|\tAcc: 87.28%(valid)\n",
      "Epoch 12 | time in 0 minutes, 4 seconds | lr=0.000540\n",
      "\tLoss: 0.00067(train)\t|\tAcc: 99.98%(train)\n",
      "\tLoss: 0.03035(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 13 | time in 0 minutes, 4 seconds | lr=0.000513\n",
      "\tLoss: 0.00032(train)\t|\tAcc: 99.99%(train)\n",
      "\tLoss: 0.03492(valid)\t|\tAcc: 87.30%(valid)\n",
      "Epoch 14 | time in 0 minutes, 4 seconds | lr=0.000488\n",
      "\tLoss: 0.00018(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.04039(valid)\t|\tAcc: 87.34%(valid)\n",
      "Epoch 15 | time in 0 minutes, 4 seconds | lr=0.000463\n",
      "\tLoss: 0.00012(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.03226(valid)\t|\tAcc: 87.38%(valid)\n",
      "Epoch 16 | time in 0 minutes, 4 seconds | lr=0.000440\n",
      "\tLoss: 0.00008(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.02739(valid)\t|\tAcc: 87.36%(valid)\n",
      "Epoch 17 | time in 0 minutes, 4 seconds | lr=0.000418\n",
      "\tLoss: 0.00006(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.02661(valid)\t|\tAcc: 87.42%(valid)\n",
      "Epoch 18 | time in 0 minutes, 4 seconds | lr=0.000397\n",
      "\tLoss: 0.00004(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06163(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 19 | time in 0 minutes, 4 seconds | lr=0.000377\n",
      "\tLoss: 0.00004(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.00796(valid)\t|\tAcc: 87.38%(valid)\n",
      "Epoch 20 | time in 0 minutes, 4 seconds | lr=0.000358\n",
      "\tLoss: 0.00003(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05210(valid)\t|\tAcc: 87.42%(valid)\n",
      "Epoch 21 | time in 0 minutes, 4 seconds | lr=0.000341\n",
      "\tLoss: 0.00002(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.03823(valid)\t|\tAcc: 87.44%(valid)\n",
      "Epoch 22 | time in 0 minutes, 4 seconds | lr=0.000324\n",
      "\tLoss: 0.00002(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06648(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 23 | time in 0 minutes, 4 seconds | lr=0.000307\n",
      "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.04355(valid)\t|\tAcc: 87.42%(valid)\n",
      "Epoch 24 | time in 0 minutes, 4 seconds | lr=0.000292\n",
      "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.04083(valid)\t|\tAcc: 87.42%(valid)\n",
      "Epoch 25 | time in 0 minutes, 4 seconds | lr=0.000277\n",
      "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05947(valid)\t|\tAcc: 87.40%(valid)\n",
      "Epoch 26 | time in 0 minutes, 4 seconds | lr=0.000264\n",
      "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05956(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 27 | time in 0 minutes, 4 seconds | lr=0.000250\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.04583(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 28 | time in 0 minutes, 4 seconds | lr=0.000238\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06313(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 29 | time in 0 minutes, 4 seconds | lr=0.000226\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.07767(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 30 | time in 0 minutes, 4 seconds | lr=0.000215\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.07218(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 31 | time in 0 minutes, 4 seconds | lr=0.000204\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05782(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 32 | time in 0 minutes, 4 seconds | lr=0.000194\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.04516(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 33 | time in 0 minutes, 4 seconds | lr=0.000184\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.07190(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 34 | time in 0 minutes, 4 seconds | lr=0.000175\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05054(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 35 | time in 0 minutes, 4 seconds | lr=0.000166\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06008(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 36 | time in 0 minutes, 4 seconds | lr=0.000158\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06220(valid)\t|\tAcc: 87.42%(valid)\n",
      "Epoch 37 | time in 0 minutes, 4 seconds | lr=0.000150\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.04425(valid)\t|\tAcc: 87.42%(valid)\n",
      "Epoch 38 | time in 0 minutes, 4 seconds | lr=0.000142\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05522(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 39 | time in 0 minutes, 4 seconds | lr=0.000135\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.04506(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 40 | time in 0 minutes, 4 seconds | lr=0.000129\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06363(valid)\t|\tAcc: 87.52%(valid)\n",
      "Epoch 41 | time in 0 minutes, 4 seconds | lr=0.000122\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.02211(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 42 | time in 0 minutes, 4 seconds | lr=0.000116\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.07323(valid)\t|\tAcc: 87.52%(valid)\n",
      "Epoch 43 | time in 0 minutes, 4 seconds | lr=0.000110\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.04691(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 44 | time in 0 minutes, 4 seconds | lr=0.000105\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.08812(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 45 | time in 0 minutes, 4 seconds | lr=0.000099\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.04173(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 46 | time in 0 minutes, 4 seconds | lr=0.000094\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.07106(valid)\t|\tAcc: 87.52%(valid)\n",
      "Epoch 47 | time in 0 minutes, 4 seconds | lr=0.000090\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.07708(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 48 | time in 0 minutes, 4 seconds | lr=0.000085\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.09172(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 49 | time in 0 minutes, 4 seconds | lr=0.000081\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.03905(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 50 | time in 0 minutes, 4 seconds | lr=0.000077\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05463(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 51 | time in 0 minutes, 4 seconds | lr=0.000073\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.08241(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 52 | time in 0 minutes, 4 seconds | lr=0.000069\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06896(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 53 | time in 0 minutes, 4 seconds | lr=0.000066\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.01512(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 54 | time in 0 minutes, 4 seconds | lr=0.000063\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06972(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 55 | time in 0 minutes, 4 seconds | lr=0.000060\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.07422(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 56 | time in 0 minutes, 4 seconds | lr=0.000057\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.07617(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 57 | time in 0 minutes, 4 seconds | lr=0.000054\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.07743(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 58 | time in 0 minutes, 4 seconds | lr=0.000051\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05566(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 59 | time in 0 minutes, 4 seconds | lr=0.000048\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.03240(valid)\t|\tAcc: 87.48%(valid)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | time in 0 minutes, 4 seconds | lr=0.000046\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05310(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 61 | time in 0 minutes, 4 seconds | lr=0.000044\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05827(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 62 | time in 0 minutes, 4 seconds | lr=0.000042\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.09207(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 63 | time in 0 minutes, 4 seconds | lr=0.000039\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06829(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 64 | time in 0 minutes, 4 seconds | lr=0.000038\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.10514(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 65 | time in 0 minutes, 4 seconds | lr=0.000036\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06478(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 66 | time in 0 minutes, 5 seconds | lr=0.000034\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.06844(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 91 | time in 0 minutes, 4 seconds | lr=0.000009\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.12887(valid)\t|\tAcc: 87.44%(valid)\n",
      "Epoch 92 | time in 0 minutes, 4 seconds | lr=0.000009\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.09405(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 93 | time in 0 minutes, 4 seconds | lr=0.000008\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.03695(valid)\t|\tAcc: 87.44%(valid)\n",
      "Epoch 94 | time in 0 minutes, 4 seconds | lr=0.000008\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.08290(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 95 | time in 0 minutes, 4 seconds | lr=0.000008\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05107(valid)\t|\tAcc: 87.44%(valid)\n",
      "Epoch 96 | time in 0 minutes, 4 seconds | lr=0.000007\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.04503(valid)\t|\tAcc: 87.44%(valid)\n",
      "Epoch 97 | time in 0 minutes, 4 seconds | lr=0.000007\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05313(valid)\t|\tAcc: 87.44%(valid)\n",
      "Epoch 98 | time in 0 minutes, 4 seconds | lr=0.000007\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.07670(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 99 | time in 0 minutes, 4 seconds | lr=0.000006\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.03445(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 100 | time in 0 minutes, 4 seconds | lr=0.000006\n",
      "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
      "\tLoss: 0.05114(valid)\t|\tAcc: 87.46%(valid)\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "  start_time = time.time()\n",
    "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
    "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
    "\n",
    "  secs = int(time.time() - start_time)\n",
    "  mins = secs // 60\n",
    "  secs = secs % 60\n",
    "\n",
    "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
    "  for param_group in optimizer.param_groups:\n",
    "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
    "    break\n",
    "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
    "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPux8PReWTXG"
   },
   "source": [
    "## 07-04 再検討\n",
    "* 訓練データ上での分類精度がほぼ100%になってしまっている。\n",
    "* 検証データでの分類精度と大きな差があり、明らかにオーバーフィッティング。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23jMgtmoWkty"
   },
   "source": [
    "### ドロップアウトを使う\n",
    "* モデルのインスタンスを作るときにdropoutの確率を引数pで指定できるようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "khps3ZuBWntq"
   },
   "outputs": [],
   "source": [
    "class EmbedTextSentiment(nn.Module):\n",
    "  def __init__(self, embed_dim, num_class, vocab_size, padding_idx, p=0.0):\n",
    "    super(EmbedTextSentiment, self).__init__()\n",
    "    self.padding_idx = padding_idx # 2020/12/19追加\n",
    "    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "    self.dropout = nn.Dropout(p=p)\n",
    "    self.fc1 = nn.Linear(embed_dim, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 100)\n",
    "    self.fc3 = nn.Linear(100, num_class)\n",
    "\n",
    "  def forward(self, text):\n",
    "    x = self.dropout(self.embed(text)) #埋め込み層の直後にdropout\n",
    "    #x = x.mean(0)\n",
    "    #上の平均の計算を正確に書くと、以下の2行のようになります。（2020/12/19追加）\n",
    "    mask = (text != self.padding_idx)\n",
    "    x = (x * mask.unsqueeze(2)).sum(0) / mask.sum(0).unsqueeze(1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ZVXbkt6qXxNt"
   },
   "outputs": [],
   "source": [
    "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXkBDXc6X1mp",
    "outputId": "e1f33a37-9de3-4b37-8742-84451b45c2e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | time in 0 minutes, 5 seconds | lr=0.000950\n",
      "\tLoss: 0.53182(train)\t|\tAcc: 73.20%(train)\n",
      "\tLoss: 0.01476(valid)\t|\tAcc: 82.70%(valid)\n",
      "Epoch 2 | time in 0 minutes, 5 seconds | lr=0.000902\n",
      "\tLoss: 0.37805(train)\t|\tAcc: 83.63%(train)\n",
      "\tLoss: 0.01656(valid)\t|\tAcc: 86.02%(valid)\n",
      "Epoch 3 | time in 0 minutes, 5 seconds | lr=0.000857\n",
      "\tLoss: 0.31108(train)\t|\tAcc: 87.06%(train)\n",
      "\tLoss: 0.01612(valid)\t|\tAcc: 87.56%(valid)\n",
      "Epoch 4 | time in 0 minutes, 5 seconds | lr=0.000815\n",
      "\tLoss: 0.26604(train)\t|\tAcc: 89.12%(train)\n",
      "\tLoss: 0.01526(valid)\t|\tAcc: 86.14%(valid)\n",
      "Epoch 5 | time in 0 minutes, 4 seconds | lr=0.000774\n",
      "\tLoss: 0.23360(train)\t|\tAcc: 90.58%(train)\n",
      "\tLoss: 0.01506(valid)\t|\tAcc: 88.70%(valid)\n",
      "Epoch 6 | time in 0 minutes, 5 seconds | lr=0.000735\n",
      "\tLoss: 0.20254(train)\t|\tAcc: 91.86%(train)\n",
      "\tLoss: 0.00898(valid)\t|\tAcc: 88.64%(valid)\n",
      "Epoch 7 | time in 0 minutes, 5 seconds | lr=0.000698\n",
      "\tLoss: 0.18239(train)\t|\tAcc: 92.96%(train)\n",
      "\tLoss: 0.01073(valid)\t|\tAcc: 88.76%(valid)\n",
      "Epoch 8 | time in 0 minutes, 5 seconds | lr=0.000663\n",
      "\tLoss: 0.16133(train)\t|\tAcc: 93.68%(train)\n",
      "\tLoss: 0.01535(valid)\t|\tAcc: 88.92%(valid)\n",
      "Epoch 9 | time in 0 minutes, 5 seconds | lr=0.000630\n",
      "\tLoss: 0.14752(train)\t|\tAcc: 94.32%(train)\n",
      "\tLoss: 0.01127(valid)\t|\tAcc: 89.02%(valid)\n",
      "Epoch 10 | time in 0 minutes, 5 seconds | lr=0.000599\n",
      "\tLoss: 0.12818(train)\t|\tAcc: 95.01%(train)\n",
      "\tLoss: 0.00807(valid)\t|\tAcc: 88.68%(valid)\n",
      "Epoch 11 | time in 0 minutes, 5 seconds | lr=0.000569\n",
      "\tLoss: 0.11925(train)\t|\tAcc: 95.41%(train)\n",
      "\tLoss: 0.00751(valid)\t|\tAcc: 88.74%(valid)\n",
      "Epoch 12 | time in 0 minutes, 5 seconds | lr=0.000540\n",
      "\tLoss: 0.10326(train)\t|\tAcc: 96.05%(train)\n",
      "\tLoss: 0.01019(valid)\t|\tAcc: 89.04%(valid)\n",
      "Epoch 13 | time in 0 minutes, 5 seconds | lr=0.000513\n",
      "\tLoss: 0.10166(train)\t|\tAcc: 96.20%(train)\n",
      "\tLoss: 0.01373(valid)\t|\tAcc: 88.28%(valid)\n",
      "Epoch 14 | time in 0 minutes, 5 seconds | lr=0.000488\n",
      "\tLoss: 0.08484(train)\t|\tAcc: 96.88%(train)\n",
      "\tLoss: 0.02205(valid)\t|\tAcc: 88.66%(valid)\n",
      "Epoch 15 | time in 0 minutes, 5 seconds | lr=0.000463\n",
      "\tLoss: 0.07404(train)\t|\tAcc: 97.18%(train)\n",
      "\tLoss: 0.01984(valid)\t|\tAcc: 88.94%(valid)\n",
      "Epoch 16 | time in 0 minutes, 5 seconds | lr=0.000440\n",
      "\tLoss: 0.07114(train)\t|\tAcc: 97.35%(train)\n",
      "\tLoss: 0.01388(valid)\t|\tAcc: 88.70%(valid)\n",
      "Epoch 17 | time in 0 minutes, 5 seconds | lr=0.000418\n",
      "\tLoss: 0.06675(train)\t|\tAcc: 97.53%(train)\n",
      "\tLoss: 0.01998(valid)\t|\tAcc: 88.74%(valid)\n",
      "Epoch 18 | time in 0 minutes, 5 seconds | lr=0.000397\n",
      "\tLoss: 0.06167(train)\t|\tAcc: 97.77%(train)\n",
      "\tLoss: 0.00982(valid)\t|\tAcc: 88.72%(valid)\n",
      "Epoch 19 | time in 0 minutes, 5 seconds | lr=0.000377\n",
      "\tLoss: 0.05814(train)\t|\tAcc: 97.79%(train)\n",
      "\tLoss: 0.01823(valid)\t|\tAcc: 88.82%(valid)\n",
      "Epoch 20 | time in 0 minutes, 5 seconds | lr=0.000358\n",
      "\tLoss: 0.05349(train)\t|\tAcc: 98.06%(train)\n",
      "\tLoss: 0.02008(valid)\t|\tAcc: 89.04%(valid)\n",
      "Epoch 21 | time in 0 minutes, 5 seconds | lr=0.000341\n",
      "\tLoss: 0.04920(train)\t|\tAcc: 98.27%(train)\n",
      "\tLoss: 0.00959(valid)\t|\tAcc: 88.38%(valid)\n",
      "Epoch 22 | time in 0 minutes, 5 seconds | lr=0.000324\n",
      "\tLoss: 0.04378(train)\t|\tAcc: 98.37%(train)\n",
      "\tLoss: 0.02328(valid)\t|\tAcc: 88.28%(valid)\n",
      "Epoch 23 | time in 0 minutes, 5 seconds | lr=0.000307\n",
      "\tLoss: 0.04201(train)\t|\tAcc: 98.48%(train)\n",
      "\tLoss: 0.01526(valid)\t|\tAcc: 88.24%(valid)\n",
      "Epoch 24 | time in 0 minutes, 5 seconds | lr=0.000292\n",
      "\tLoss: 0.03941(train)\t|\tAcc: 98.48%(train)\n",
      "\tLoss: 0.00983(valid)\t|\tAcc: 88.38%(valid)\n",
      "Epoch 25 | time in 0 minutes, 5 seconds | lr=0.000277\n",
      "\tLoss: 0.03751(train)\t|\tAcc: 98.71%(train)\n",
      "\tLoss: 0.00904(valid)\t|\tAcc: 88.48%(valid)\n",
      "Epoch 26 | time in 0 minutes, 5 seconds | lr=0.000264\n",
      "\tLoss: 0.03507(train)\t|\tAcc: 98.77%(train)\n",
      "\tLoss: 0.01308(valid)\t|\tAcc: 88.32%(valid)\n",
      "Epoch 27 | time in 0 minutes, 5 seconds | lr=0.000250\n",
      "\tLoss: 0.03340(train)\t|\tAcc: 98.82%(train)\n",
      "\tLoss: 0.02578(valid)\t|\tAcc: 88.38%(valid)\n",
      "Epoch 28 | time in 0 minutes, 5 seconds | lr=0.000238\n",
      "\tLoss: 0.03307(train)\t|\tAcc: 98.83%(train)\n",
      "\tLoss: 0.01656(valid)\t|\tAcc: 88.70%(valid)\n",
      "Epoch 29 | time in 0 minutes, 5 seconds | lr=0.000226\n",
      "\tLoss: 0.02848(train)\t|\tAcc: 98.99%(train)\n",
      "\tLoss: 0.00938(valid)\t|\tAcc: 88.66%(valid)\n",
      "Epoch 30 | time in 0 minutes, 5 seconds | lr=0.000215\n",
      "\tLoss: 0.03039(train)\t|\tAcc: 98.89%(train)\n",
      "\tLoss: 0.02996(valid)\t|\tAcc: 88.60%(valid)\n",
      "Epoch 31 | time in 0 minutes, 5 seconds | lr=0.000204\n",
      "\tLoss: 0.02348(train)\t|\tAcc: 99.25%(train)\n",
      "\tLoss: 0.01931(valid)\t|\tAcc: 88.54%(valid)\n",
      "Epoch 32 | time in 0 minutes, 5 seconds | lr=0.000194\n",
      "\tLoss: 0.02628(train)\t|\tAcc: 99.10%(train)\n",
      "\tLoss: 0.01983(valid)\t|\tAcc: 88.16%(valid)\n",
      "Epoch 33 | time in 0 minutes, 5 seconds | lr=0.000184\n",
      "\tLoss: 0.02657(train)\t|\tAcc: 99.13%(train)\n",
      "\tLoss: 0.01533(valid)\t|\tAcc: 88.50%(valid)\n",
      "Epoch 34 | time in 0 minutes, 5 seconds | lr=0.000175\n",
      "\tLoss: 0.02508(train)\t|\tAcc: 99.08%(train)\n",
      "\tLoss: 0.01334(valid)\t|\tAcc: 88.62%(valid)\n",
      "Epoch 35 | time in 0 minutes, 5 seconds | lr=0.000166\n",
      "\tLoss: 0.02105(train)\t|\tAcc: 99.26%(train)\n",
      "\tLoss: 0.03337(valid)\t|\tAcc: 88.54%(valid)\n",
      "Epoch 36 | time in 0 minutes, 5 seconds | lr=0.000158\n",
      "\tLoss: 0.02486(train)\t|\tAcc: 99.12%(train)\n",
      "\tLoss: 0.02335(valid)\t|\tAcc: 88.48%(valid)\n",
      "Epoch 37 | time in 0 minutes, 5 seconds | lr=0.000150\n",
      "\tLoss: 0.02044(train)\t|\tAcc: 99.27%(train)\n",
      "\tLoss: 0.01937(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 38 | time in 0 minutes, 5 seconds | lr=0.000142\n",
      "\tLoss: 0.02365(train)\t|\tAcc: 99.24%(train)\n",
      "\tLoss: 0.01592(valid)\t|\tAcc: 88.74%(valid)\n",
      "Epoch 39 | time in 0 minutes, 5 seconds | lr=0.000135\n",
      "\tLoss: 0.01927(train)\t|\tAcc: 99.39%(train)\n",
      "\tLoss: 0.01333(valid)\t|\tAcc: 88.42%(valid)\n",
      "Epoch 40 | time in 0 minutes, 5 seconds | lr=0.000129\n",
      "\tLoss: 0.01898(train)\t|\tAcc: 99.33%(train)\n",
      "\tLoss: 0.01990(valid)\t|\tAcc: 88.50%(valid)\n",
      "Epoch 41 | time in 0 minutes, 5 seconds | lr=0.000122\n",
      "\tLoss: 0.01754(train)\t|\tAcc: 99.39%(train)\n",
      "\tLoss: 0.02245(valid)\t|\tAcc: 88.60%(valid)\n",
      "Epoch 42 | time in 0 minutes, 5 seconds | lr=0.000116\n",
      "\tLoss: 0.01936(train)\t|\tAcc: 99.29%(train)\n",
      "\tLoss: 0.02287(valid)\t|\tAcc: 88.58%(valid)\n",
      "Epoch 43 | time in 0 minutes, 5 seconds | lr=0.000110\n",
      "\tLoss: 0.01809(train)\t|\tAcc: 99.40%(train)\n",
      "\tLoss: 0.02059(valid)\t|\tAcc: 88.50%(valid)\n",
      "Epoch 44 | time in 0 minutes, 5 seconds | lr=0.000105\n",
      "\tLoss: 0.01792(train)\t|\tAcc: 99.45%(train)\n",
      "\tLoss: 0.01906(valid)\t|\tAcc: 88.54%(valid)\n",
      "Epoch 45 | time in 0 minutes, 5 seconds | lr=0.000099\n",
      "\tLoss: 0.01710(train)\t|\tAcc: 99.43%(train)\n",
      "\tLoss: 0.03672(valid)\t|\tAcc: 88.28%(valid)\n",
      "Epoch 46 | time in 0 minutes, 5 seconds | lr=0.000094\n",
      "\tLoss: 0.01724(train)\t|\tAcc: 99.44%(train)\n",
      "\tLoss: 0.01930(valid)\t|\tAcc: 88.26%(valid)\n",
      "Epoch 47 | time in 0 minutes, 5 seconds | lr=0.000090\n",
      "\tLoss: 0.01839(train)\t|\tAcc: 99.34%(train)\n",
      "\tLoss: 0.02265(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 48 | time in 0 minutes, 5 seconds | lr=0.000085\n",
      "\tLoss: 0.01617(train)\t|\tAcc: 99.41%(train)\n",
      "\tLoss: 0.02140(valid)\t|\tAcc: 88.72%(valid)\n",
      "Epoch 49 | time in 0 minutes, 5 seconds | lr=0.000081\n",
      "\tLoss: 0.01452(train)\t|\tAcc: 99.51%(train)\n",
      "\tLoss: 0.01925(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 50 | time in 0 minutes, 5 seconds | lr=0.000077\n",
      "\tLoss: 0.01614(train)\t|\tAcc: 99.42%(train)\n",
      "\tLoss: 0.04709(valid)\t|\tAcc: 88.60%(valid)\n",
      "Epoch 51 | time in 0 minutes, 5 seconds | lr=0.000073\n",
      "\tLoss: 0.01571(train)\t|\tAcc: 99.40%(train)\n",
      "\tLoss: 0.02623(valid)\t|\tAcc: 88.34%(valid)\n",
      "Epoch 52 | time in 0 minutes, 5 seconds | lr=0.000069\n",
      "\tLoss: 0.01406(train)\t|\tAcc: 99.51%(train)\n",
      "\tLoss: 0.03219(valid)\t|\tAcc: 88.26%(valid)\n",
      "Epoch 53 | time in 0 minutes, 5 seconds | lr=0.000066\n",
      "\tLoss: 0.01538(train)\t|\tAcc: 99.44%(train)\n",
      "\tLoss: 0.03457(valid)\t|\tAcc: 88.42%(valid)\n",
      "Epoch 54 | time in 0 minutes, 4 seconds | lr=0.000063\n",
      "\tLoss: 0.01474(train)\t|\tAcc: 99.50%(train)\n",
      "\tLoss: 0.03316(valid)\t|\tAcc: 88.54%(valid)\n",
      "Epoch 55 | time in 0 minutes, 5 seconds | lr=0.000060\n",
      "\tLoss: 0.01501(train)\t|\tAcc: 99.51%(train)\n",
      "\tLoss: 0.04187(valid)\t|\tAcc: 88.46%(valid)\n",
      "Epoch 56 | time in 0 minutes, 5 seconds | lr=0.000057\n",
      "\tLoss: 0.01450(train)\t|\tAcc: 99.50%(train)\n",
      "\tLoss: 0.01377(valid)\t|\tAcc: 88.44%(valid)\n",
      "Epoch 57 | time in 0 minutes, 5 seconds | lr=0.000054\n",
      "\tLoss: 0.01312(train)\t|\tAcc: 99.55%(train)\n",
      "\tLoss: 0.02604(valid)\t|\tAcc: 88.44%(valid)\n",
      "Epoch 58 | time in 0 minutes, 5 seconds | lr=0.000051\n",
      "\tLoss: 0.01428(train)\t|\tAcc: 99.47%(train)\n",
      "\tLoss: 0.01333(valid)\t|\tAcc: 88.42%(valid)\n",
      "Epoch 59 | time in 0 minutes, 5 seconds | lr=0.000048\n",
      "\tLoss: 0.01216(train)\t|\tAcc: 99.63%(train)\n",
      "\tLoss: 0.01011(valid)\t|\tAcc: 88.44%(valid)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | time in 0 minutes, 5 seconds | lr=0.000046\n",
      "\tLoss: 0.01419(train)\t|\tAcc: 99.52%(train)\n",
      "\tLoss: 0.01932(valid)\t|\tAcc: 88.56%(valid)\n",
      "Epoch 61 | time in 0 minutes, 5 seconds | lr=0.000044\n",
      "\tLoss: 0.01312(train)\t|\tAcc: 99.49%(train)\n",
      "\tLoss: 0.02708(valid)\t|\tAcc: 88.32%(valid)\n",
      "Epoch 62 | time in 0 minutes, 5 seconds | lr=0.000042\n",
      "\tLoss: 0.01384(train)\t|\tAcc: 99.49%(train)\n",
      "\tLoss: 0.02122(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 63 | time in 0 minutes, 5 seconds | lr=0.000039\n",
      "\tLoss: 0.01099(train)\t|\tAcc: 99.63%(train)\n",
      "\tLoss: 0.02326(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 64 | time in 0 minutes, 5 seconds | lr=0.000038\n",
      "\tLoss: 0.01364(train)\t|\tAcc: 99.58%(train)\n",
      "\tLoss: 0.02699(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 65 | time in 0 minutes, 5 seconds | lr=0.000036\n",
      "\tLoss: 0.01311(train)\t|\tAcc: 99.56%(train)\n",
      "\tLoss: 0.02860(valid)\t|\tAcc: 88.52%(valid)\n",
      "Epoch 66 | time in 0 minutes, 5 seconds | lr=0.000034\n",
      "\tLoss: 0.01256(train)\t|\tAcc: 99.60%(train)\n",
      "\tLoss: 0.02781(valid)\t|\tAcc: 88.52%(valid)\n",
      "Epoch 67 | time in 0 minutes, 5 seconds | lr=0.000032\n",
      "\tLoss: 0.01308(train)\t|\tAcc: 99.57%(train)\n",
      "\tLoss: 0.01588(valid)\t|\tAcc: 88.38%(valid)\n",
      "Epoch 68 | time in 0 minutes, 5 seconds | lr=0.000031\n",
      "\tLoss: 0.01311(train)\t|\tAcc: 99.55%(train)\n",
      "\tLoss: 0.01578(valid)\t|\tAcc: 88.50%(valid)\n",
      "Epoch 69 | time in 0 minutes, 4 seconds | lr=0.000029\n",
      "\tLoss: 0.01100(train)\t|\tAcc: 99.64%(train)\n",
      "\tLoss: 0.02118(valid)\t|\tAcc: 88.50%(valid)\n",
      "Epoch 70 | time in 0 minutes, 5 seconds | lr=0.000028\n",
      "\tLoss: 0.01277(train)\t|\tAcc: 99.50%(train)\n",
      "\tLoss: 0.00999(valid)\t|\tAcc: 88.36%(valid)\n",
      "Epoch 71 | time in 0 minutes, 5 seconds | lr=0.000026\n",
      "\tLoss: 0.01379(train)\t|\tAcc: 99.51%(train)\n",
      "\tLoss: 0.01862(valid)\t|\tAcc: 88.44%(valid)\n",
      "Epoch 72 | time in 0 minutes, 5 seconds | lr=0.000025\n",
      "\tLoss: 0.01356(train)\t|\tAcc: 99.54%(train)\n",
      "\tLoss: 0.02446(valid)\t|\tAcc: 88.26%(valid)\n",
      "Epoch 73 | time in 0 minutes, 5 seconds | lr=0.000024\n",
      "\tLoss: 0.01109(train)\t|\tAcc: 99.61%(train)\n",
      "\tLoss: 0.02960(valid)\t|\tAcc: 88.36%(valid)\n",
      "Epoch 74 | time in 0 minutes, 5 seconds | lr=0.000022\n",
      "\tLoss: 0.01184(train)\t|\tAcc: 99.63%(train)\n",
      "\tLoss: 0.02973(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 75 | time in 0 minutes, 5 seconds | lr=0.000021\n",
      "\tLoss: 0.01377(train)\t|\tAcc: 99.55%(train)\n",
      "\tLoss: 0.01748(valid)\t|\tAcc: 88.24%(valid)\n",
      "Epoch 76 | time in 0 minutes, 5 seconds | lr=0.000020\n",
      "\tLoss: 0.01189(train)\t|\tAcc: 99.61%(train)\n",
      "\tLoss: 0.01476(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 77 | time in 0 minutes, 5 seconds | lr=0.000019\n",
      "\tLoss: 0.01118(train)\t|\tAcc: 99.65%(train)\n",
      "\tLoss: 0.01005(valid)\t|\tAcc: 88.30%(valid)\n",
      "Epoch 78 | time in 0 minutes, 5 seconds | lr=0.000018\n",
      "\tLoss: 0.01205(train)\t|\tAcc: 99.60%(train)\n",
      "\tLoss: 0.03541(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 79 | time in 0 minutes, 5 seconds | lr=0.000017\n",
      "\tLoss: 0.01120(train)\t|\tAcc: 99.64%(train)\n",
      "\tLoss: 0.02423(valid)\t|\tAcc: 88.26%(valid)\n",
      "Epoch 80 | time in 0 minutes, 5 seconds | lr=0.000017\n",
      "\tLoss: 0.01268(train)\t|\tAcc: 99.56%(train)\n",
      "\tLoss: 0.02229(valid)\t|\tAcc: 88.38%(valid)\n",
      "Epoch 81 | time in 0 minutes, 5 seconds | lr=0.000016\n",
      "\tLoss: 0.01169(train)\t|\tAcc: 99.60%(train)\n",
      "\tLoss: 0.02411(valid)\t|\tAcc: 88.30%(valid)\n",
      "Epoch 82 | time in 0 minutes, 5 seconds | lr=0.000015\n",
      "\tLoss: 0.01077(train)\t|\tAcc: 99.65%(train)\n",
      "\tLoss: 0.01277(valid)\t|\tAcc: 88.34%(valid)\n",
      "Epoch 83 | time in 0 minutes, 5 seconds | lr=0.000014\n",
      "\tLoss: 0.01142(train)\t|\tAcc: 99.64%(train)\n",
      "\tLoss: 0.02095(valid)\t|\tAcc: 88.46%(valid)\n",
      "Epoch 84 | time in 0 minutes, 5 seconds | lr=0.000013\n",
      "\tLoss: 0.01170(train)\t|\tAcc: 99.69%(train)\n",
      "\tLoss: 0.02405(valid)\t|\tAcc: 88.44%(valid)\n",
      "Epoch 85 | time in 0 minutes, 5 seconds | lr=0.000013\n",
      "\tLoss: 0.01228(train)\t|\tAcc: 99.56%(train)\n",
      "\tLoss: 0.01562(valid)\t|\tAcc: 88.38%(valid)\n",
      "Epoch 86 | time in 0 minutes, 5 seconds | lr=0.000012\n",
      "\tLoss: 0.01306(train)\t|\tAcc: 99.58%(train)\n",
      "\tLoss: 0.03375(valid)\t|\tAcc: 88.38%(valid)\n",
      "Epoch 87 | time in 0 minutes, 4 seconds | lr=0.000012\n",
      "\tLoss: 0.01159(train)\t|\tAcc: 99.58%(train)\n",
      "\tLoss: 0.01581(valid)\t|\tAcc: 88.34%(valid)\n",
      "Epoch 88 | time in 0 minutes, 5 seconds | lr=0.000011\n",
      "\tLoss: 0.01149(train)\t|\tAcc: 99.64%(train)\n",
      "\tLoss: 0.01366(valid)\t|\tAcc: 88.32%(valid)\n",
      "Epoch 89 | time in 0 minutes, 5 seconds | lr=0.000010\n",
      "\tLoss: 0.01031(train)\t|\tAcc: 99.66%(train)\n",
      "\tLoss: 0.01127(valid)\t|\tAcc: 88.50%(valid)\n",
      "Epoch 90 | time in 0 minutes, 5 seconds | lr=0.000010\n",
      "\tLoss: 0.01172(train)\t|\tAcc: 99.61%(train)\n",
      "\tLoss: 0.01297(valid)\t|\tAcc: 88.28%(valid)\n",
      "Epoch 91 | time in 0 minutes, 5 seconds | lr=0.000009\n",
      "\tLoss: 0.01082(train)\t|\tAcc: 99.65%(train)\n",
      "\tLoss: 0.03112(valid)\t|\tAcc: 88.52%(valid)\n",
      "Epoch 92 | time in 0 minutes, 5 seconds | lr=0.000009\n",
      "\tLoss: 0.01209(train)\t|\tAcc: 99.60%(train)\n",
      "\tLoss: 0.02169(valid)\t|\tAcc: 88.48%(valid)\n",
      "Epoch 93 | time in 0 minutes, 5 seconds | lr=0.000008\n",
      "\tLoss: 0.01131(train)\t|\tAcc: 99.63%(train)\n",
      "\tLoss: 0.01734(valid)\t|\tAcc: 88.50%(valid)\n",
      "Epoch 94 | time in 0 minutes, 5 seconds | lr=0.000008\n",
      "\tLoss: 0.01112(train)\t|\tAcc: 99.63%(train)\n",
      "\tLoss: 0.01918(valid)\t|\tAcc: 88.42%(valid)\n",
      "Epoch 95 | time in 0 minutes, 4 seconds | lr=0.000008\n",
      "\tLoss: 0.01115(train)\t|\tAcc: 99.64%(train)\n",
      "\tLoss: 0.02663(valid)\t|\tAcc: 88.42%(valid)\n",
      "Epoch 96 | time in 0 minutes, 5 seconds | lr=0.000007\n",
      "\tLoss: 0.00946(train)\t|\tAcc: 99.70%(train)\n",
      "\tLoss: 0.01965(valid)\t|\tAcc: 88.38%(valid)\n",
      "Epoch 97 | time in 0 minutes, 5 seconds | lr=0.000007\n",
      "\tLoss: 0.01205(train)\t|\tAcc: 99.65%(train)\n",
      "\tLoss: 0.02563(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 98 | time in 0 minutes, 5 seconds | lr=0.000007\n",
      "\tLoss: 0.01020(train)\t|\tAcc: 99.69%(train)\n",
      "\tLoss: 0.04066(valid)\t|\tAcc: 88.40%(valid)\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "  start_time = time.time()\n",
    "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
    "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
    "\n",
    "  secs = int(time.time() - start_time)\n",
    "  mins = secs // 60\n",
    "  secs = secs % 60\n",
    "\n",
    "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
    "  for param_group in optimizer.param_groups:\n",
    "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
    "    break\n",
    "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
    "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vu3Y-wjwb0po"
   },
   "source": [
    "### L２正則化を使う\n",
    "* optimizerのweight_decayパラメータを0より大きな値にする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmxEuSFJazCJ"
   },
   "outputs": [],
   "source": [
    "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0Zr2S7ga3J4",
    "outputId": "6ce52deb-c6b3-468d-d488-28aa9e28ee53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | time in 0 minutes, 5 seconds | lr=0.000341\n",
      "\tLoss: 0.32830(train)\t|\tAcc: 86.29%(train)\n",
      "\tLoss: 0.01462(valid)\t|\tAcc: 86.34%(valid)\n",
      "Epoch 22 | time in 0 minutes, 5 seconds | lr=0.000324\n",
      "\tLoss: 0.31768(train)\t|\tAcc: 87.07%(train)\n",
      "\tLoss: 0.01073(valid)\t|\tAcc: 87.16%(valid)\n",
      "Epoch 23 | time in 0 minutes, 5 seconds | lr=0.000307\n",
      "\tLoss: 0.31307(train)\t|\tAcc: 86.94%(train)\n",
      "\tLoss: 0.01918(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 24 | time in 0 minutes, 5 seconds | lr=0.000292\n",
      "\tLoss: 0.30524(train)\t|\tAcc: 87.46%(train)\n",
      "\tLoss: 0.01391(valid)\t|\tAcc: 87.46%(valid)\n",
      "Epoch 25 | time in 0 minutes, 5 seconds | lr=0.000277\n",
      "\tLoss: 0.29485(train)\t|\tAcc: 87.79%(train)\n",
      "\tLoss: 0.01231(valid)\t|\tAcc: 87.78%(valid)\n",
      "Epoch 26 | time in 0 minutes, 5 seconds | lr=0.000264\n",
      "\tLoss: 0.28863(train)\t|\tAcc: 88.39%(train)\n",
      "\tLoss: 0.00853(valid)\t|\tAcc: 87.82%(valid)\n",
      "Epoch 27 | time in 0 minutes, 5 seconds | lr=0.000250\n",
      "\tLoss: 0.27876(train)\t|\tAcc: 88.72%(train)\n",
      "\tLoss: 0.01063(valid)\t|\tAcc: 87.88%(valid)\n",
      "Epoch 28 | time in 0 minutes, 4 seconds | lr=0.000238\n",
      "\tLoss: 0.27306(train)\t|\tAcc: 88.82%(train)\n",
      "\tLoss: 0.01534(valid)\t|\tAcc: 86.72%(valid)\n",
      "Epoch 29 | time in 0 minutes, 5 seconds | lr=0.000226\n",
      "\tLoss: 0.26618(train)\t|\tAcc: 89.13%(train)\n",
      "\tLoss: 0.01131(valid)\t|\tAcc: 87.50%(valid)\n",
      "Epoch 30 | time in 0 minutes, 4 seconds | lr=0.000215\n",
      "\tLoss: 0.26004(train)\t|\tAcc: 89.74%(train)\n",
      "\tLoss: 0.00986(valid)\t|\tAcc: 88.36%(valid)\n",
      "Epoch 31 | time in 0 minutes, 5 seconds | lr=0.000204\n",
      "\tLoss: 0.25714(train)\t|\tAcc: 89.70%(train)\n",
      "\tLoss: 0.01061(valid)\t|\tAcc: 87.72%(valid)\n",
      "Epoch 32 | time in 0 minutes, 5 seconds | lr=0.000194\n",
      "\tLoss: 0.24625(train)\t|\tAcc: 90.31%(train)\n",
      "\tLoss: 0.01278(valid)\t|\tAcc: 88.16%(valid)\n",
      "Epoch 33 | time in 0 minutes, 5 seconds | lr=0.000184\n",
      "\tLoss: 0.24061(train)\t|\tAcc: 90.56%(train)\n",
      "\tLoss: 0.01097(valid)\t|\tAcc: 88.24%(valid)\n",
      "Epoch 34 | time in 0 minutes, 5 seconds | lr=0.000175\n",
      "\tLoss: 0.23657(train)\t|\tAcc: 90.57%(train)\n",
      "\tLoss: 0.01486(valid)\t|\tAcc: 87.60%(valid)\n",
      "Epoch 35 | time in 0 minutes, 5 seconds | lr=0.000166\n",
      "\tLoss: 0.22831(train)\t|\tAcc: 91.20%(train)\n",
      "\tLoss: 0.01130(valid)\t|\tAcc: 88.16%(valid)\n",
      "Epoch 36 | time in 0 minutes, 5 seconds | lr=0.000158\n",
      "\tLoss: 0.22440(train)\t|\tAcc: 91.46%(train)\n",
      "\tLoss: 0.00773(valid)\t|\tAcc: 88.56%(valid)\n",
      "Epoch 37 | time in 0 minutes, 5 seconds | lr=0.000150\n",
      "\tLoss: 0.21701(train)\t|\tAcc: 91.61%(train)\n",
      "\tLoss: 0.01079(valid)\t|\tAcc: 87.92%(valid)\n",
      "Epoch 38 | time in 0 minutes, 5 seconds | lr=0.000142\n",
      "\tLoss: 0.21310(train)\t|\tAcc: 91.87%(train)\n",
      "\tLoss: 0.01060(valid)\t|\tAcc: 88.22%(valid)\n",
      "Epoch 39 | time in 0 minutes, 5 seconds | lr=0.000135\n",
      "\tLoss: 0.20922(train)\t|\tAcc: 92.19%(train)\n",
      "\tLoss: 0.01000(valid)\t|\tAcc: 88.28%(valid)\n",
      "Epoch 40 | time in 0 minutes, 5 seconds | lr=0.000129\n",
      "\tLoss: 0.20480(train)\t|\tAcc: 92.04%(train)\n",
      "\tLoss: 0.01359(valid)\t|\tAcc: 88.22%(valid)\n",
      "Epoch 41 | time in 0 minutes, 4 seconds | lr=0.000122\n",
      "\tLoss: 0.20065(train)\t|\tAcc: 92.47%(train)\n",
      "\tLoss: 0.01053(valid)\t|\tAcc: 88.20%(valid)\n",
      "Epoch 42 | time in 0 minutes, 5 seconds | lr=0.000116\n",
      "\tLoss: 0.19655(train)\t|\tAcc: 92.62%(train)\n",
      "\tLoss: 0.01065(valid)\t|\tAcc: 88.78%(valid)\n",
      "Epoch 43 | time in 0 minutes, 5 seconds | lr=0.000110\n",
      "\tLoss: 0.19053(train)\t|\tAcc: 93.12%(train)\n",
      "\tLoss: 0.00927(valid)\t|\tAcc: 88.62%(valid)\n",
      "Epoch 44 | time in 0 minutes, 5 seconds | lr=0.000105\n",
      "\tLoss: 0.18665(train)\t|\tAcc: 92.96%(train)\n",
      "\tLoss: 0.01096(valid)\t|\tAcc: 88.56%(valid)\n",
      "Epoch 45 | time in 0 minutes, 5 seconds | lr=0.000099\n",
      "\tLoss: 0.18255(train)\t|\tAcc: 93.15%(train)\n",
      "\tLoss: 0.01551(valid)\t|\tAcc: 88.20%(valid)\n",
      "Epoch 46 | time in 0 minutes, 5 seconds | lr=0.000094\n",
      "\tLoss: 0.18425(train)\t|\tAcc: 93.21%(train)\n",
      "\tLoss: 0.01339(valid)\t|\tAcc: 88.54%(valid)\n",
      "Epoch 47 | time in 0 minutes, 5 seconds | lr=0.000090\n",
      "\tLoss: 0.17628(train)\t|\tAcc: 93.46%(train)\n",
      "\tLoss: 0.01424(valid)\t|\tAcc: 88.18%(valid)\n",
      "Epoch 48 | time in 0 minutes, 5 seconds | lr=0.000085\n",
      "\tLoss: 0.17210(train)\t|\tAcc: 93.68%(train)\n",
      "\tLoss: 0.00569(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 49 | time in 0 minutes, 5 seconds | lr=0.000081\n",
      "\tLoss: 0.16794(train)\t|\tAcc: 93.89%(train)\n",
      "\tLoss: 0.01096(valid)\t|\tAcc: 88.66%(valid)\n",
      "Epoch 50 | time in 0 minutes, 5 seconds | lr=0.000077\n",
      "\tLoss: 0.16727(train)\t|\tAcc: 93.89%(train)\n",
      "\tLoss: 0.01487(valid)\t|\tAcc: 88.68%(valid)\n",
      "Epoch 51 | time in 0 minutes, 5 seconds | lr=0.000073\n",
      "\tLoss: 0.16604(train)\t|\tAcc: 94.01%(train)\n",
      "\tLoss: 0.01307(valid)\t|\tAcc: 88.60%(valid)\n",
      "Epoch 52 | time in 0 minutes, 5 seconds | lr=0.000069\n",
      "\tLoss: 0.16290(train)\t|\tAcc: 94.02%(train)\n",
      "\tLoss: 0.00697(valid)\t|\tAcc: 88.34%(valid)\n",
      "Epoch 53 | time in 0 minutes, 5 seconds | lr=0.000066\n",
      "\tLoss: 0.15685(train)\t|\tAcc: 94.41%(train)\n",
      "\tLoss: 0.01255(valid)\t|\tAcc: 88.54%(valid)\n",
      "Epoch 54 | time in 0 minutes, 5 seconds | lr=0.000063\n",
      "\tLoss: 0.15523(train)\t|\tAcc: 94.72%(train)\n",
      "\tLoss: 0.00879(valid)\t|\tAcc: 88.52%(valid)\n",
      "Epoch 55 | time in 0 minutes, 5 seconds | lr=0.000060\n",
      "\tLoss: 0.15382(train)\t|\tAcc: 94.57%(train)\n",
      "\tLoss: 0.00777(valid)\t|\tAcc: 88.80%(valid)\n",
      "Epoch 56 | time in 0 minutes, 5 seconds | lr=0.000057\n",
      "\tLoss: 0.15371(train)\t|\tAcc: 94.82%(train)\n",
      "\tLoss: 0.01057(valid)\t|\tAcc: 88.58%(valid)\n",
      "Epoch 57 | time in 0 minutes, 5 seconds | lr=0.000054\n",
      "\tLoss: 0.14809(train)\t|\tAcc: 94.95%(train)\n",
      "\tLoss: 0.01004(valid)\t|\tAcc: 88.42%(valid)\n",
      "Epoch 58 | time in 0 minutes, 5 seconds | lr=0.000051\n",
      "\tLoss: 0.14988(train)\t|\tAcc: 94.63%(train)\n",
      "\tLoss: 0.01012(valid)\t|\tAcc: 88.62%(valid)\n",
      "Epoch 59 | time in 0 minutes, 5 seconds | lr=0.000048\n",
      "\tLoss: 0.14381(train)\t|\tAcc: 95.09%(train)\n",
      "\tLoss: 0.01127(valid)\t|\tAcc: 88.56%(valid)\n",
      "Epoch 60 | time in 0 minutes, 4 seconds | lr=0.000046\n",
      "\tLoss: 0.14626(train)\t|\tAcc: 94.98%(train)\n",
      "\tLoss: 0.01231(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 61 | time in 0 minutes, 5 seconds | lr=0.000044\n",
      "\tLoss: 0.14105(train)\t|\tAcc: 95.14%(train)\n",
      "\tLoss: 0.00968(valid)\t|\tAcc: 88.56%(valid)\n",
      "Epoch 62 | time in 0 minutes, 5 seconds | lr=0.000042\n",
      "\tLoss: 0.13702(train)\t|\tAcc: 95.48%(train)\n",
      "\tLoss: 0.01682(valid)\t|\tAcc: 88.62%(valid)\n",
      "Epoch 63 | time in 0 minutes, 5 seconds | lr=0.000039\n",
      "\tLoss: 0.13740(train)\t|\tAcc: 95.45%(train)\n",
      "\tLoss: 0.00997(valid)\t|\tAcc: 88.60%(valid)\n",
      "Epoch 64 | time in 0 minutes, 5 seconds | lr=0.000038\n",
      "\tLoss: 0.13652(train)\t|\tAcc: 95.34%(train)\n",
      "\tLoss: 0.01398(valid)\t|\tAcc: 88.34%(valid)\n",
      "Epoch 65 | time in 0 minutes, 5 seconds | lr=0.000036\n",
      "\tLoss: 0.13705(train)\t|\tAcc: 95.31%(train)\n",
      "\tLoss: 0.01810(valid)\t|\tAcc: 88.74%(valid)\n",
      "Epoch 66 | time in 0 minutes, 4 seconds | lr=0.000034\n",
      "\tLoss: 0.13502(train)\t|\tAcc: 95.40%(train)\n",
      "\tLoss: 0.01359(valid)\t|\tAcc: 88.34%(valid)\n",
      "Epoch 67 | time in 0 minutes, 5 seconds | lr=0.000032\n",
      "\tLoss: 0.13574(train)\t|\tAcc: 95.38%(train)\n",
      "\tLoss: 0.01346(valid)\t|\tAcc: 88.50%(valid)\n",
      "Epoch 68 | time in 0 minutes, 5 seconds | lr=0.000031\n",
      "\tLoss: 0.13305(train)\t|\tAcc: 95.50%(train)\n",
      "\tLoss: 0.00720(valid)\t|\tAcc: 88.54%(valid)\n",
      "Epoch 69 | time in 0 minutes, 5 seconds | lr=0.000029\n",
      "\tLoss: 0.13181(train)\t|\tAcc: 95.53%(train)\n",
      "\tLoss: 0.01080(valid)\t|\tAcc: 88.60%(valid)\n",
      "Epoch 70 | time in 0 minutes, 5 seconds | lr=0.000028\n",
      "\tLoss: 0.13163(train)\t|\tAcc: 95.53%(train)\n",
      "\tLoss: 0.01564(valid)\t|\tAcc: 88.46%(valid)\n",
      "Epoch 71 | time in 0 minutes, 5 seconds | lr=0.000026\n",
      "\tLoss: 0.13047(train)\t|\tAcc: 95.58%(train)\n",
      "\tLoss: 0.01338(valid)\t|\tAcc: 88.60%(valid)\n",
      "Epoch 72 | time in 0 minutes, 5 seconds | lr=0.000025\n",
      "\tLoss: 0.12900(train)\t|\tAcc: 95.63%(train)\n",
      "\tLoss: 0.01186(valid)\t|\tAcc: 88.52%(valid)\n",
      "Epoch 73 | time in 0 minutes, 5 seconds | lr=0.000024\n",
      "\tLoss: 0.12935(train)\t|\tAcc: 95.70%(train)\n",
      "\tLoss: 0.01058(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 74 | time in 0 minutes, 5 seconds | lr=0.000022\n",
      "\tLoss: 0.12964(train)\t|\tAcc: 95.73%(train)\n",
      "\tLoss: 0.01154(valid)\t|\tAcc: 88.42%(valid)\n",
      "Epoch 75 | time in 0 minutes, 5 seconds | lr=0.000021\n",
      "\tLoss: 0.12960(train)\t|\tAcc: 95.49%(train)\n",
      "\tLoss: 0.00918(valid)\t|\tAcc: 88.52%(valid)\n",
      "Epoch 76 | time in 0 minutes, 5 seconds | lr=0.000020\n",
      "\tLoss: 0.12395(train)\t|\tAcc: 95.92%(train)\n",
      "\tLoss: 0.00977(valid)\t|\tAcc: 88.46%(valid)\n",
      "Epoch 77 | time in 0 minutes, 5 seconds | lr=0.000019\n",
      "\tLoss: 0.12518(train)\t|\tAcc: 95.92%(train)\n",
      "\tLoss: 0.00796(valid)\t|\tAcc: 88.48%(valid)\n",
      "Epoch 78 | time in 0 minutes, 5 seconds | lr=0.000018\n",
      "\tLoss: 0.12425(train)\t|\tAcc: 95.82%(train)\n",
      "\tLoss: 0.01254(valid)\t|\tAcc: 88.52%(valid)\n",
      "Epoch 79 | time in 0 minutes, 5 seconds | lr=0.000017\n",
      "\tLoss: 0.12647(train)\t|\tAcc: 95.90%(train)\n",
      "\tLoss: 0.01096(valid)\t|\tAcc: 88.54%(valid)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 | time in 0 minutes, 4 seconds | lr=0.000017\n",
      "\tLoss: 0.12422(train)\t|\tAcc: 95.94%(train)\n",
      "\tLoss: 0.00800(valid)\t|\tAcc: 88.64%(valid)\n",
      "Epoch 81 | time in 0 minutes, 5 seconds | lr=0.000016\n",
      "\tLoss: 0.12367(train)\t|\tAcc: 95.83%(train)\n",
      "\tLoss: 0.01189(valid)\t|\tAcc: 88.54%(valid)\n",
      "Epoch 82 | time in 0 minutes, 5 seconds | lr=0.000015\n",
      "\tLoss: 0.12237(train)\t|\tAcc: 95.93%(train)\n",
      "\tLoss: 0.01004(valid)\t|\tAcc: 88.44%(valid)\n",
      "Epoch 83 | time in 0 minutes, 5 seconds | lr=0.000014\n",
      "\tLoss: 0.12076(train)\t|\tAcc: 96.05%(train)\n",
      "\tLoss: 0.01043(valid)\t|\tAcc: 88.48%(valid)\n",
      "Epoch 84 | time in 0 minutes, 5 seconds | lr=0.000013\n",
      "\tLoss: 0.12264(train)\t|\tAcc: 96.02%(train)\n",
      "\tLoss: 0.01070(valid)\t|\tAcc: 88.46%(valid)\n",
      "Epoch 85 | time in 0 minutes, 5 seconds | lr=0.000013\n",
      "\tLoss: 0.12289(train)\t|\tAcc: 95.96%(train)\n",
      "\tLoss: 0.01159(valid)\t|\tAcc: 88.46%(valid)\n",
      "Epoch 86 | time in 0 minutes, 5 seconds | lr=0.000012\n",
      "\tLoss: 0.12097(train)\t|\tAcc: 96.10%(train)\n",
      "\tLoss: 0.00764(valid)\t|\tAcc: 88.48%(valid)\n",
      "Epoch 87 | time in 0 minutes, 5 seconds | lr=0.000012\n",
      "\tLoss: 0.12220(train)\t|\tAcc: 95.95%(train)\n",
      "\tLoss: 0.01404(valid)\t|\tAcc: 88.48%(valid)\n",
      "Epoch 88 | time in 0 minutes, 4 seconds | lr=0.000011\n",
      "\tLoss: 0.12297(train)\t|\tAcc: 95.89%(train)\n",
      "\tLoss: 0.01223(valid)\t|\tAcc: 88.44%(valid)\n",
      "Epoch 89 | time in 0 minutes, 5 seconds | lr=0.000010\n",
      "\tLoss: 0.12195(train)\t|\tAcc: 96.06%(train)\n",
      "\tLoss: 0.01195(valid)\t|\tAcc: 88.54%(valid)\n",
      "Epoch 90 | time in 0 minutes, 4 seconds | lr=0.000010\n",
      "\tLoss: 0.12074(train)\t|\tAcc: 96.09%(train)\n",
      "\tLoss: 0.01316(valid)\t|\tAcc: 88.38%(valid)\n",
      "Epoch 91 | time in 0 minutes, 5 seconds | lr=0.000009\n",
      "\tLoss: 0.11955(train)\t|\tAcc: 96.25%(train)\n",
      "\tLoss: 0.01586(valid)\t|\tAcc: 88.58%(valid)\n",
      "Epoch 92 | time in 0 minutes, 5 seconds | lr=0.000009\n",
      "\tLoss: 0.11823(train)\t|\tAcc: 96.18%(train)\n",
      "\tLoss: 0.01119(valid)\t|\tAcc: 88.56%(valid)\n",
      "Epoch 93 | time in 0 minutes, 5 seconds | lr=0.000008\n",
      "\tLoss: 0.11876(train)\t|\tAcc: 96.33%(train)\n",
      "\tLoss: 0.01144(valid)\t|\tAcc: 88.42%(valid)\n",
      "Epoch 94 | time in 0 minutes, 5 seconds | lr=0.000008\n",
      "\tLoss: 0.11803(train)\t|\tAcc: 96.30%(train)\n",
      "\tLoss: 0.01369(valid)\t|\tAcc: 88.58%(valid)\n",
      "Epoch 95 | time in 0 minutes, 5 seconds | lr=0.000008\n",
      "\tLoss: 0.11865(train)\t|\tAcc: 96.17%(train)\n",
      "\tLoss: 0.01029(valid)\t|\tAcc: 88.52%(valid)\n",
      "Epoch 96 | time in 0 minutes, 5 seconds | lr=0.000007\n",
      "\tLoss: 0.11859(train)\t|\tAcc: 96.00%(train)\n",
      "\tLoss: 0.01599(valid)\t|\tAcc: 88.46%(valid)\n",
      "Epoch 97 | time in 0 minutes, 5 seconds | lr=0.000007\n",
      "\tLoss: 0.11765(train)\t|\tAcc: 96.29%(train)\n",
      "\tLoss: 0.00875(valid)\t|\tAcc: 88.50%(valid)\n",
      "Epoch 98 | time in 0 minutes, 5 seconds | lr=0.000007\n",
      "\tLoss: 0.11789(train)\t|\tAcc: 96.19%(train)\n",
      "\tLoss: 0.01034(valid)\t|\tAcc: 88.58%(valid)\n",
      "Epoch 99 | time in 0 minutes, 5 seconds | lr=0.000006\n",
      "\tLoss: 0.11949(train)\t|\tAcc: 96.21%(train)\n",
      "\tLoss: 0.01084(valid)\t|\tAcc: 88.56%(valid)\n",
      "Epoch 100 | time in 0 minutes, 5 seconds | lr=0.000006\n",
      "\tLoss: 0.11683(train)\t|\tAcc: 96.28%(train)\n",
      "\tLoss: 0.01375(valid)\t|\tAcc: 88.56%(valid)\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "  start_time = time.time()\n",
    "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
    "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
    "\n",
    "  secs = int(time.time() - start_time)\n",
    "  mins = secs // 60\n",
    "  secs = secs % 60\n",
    "\n",
    "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
    "  for param_group in optimizer.param_groups:\n",
    "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
    "    break\n",
    "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
    "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIHA64UTdmBj"
   },
   "source": [
    "### early stopping\n",
    "* validation setでのaccuracyが4回連続で最高値を下回ったら訓練を終えることにする。\n",
    "* early stoppingの実現については、PyTorch Lightningを使う手もある。\n",
    " * https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "o0zclQnVdlVZ"
   },
   "outputs": [],
   "source": [
    "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3E_I5sRc3FF",
    "outputId": "42642acb-f5ea-4b16-85e8-caf2c69fb7f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | time in 0 minutes, 5 seconds | lr=0.000950\n",
      "\tLoss: 0.59996(train)\t|\tAcc: 67.92%(train)\n",
      "\tLoss: 0.02367(valid)\t|\tAcc: 71.64%(valid)\n",
      "Epoch 2 | time in 0 minutes, 5 seconds | lr=0.000902\n",
      "\tLoss: 0.55894(train)\t|\tAcc: 71.13%(train)\n",
      "\tLoss: 0.02175(valid)\t|\tAcc: 74.22%(valid)\n",
      "Epoch 3 | time in 0 minutes, 5 seconds | lr=0.000857\n",
      "\tLoss: 0.54009(train)\t|\tAcc: 72.75%(train)\n",
      "\tLoss: 0.02124(valid)\t|\tAcc: 76.92%(valid)\n",
      "Epoch 4 | time in 0 minutes, 5 seconds | lr=0.000815\n",
      "\tLoss: 0.52548(train)\t|\tAcc: 74.31%(train)\n",
      "\tLoss: 0.01911(valid)\t|\tAcc: 76.92%(valid)\n",
      "Epoch 5 | time in 0 minutes, 5 seconds | lr=0.000774\n",
      "\tLoss: 0.51180(train)\t|\tAcc: 75.15%(train)\n",
      "\tLoss: 0.01855(valid)\t|\tAcc: 78.24%(valid)\n",
      "Epoch 6 | time in 0 minutes, 5 seconds | lr=0.000735\n",
      "\tLoss: 0.49469(train)\t|\tAcc: 76.28%(train)\n",
      "\tLoss: 0.01846(valid)\t|\tAcc: 79.76%(valid)\n",
      "Epoch 7 | time in 0 minutes, 5 seconds | lr=0.000698\n",
      "\tLoss: 0.48739(train)\t|\tAcc: 76.65%(train)\n",
      "\tLoss: 0.01656(valid)\t|\tAcc: 78.56%(valid)\n",
      "Epoch 8 | time in 0 minutes, 4 seconds | lr=0.000663\n",
      "\tLoss: 0.46675(train)\t|\tAcc: 77.90%(train)\n",
      "\tLoss: 0.01949(valid)\t|\tAcc: 80.70%(valid)\n",
      "Epoch 9 | time in 0 minutes, 5 seconds | lr=0.000630\n",
      "\tLoss: 0.45941(train)\t|\tAcc: 78.46%(train)\n",
      "\tLoss: 0.01729(valid)\t|\tAcc: 81.86%(valid)\n",
      "Epoch 10 | time in 0 minutes, 4 seconds | lr=0.000599\n",
      "\tLoss: 0.43971(train)\t|\tAcc: 79.83%(train)\n",
      "\tLoss: 0.01455(valid)\t|\tAcc: 82.00%(valid)\n",
      "Epoch 11 | time in 0 minutes, 5 seconds | lr=0.000569\n",
      "\tLoss: 0.42657(train)\t|\tAcc: 80.85%(train)\n",
      "\tLoss: 0.01800(valid)\t|\tAcc: 76.32%(valid)\n",
      "Epoch 12 | time in 0 minutes, 5 seconds | lr=0.000540\n",
      "\tLoss: 0.42693(train)\t|\tAcc: 80.77%(train)\n",
      "\tLoss: 0.01612(valid)\t|\tAcc: 78.54%(valid)\n",
      "Epoch 13 | time in 0 minutes, 5 seconds | lr=0.000513\n",
      "\tLoss: 0.41091(train)\t|\tAcc: 81.75%(train)\n",
      "\tLoss: 0.01556(valid)\t|\tAcc: 84.04%(valid)\n",
      "Epoch 14 | time in 0 minutes, 5 seconds | lr=0.000488\n",
      "\tLoss: 0.39570(train)\t|\tAcc: 82.37%(train)\n",
      "\tLoss: 0.01315(valid)\t|\tAcc: 83.34%(valid)\n",
      "Epoch 15 | time in 0 minutes, 5 seconds | lr=0.000463\n",
      "\tLoss: 0.38621(train)\t|\tAcc: 83.10%(train)\n",
      "\tLoss: 0.01183(valid)\t|\tAcc: 85.06%(valid)\n",
      "Epoch 16 | time in 0 minutes, 4 seconds | lr=0.000440\n",
      "\tLoss: 0.38264(train)\t|\tAcc: 83.29%(train)\n",
      "\tLoss: 0.01233(valid)\t|\tAcc: 84.56%(valid)\n",
      "Epoch 17 | time in 0 minutes, 5 seconds | lr=0.000418\n",
      "\tLoss: 0.36514(train)\t|\tAcc: 84.00%(train)\n",
      "\tLoss: 0.01332(valid)\t|\tAcc: 85.30%(valid)\n",
      "Epoch 18 | time in 0 minutes, 5 seconds | lr=0.000397\n",
      "\tLoss: 0.35974(train)\t|\tAcc: 84.42%(train)\n",
      "\tLoss: 0.01488(valid)\t|\tAcc: 85.74%(valid)\n",
      "Epoch 19 | time in 0 minutes, 5 seconds | lr=0.000377\n",
      "\tLoss: 0.34441(train)\t|\tAcc: 85.54%(train)\n",
      "\tLoss: 0.01340(valid)\t|\tAcc: 86.26%(valid)\n",
      "Epoch 20 | time in 0 minutes, 4 seconds | lr=0.000358\n",
      "\tLoss: 0.33994(train)\t|\tAcc: 85.58%(train)\n",
      "\tLoss: 0.01233(valid)\t|\tAcc: 86.56%(valid)\n",
      "Epoch 21 | time in 0 minutes, 5 seconds | lr=0.000341\n",
      "\tLoss: 0.33041(train)\t|\tAcc: 85.87%(train)\n",
      "\tLoss: 0.01117(valid)\t|\tAcc: 86.14%(valid)\n",
      "Epoch 22 | time in 0 minutes, 5 seconds | lr=0.000324\n",
      "\tLoss: 0.33010(train)\t|\tAcc: 85.79%(train)\n",
      "\tLoss: 0.01182(valid)\t|\tAcc: 86.92%(valid)\n",
      "Epoch 23 | time in 0 minutes, 5 seconds | lr=0.000307\n",
      "\tLoss: 0.31266(train)\t|\tAcc: 86.92%(train)\n",
      "\tLoss: 0.01101(valid)\t|\tAcc: 87.34%(valid)\n",
      "Epoch 24 | time in 0 minutes, 5 seconds | lr=0.000292\n",
      "\tLoss: 0.30788(train)\t|\tAcc: 87.24%(train)\n",
      "\tLoss: 0.01425(valid)\t|\tAcc: 87.44%(valid)\n",
      "Epoch 25 | time in 0 minutes, 5 seconds | lr=0.000277\n",
      "\tLoss: 0.29855(train)\t|\tAcc: 87.61%(train)\n",
      "\tLoss: 0.01309(valid)\t|\tAcc: 87.86%(valid)\n",
      "Epoch 26 | time in 0 minutes, 5 seconds | lr=0.000264\n",
      "\tLoss: 0.28931(train)\t|\tAcc: 88.14%(train)\n",
      "\tLoss: 0.01286(valid)\t|\tAcc: 87.48%(valid)\n",
      "Epoch 27 | time in 0 minutes, 5 seconds | lr=0.000250\n",
      "\tLoss: 0.28068(train)\t|\tAcc: 88.47%(train)\n",
      "\tLoss: 0.01079(valid)\t|\tAcc: 87.74%(valid)\n",
      "Epoch 28 | time in 0 minutes, 5 seconds | lr=0.000238\n",
      "\tLoss: 0.27569(train)\t|\tAcc: 88.80%(train)\n",
      "\tLoss: 0.01237(valid)\t|\tAcc: 87.80%(valid)\n",
      "Epoch 29 | time in 0 minutes, 5 seconds | lr=0.000226\n",
      "\tLoss: 0.26729(train)\t|\tAcc: 89.12%(train)\n",
      "\tLoss: 0.01655(valid)\t|\tAcc: 87.88%(valid)\n",
      "Epoch 30 | time in 0 minutes, 4 seconds | lr=0.000215\n",
      "\tLoss: 0.25991(train)\t|\tAcc: 89.74%(train)\n",
      "\tLoss: 0.01178(valid)\t|\tAcc: 87.28%(valid)\n",
      "Epoch 31 | time in 0 minutes, 5 seconds | lr=0.000204\n",
      "\tLoss: 0.25320(train)\t|\tAcc: 89.89%(train)\n",
      "\tLoss: 0.01261(valid)\t|\tAcc: 88.06%(valid)\n",
      "Epoch 32 | time in 0 minutes, 4 seconds | lr=0.000194\n",
      "\tLoss: 0.24693(train)\t|\tAcc: 90.13%(train)\n",
      "\tLoss: 0.01669(valid)\t|\tAcc: 88.00%(valid)\n",
      "Epoch 33 | time in 0 minutes, 4 seconds | lr=0.000184\n",
      "\tLoss: 0.24235(train)\t|\tAcc: 90.46%(train)\n",
      "\tLoss: 0.01151(valid)\t|\tAcc: 88.18%(valid)\n",
      "Epoch 34 | time in 0 minutes, 4 seconds | lr=0.000175\n",
      "\tLoss: 0.23205(train)\t|\tAcc: 90.93%(train)\n",
      "\tLoss: 0.00716(valid)\t|\tAcc: 88.26%(valid)\n",
      "Epoch 35 | time in 0 minutes, 4 seconds | lr=0.000166\n",
      "\tLoss: 0.22598(train)\t|\tAcc: 91.33%(train)\n",
      "\tLoss: 0.00918(valid)\t|\tAcc: 88.04%(valid)\n",
      "Epoch 36 | time in 0 minutes, 5 seconds | lr=0.000158\n",
      "\tLoss: 0.22175(train)\t|\tAcc: 91.56%(train)\n",
      "\tLoss: 0.01267(valid)\t|\tAcc: 88.12%(valid)\n",
      "Epoch 37 | time in 0 minutes, 5 seconds | lr=0.000150\n",
      "\tLoss: 0.21654(train)\t|\tAcc: 91.52%(train)\n",
      "\tLoss: 0.01079(valid)\t|\tAcc: 88.30%(valid)\n",
      "Epoch 38 | time in 0 minutes, 5 seconds | lr=0.000142\n",
      "\tLoss: 0.20797(train)\t|\tAcc: 92.16%(train)\n",
      "\tLoss: 0.01382(valid)\t|\tAcc: 87.96%(valid)\n",
      "Epoch 39 | time in 0 minutes, 5 seconds | lr=0.000135\n",
      "\tLoss: 0.20751(train)\t|\tAcc: 92.11%(train)\n",
      "\tLoss: 0.00856(valid)\t|\tAcc: 88.26%(valid)\n",
      "Epoch 40 | time in 0 minutes, 5 seconds | lr=0.000129\n",
      "\tLoss: 0.19911(train)\t|\tAcc: 92.36%(train)\n",
      "\tLoss: 0.01036(valid)\t|\tAcc: 88.38%(valid)\n",
      "Epoch 41 | time in 0 minutes, 5 seconds | lr=0.000122\n",
      "\tLoss: 0.19656(train)\t|\tAcc: 92.69%(train)\n",
      "\tLoss: 0.01161(valid)\t|\tAcc: 88.04%(valid)\n",
      "Epoch 42 | time in 0 minutes, 4 seconds | lr=0.000116\n",
      "\tLoss: 0.19180(train)\t|\tAcc: 92.73%(train)\n",
      "\tLoss: 0.01247(valid)\t|\tAcc: 88.12%(valid)\n",
      "Epoch 43 | time in 0 minutes, 5 seconds | lr=0.000110\n",
      "\tLoss: 0.18847(train)\t|\tAcc: 92.91%(train)\n",
      "\tLoss: 0.00755(valid)\t|\tAcc: 88.18%(valid)\n",
      "Epoch 44 | time in 0 minutes, 5 seconds | lr=0.000105\n",
      "\tLoss: 0.18408(train)\t|\tAcc: 93.22%(train)\n",
      "\tLoss: 0.00903(valid)\t|\tAcc: 88.50%(valid)\n",
      "Epoch 45 | time in 0 minutes, 5 seconds | lr=0.000099\n",
      "\tLoss: 0.18403(train)\t|\tAcc: 93.11%(train)\n",
      "\tLoss: 0.01307(valid)\t|\tAcc: 87.90%(valid)\n",
      "Epoch 46 | time in 0 minutes, 4 seconds | lr=0.000094\n",
      "\tLoss: 0.17692(train)\t|\tAcc: 93.64%(train)\n",
      "\tLoss: 0.00800(valid)\t|\tAcc: 88.66%(valid)\n",
      "Epoch 47 | time in 0 minutes, 4 seconds | lr=0.000090\n",
      "\tLoss: 0.17812(train)\t|\tAcc: 93.23%(train)\n",
      "\tLoss: 0.01381(valid)\t|\tAcc: 88.20%(valid)\n",
      "Epoch 48 | time in 0 minutes, 5 seconds | lr=0.000085\n",
      "\tLoss: 0.17359(train)\t|\tAcc: 93.67%(train)\n",
      "\tLoss: 0.00882(valid)\t|\tAcc: 88.40%(valid)\n",
      "Epoch 49 | time in 0 minutes, 4 seconds | lr=0.000081\n",
      "\tLoss: 0.16697(train)\t|\tAcc: 94.05%(train)\n",
      "\tLoss: 0.01279(valid)\t|\tAcc: 88.62%(valid)\n",
      "Epoch 50 | time in 0 minutes, 4 seconds | lr=0.000077\n",
      "\tLoss: 0.16476(train)\t|\tAcc: 94.15%(train)\n",
      "\tLoss: 0.01130(valid)\t|\tAcc: 88.48%(valid)\n"
     ]
    }
   ],
   "source": [
    "patience = 4\n",
    "early_stop_count = 0\n",
    "best_valid_acc = 0.0\n",
    "\n",
    "MIN_N_EPOCHS = 10 # 最低このエポック数は実行する\n",
    "N_EPOCHS = 100 # エポック数を増やしておく\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "  start_time = time.time()\n",
    "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
    "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
    "\n",
    "  secs = int(time.time() - start_time)\n",
    "  mins = secs // 60\n",
    "  secs = secs % 60\n",
    "\n",
    "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
    "  for param_group in optimizer.param_groups:\n",
    "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
    "    break\n",
    "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
    "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')\n",
    "\n",
    "  # early stopping\n",
    "  if epoch + 1 > MIN_N_EPOCHS:\n",
    "    if best_valid_acc <= valid_acc:\n",
    "      best_valid_acc = valid_acc\n",
    "      early_stop_count = 0\n",
    "    else:\n",
    "      early_stop_count += 1\n",
    "      if early_stop_count == patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRvkncN09MKk"
   },
   "source": [
    "## 07-05 テストセット上で評価\n",
    "* 見つけ出したベストな設定を使って、テストセット上での最終的な評価をおこなう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_gHj4x38y8h",
    "outputId": "471964c0-2621-43e6-8799-499b17f5db99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset...\n",
      "\tLoss: 0.00310(test)\t|\tAcc: 88.01%(test)\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset...')\n",
    "test_loss, test_acc = test(test_iterator, model, criterion)\n",
    "print(f'\\tLoss: {test_loss:.5f}(test)\\t|\\tAcc: {test_acc * 100:.2f}%(test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1M_VQ1xhcWq"
   },
   "source": [
    "# MLPだけを使って（RNNを使わずに）単語列データの感情分析（ポジネガの二値分類）を行うコードを、PyTorchで書いてください。\n",
    "\n",
    "\n",
    "# 一つ前の課題との違いは、単語埋め込みも今回は同時に一から学習する、という点です。（一つ前の課題では、fastTextの単語ベクトルを定数としてそのまま使っていました。）\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOseP2iX9ENI9isDfpwMeSd",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "07_document_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
