{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/08_document_classification_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtbbXGNJnJQB"
   },
   "source": [
    "# 08 RNNを使った文書分類\n",
    "* RNNの出力を文書の潜在表現として利用し、文書分類を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6pvVYxeoOqB"
   },
   "source": [
    "## 08-01 torchtextを使ってIMDbデータを読み込む\n",
    "* ここでIMDbデータセットの読み込みにつかう`torchtext.datasets`については、下記を参照。\n",
    " * https://torchtext.readthedocs.io/en/latest/datasets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8X-GEo5nqdK"
   },
   "source": [
    "### 実験の再現性確保のための設定など\n",
    "* https://pytorch.org/docs/stable/notes/randomness.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG']=\":4096:8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2VicF1RrhJfa"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext import datasets\n",
    "from torchtext.data import Field, LabelField, BucketIterator\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.set_deterministic(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeCGHBNAojNh"
   },
   "source": [
    "### torchtextのフィールド\n",
    "* TEXTフィールドと、LABELフィールドという２種類のFieldオブジェクトのインスタンスを作る。\n",
    " * Fieldクラスの詳細については[ここ](https://github.com/pytorch/text/blob/master/torchtext/data/field.py)を参照。\n",
    "* TEXTフィールドは、テキストの前処理の仕方を決めておくのに使う。\n",
    "* LABELフィールドは、ラベルの前処理に使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jug86Tt9hMMD"
   },
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize=\"spacy\")\n",
    "LABEL = LabelField()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TaaTUp6on2x"
   },
   "source": [
    "### IMDbデータセットをダウンロードした後、前処理しつつ読み込む\n",
    "* ダウンロードはすぐ終わるが、解凍に少し時間がかかる。\n",
    "* また、TEXTフィールドでspaCyのtokenizationを使うように設定したので、少し時間がかかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bj6XmwLXhVKv",
    "outputId": "c3a4a902-e644-4ede-e791-d11f22cb9cbe"
   },
   "outputs": [],
   "source": [
    "train_valid_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11FpCyLWotGK"
   },
   "source": [
    "### テストセット以外の部分を訓練データと検証データに分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72Xd-UDohXcx",
    "outputId": "e965adc9-e4de-449e-d70a-b8288375592a"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_valid_data.split(split_ratio=0.8)\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lohYcCzUo2K6"
   },
   "source": [
    "### データセットの語彙とラベルを作る\n",
    "* TEXTラベルのほうでは、最大語彙サイズを指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zblGelVrheSs",
    "outputId": "b05eec68-c028-4d35-8e1b-9bf51c59a27b"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rEsKP_u3fVu",
    "outputId": "ea99010c-4584-4b75-bc35-3b44bffd9a4f"
   },
   "outputs": [],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kyr7J_E4hg6V",
    "outputId": "c05a6dac-adae-45b8-ef3c-a66d18633e2b"
   },
   "outputs": [],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqr48rCVp1Tf"
   },
   "source": [
    "### デバイスの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fXYLKJvkX1m"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDjU2ykppyi2"
   },
   "source": [
    "### ミニバッチを取り出すためのiteratorを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZKysnlAhjGS"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "train_iterator = BucketIterator(train_data, batch_size=BATCH_SIZE, device=device,\n",
    "                                     sort_within_batch=True, shuffle=True, sort_key=lambda x: len(x.text))\n",
    "valid_iterator = BucketIterator(valid_data, batch_size=BATCH_SIZE, device=device)\n",
    "test_iterator = BucketIterator(test_data, batch_size=BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ0yHMt4puyA"
   },
   "source": [
    "### 定数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_3KWMr4hwxl"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "NUM_CLASS = len(LABEL.vocab)\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 64\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57xqsnpTnE_c"
   },
   "source": [
    "### モデルの定義\n",
    "* LSTMを使う（GRUに変えても良い）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1wcVHcmg9KI"
   },
   "outputs": [],
   "source": [
    "class RNNTextSentiment(nn.Module):\n",
    "  def __init__(self, emb_dim, hid_dim,\n",
    "               num_class, vocab_size, padding_idx, p=0.0):\n",
    "    super().__init__()\n",
    "\n",
    "    self.input_dim = vocab_size\n",
    "    self.emb_dim = emb_dim\n",
    "    self.hid_dim = hid_dim\n",
    "\n",
    "    self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=padding_idx)\n",
    "    self.rnn = nn.LSTM(emb_dim, hid_dim)\n",
    "    self.fc = nn.Linear(hid_dim * 2, num_class)\n",
    "    self.dropout = nn.Dropout(p=p)\n",
    "\n",
    "  def forward(self, src):\n",
    "    # srcの形は[単語列長, バッチサイズ]\n",
    "\n",
    "    embedded = self.dropout(self.embedding(src))\n",
    "    # embeddedの形は[単語列長, バッチサイズ, 埋め込み次元数]\n",
    "\n",
    "    outputs, (hidden, _) = self.rnn(embedded)\n",
    "    # outputsの形は[単語列長, バッチサイズ, 隠れ状態の次元数]\n",
    "    # hiddenの形は[1, バッチサイズ, 隠れ状態の次元数]\n",
    "\n",
    "    mean_outputs = outputs.mean(0)\n",
    "    hidden = hidden.squeeze()\n",
    "    # mean_outputsの形は[バッチサイズ, 隠れ状態の次元数]\n",
    "    # hiddenの形は[バッチサイズ, 隠れ状態の次元数]\n",
    "    output = self.fc(torch.cat((mean_outputs, hidden), dim=1))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZLDlFWMqsZj"
   },
   "source": [
    "### 重みの初期化はこのような方法でも可能\n",
    "* 関数を定義しておき、applyする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0nkUyLx3xDZ"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "  for name, param in m.named_parameters():\n",
    "    if 'weight' in name:\n",
    "      nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "    else:\n",
    "      nn.init.constant_(param.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLo4vO0IrR62"
   },
   "source": [
    "* モデルのインスタンスを得る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuW6ghef34R4"
   },
   "outputs": [],
   "source": [
    "model = RNNTextSentiment(EMBED_DIM, HIDDEN_DIM, NUM_CLASS, INPUT_DIM,\n",
    "                         padding_idx=PAD_IDX, p=0.5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fJkM3QLrUGN"
   },
   "source": [
    "* 重みの初期化を実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnUstTZe4X2x",
    "outputId": "c3152206-86b7-49fe-b12c-eb89fa3e1d44"
   },
   "outputs": [],
   "source": [
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRp5h3wQrMib"
   },
   "source": [
    "* バイアスがゼロに初期化されているか確認してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8pvIjJ2rC_g",
    "outputId": "dbcae7d7-f4cd-4b6b-bd8d-b19694deb6f5"
   },
   "outputs": [],
   "source": [
    "  for name, param in model.named_parameters():\n",
    "    if 'weight' not in name:\n",
    "      print(param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-S9TDJpIraUM"
   },
   "source": [
    "### 最適化アルゴリズムの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaEbLC9T4pxb"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t427SeakeqVP"
   },
   "source": [
    "パラメータの数を数えてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h06O037X4vRV",
    "outputId": "58594067-d216-4cb6-c237-2054b5a72f69"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwMV61kTri4-"
   },
   "source": [
    "### 文書分類の損失関数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5w-1q7u47Ax"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iScb7iZSs2nY"
   },
   "source": [
    "### 訓練用の関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gg1tuw6y4-Or"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "  model.train()\n",
    "  epoch_loss = 0.\n",
    "  epoch_acc = 0.\n",
    "  for batch in iterator:\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch.text)\n",
    "    loss = criterion(output, batch.label)\n",
    "    loss.backward()\n",
    "\n",
    "    # RNNではgradientのクリッピングをよく行う\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += (output.argmax(1) == batch.label).sum().item()\n",
    "\n",
    "  return epoch_loss / len(iterator), epoch_acc / len(iterator.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBoo_Ez6s9Gs"
   },
   "source": [
    "### 評価用の関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qmfP-By5fOm"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "  model.eval()\n",
    "  epoch_loss = 0.\n",
    "  epoch_acc = 0.\n",
    "  with torch.no_grad():\n",
    "    for batch in iterator:\n",
    "      output = model(batch.text)\n",
    "      loss = criterion(output, batch.label)\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += (output.argmax(1) == batch.label).sum().item()\n",
    "\n",
    "  return epoch_loss / len(iterator), epoch_acc / len(iterator.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcPnwzJz5rnV"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "  elapsed_time = end_time - start_time\n",
    "  elapsed_mins = int(elapsed_time // 60)\n",
    "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "  return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ioV2XRKG5tf-",
    "outputId": "7ff709d0-ee87-43e9-bf8d-a93078bb50a1"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 100\n",
    "CLIP = 1.\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "\n",
    "  start_time = time.time()\n",
    "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "  end_time = time.time()\n",
    "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "  print(f'Epoch {epoch} | time in {epoch_mins} minutes, {epoch_secs} seconds')\n",
    "  print(f'\\tLoss {train_loss:.4f} (train)\\t|\\tAcc {train_acc * 100:.1f}% (train)')\n",
    "  print(f'\\tLoss {valid_loss:.4f} (valid)\\t|\\tAcc {valid_acc * 100:.1f}% (valid)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8ju77-HEhVW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPTbyJ2txUlu/c9kgd6gwEa",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1HaIOpOtFSc4pjrdAglJT6cjgfkrJQIQ4",
   "name": "08_document_classification_with_RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
